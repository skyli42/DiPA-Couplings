
\section{Preliminaries}

\subsection{Differential Privacy}

We begin by introduce the formal definition of differential privacy and key results about DP algorithms. 

Intuitively, for any output $\sigma$ of a private algorithm $A$, the probability of obtaining $\sigma$ for a dataset with some individual Alex should close (measured by a multiplicative factor) to the probability of obtaining $\sigma$ for a ``similar'' dataset (in particular, with Alex's data removed or changed).

In general, we work with \textbf{datasets} $\mathcal{X}\in X^n$ of size $n$ where $X$ is the set of all possible individual data points.

We first define what it means for datasets to be ``similar'' to each other. 

\begin{defn}
    Two datasets $\mathcal{X}=(x_1, \ldots, x_n), \mathcal{X}'=(x'_1, \ldots, x'_n)\in X^n$ are \textbf{adjacent} (denoted by $\mathcal{X}\sim\mathcal{X}'$) if $|\{i: x_i\neq x'_i\}|\leq 1$\footnote{A common variant is to define adjacency by the removal or addition of an entry, rather than by the modification of an entry}.
\end{defn}

This motivates the formal definition of differential privacy:

\begin{defn}[Pure Differential Privacy]
    For some $\varepsilon>0$, a randomized algorithm $A$ is $\varepsilon$-differentially private if, for all pairs of adjacent datasets $X\sim X'$ and all events $E \subseteq \im(A)$, \[\PP[A(X) \in E]\leq e^\varepsilon \PP[A(X')\in E]\]
    If there exists some $\varepsilon>0$ such that $A$ is $\varepsilon$-differentially private, we call $A$ ``differentially private'' or simply ``private'' without reference to a specific $\varepsilon$.
\end{defn}

The privacy parameter $\varepsilon$ is traditionally thought of as analogous to the ``privacy cost'' of a program; the larger $\varepsilon$ is, the more privacy is ``lost''. In our analysis of differentially private algorithms, we thus aim to minimize the ``cost'' of an algorithm, i.e. find a tight upper bound, if one exists, on $\varepsilon$ for an algorithm. 

We also introduce max divergence as a method of measuring ``true'' privacy cost. 

\begin{defn}[Max Divergence]
    For any two probability distributions $P, Q$ over a shared event space $E$, the max-divergence of $P$ and $Q$ is 
    $D_{\infty}(P||Q) = \max_{e\in E}\ln\left(\frac{P(e)}{Q(e)}\right)$.
\end{defn}

It immediately follows from the definition that an algorithm $A$ is $\varepsilon$-DP if and only if for all adjacent inputs $X\sim X'$, $D_{\infty}(A(X)||A(X'))\leq \varepsilon$. In particular, $D_{\infty}(A(X)||A(X'))\leq \varepsilon$ represents the tightest possible upper bound on $\varepsilon$ for $A$. 

An extremely useful property of differential privacy is that differentially private programs can be \textbf{sequentially composed} with a linear degradation in privacy:

\begin{thm}[Standard Composition \cite{dworkAlgorithmicFoundationsDifferential2014b}]
    If $A$ is $\varepsilon_1$-differentially private and, for all $\sigma$, $B(\sigma, \cdot)$ is $\varepsilon_2$-differentially private, then $B(A(X), X)$ is $\varepsilon_1+\varepsilon_2$-differentially private. 
\end{thm}

Composition therefore allows us to view privacy parameters $\varepsilon$ as a ``budget'' for privacy-leaking operations in a program. 

\subsubsection{Sensitivity and the Laplace Mechanism}

Because we are typically interested in analyzing \textit{functions} of a dataset (for example, the \textbf{average} age of a group), it is often useful to examine differential privacy through a similar model --- instead of comparing two adjacent datasets $X\sim X'$, we compare \textbf{queries} $f(X)$ and $f(X')$. In this world, we care about the \textit{sensitivity} of functions: how much a function \textit{changes} when considering adjacent inputs. 
The ($\ell_1$-)sensitivity of a function $f: X\to \RR$, denoted $\Delta f$, is defined as $\Delta f = \max_{X\sim X'}||f(X)-f(X')||_1$.

For any given function with a known sensitivity, we can construct a differentially private version of the function with the \textbf{Laplace Mechanism}. 

Recall that the Laplace distribution $\Lap(\mu, b)$ with mean $\mu$ and spread parameter $b$ is the probability distribution with probability density function $f(x) = \frac{1}{2b}\exp(-\frac{|x-\mu|}{b})$. If $\mu =0$, we may abbreviate $\Lap(0, b)$ as $\Lap(b)$. 

The Laplace Mechanism adds noise sampled from the Laplace distribution to a query result. In particular, the noise is dependent on the sensitivity of the input function; as expected, the higher the sensitivity of a function is, the more noise the Laplace mechanism will add to it.   

\begin{thm}[Theorem 3.6~\cite{dworkAlgorithmicFoundationsDifferential2014b}]
    For a function $f$ with sensitivity $\Delta$, $A(X) = f(X) + \Lap(\frac{\Delta}{\varepsilon})$ is $\varepsilon$-differentially private. 
\end{thm}

\subsection{Couplings and Liftings}

We now introduce probabilistic couplings and approximate liftings, which are probabilistic tools that allow for the structured creation of proofs of differential privacy.

Probabilistic couplings are a common tool in analyses of probabilistic processes that allow two otherwise independent processes to be correlated together and analyzed as a joint distribution; in particular, this is useful when attempting to prove properties about the \textbf{relationship} between two probabilistic processes. 

\begin{defn}[Couplings]
    A coupling between two distributions $A$ and $B$ is a joint distribution $C$ such that $\pi_1(C)=A$ and $\pi_2(C)=B$, where $\pi_1(C)$ and $\pi_2(C)$ are the first and second marginals of $C$, respectively. 
\end{defn}

A previous line of work extends couplings to reason about privacy in particular. The core construct introduced is the \textbf{approximate lifting}~\cite{bartheProvingDifferentialPrivacy2016,bartheDifferentialPrivacyComposition2013,hsuProbabilisticCouplingsProbabilistic2017,albarghouthiConstraintBasedSynthesisCoupling2018,albarghouthiSynthesizingCouplingProofs2017}:

\begin{defn}[$\varepsilon$-Lifting]
    Let $A_1, A_2$ be two sample spaces. We say a distribution $\mu_1$ on $A_1$ and $\mu_2$ on $A_2$ are related by the $\mathbf{\varepsilon}$\textbf{-lifting} of the relation $\Psi\subseteq A_1\times A_2$ (written $\mu_1(\Psi)^{\#\varepsilon}\mu_2$) if there exist two \textbf{witness distributions} $\mu_L, \mu_R$ on $A_1\times A_2$ such that\begin{enumerate}
        \item $\pi_1(\mu_L) = \mu_1$ and $\pi_2(\mu_R) = \mu_2$
        \item $\supp(\mu_L), \supp(\mu_R)\subseteq \Psi$
        \item $\sup_{E\subseteq A_1\times A_2}(\PP_{x\gets \mu_L}[x\in E]- e^\varepsilon \PP_{x\gets \mu_R}[x\in E])\leq 0$
    \end{enumerate}
\end{defn}

In some sense, approximate liftings can be considered ``half-couplings'', where ``half'' (the first marginal) of $\mu_L$ is coupled with ``half'' (the second marginal) of $\mu_R$. Approximate liftings also incur a ``privacy cost'' $\varepsilon$. 

As expected, there is a close connection between approximate liftings and differential privacy:

\begin{thm}[\cite{bartheProvingDifferentialPrivacy2016}]
    An algorithm $A(X)$ is $\varepsilon$-differentially private if and only if, for all adjacent inputs $X\sim X'$, $A(X)(=)^{\#\varepsilon}A(X')$.
\end{thm}

However, relaxing the lifted relation from equality to implication still allows us to prove that an algorithm is private; this proves useful in particular because constructing an approximate lifting of the equality relation can be intractable in practice. 

\begin{thm}[\cite{bartheProvingDifferentialPrivacy2016}]\label{implicationcouplingthm}
    If for all adjacent input sequences $X\sim X'$ and outputs $\sigma$ of $A$, $A(X)\{(a, b): a=\sigma\implies b=\sigma\}^{\#\varepsilon}A(X')$, then $A(X)$ is $\varepsilon-$differentially private.
\end{thm}

The existence of an implication coupling of this form is itself a direct proof of privacy---our goal will be to ``automatically'' construct such proofs. 

Many standard differential privacy results can be restated in terms of coupling-based proofs; we primarily leverage the facts that approximate liftings can be composed and that we can couple together Laplace random variables at the expected privacy cost. 

\begin{thm}[Composition of Liftings \cite{bartheProvingDifferentialPrivacy2016}]\label{liftingcomposition}
    Let $A_1, B_2, A_2, B_2$ be distributions over $S_1, T_1, S_2, T_2$, respectively and let $R_1\subseteq S_1\times T_1$, $R_2\subseteq S_2\times T_2$ be relations. If $A_1 R_1^{\#\varepsilon_1}B_1$ is a valid lifting and we can construct $A_2R_2^{\#\varepsilon_2}B_2$ under the assumption that the predicate $A_1 R_1 B_1$ is true, then $A_2 R_2^{\#\varepsilon_1+\varepsilon_2}B_2$.
\end{thm}

Composition for liftings operates differently than in the standard analysis of differentially private composition. Each lifting should be thought of as generating a logical assertion: in particular, the assertion is that the relation being lifted holds (for example, one could assert that two distributions $A_1$ and $B_1$ are equal by constructing the lifting $A_1 (=)^{\#\varepsilon}B_1$). 
Composition proceeds if, \textit{assuming that the first relation holds}, a second, likely more complex, lifting can be constructed. If this is true, then theorem \ref{liftingcomposition} asserts that the second lifting can be shown to hold \textit{unconditionally}, simply with a additive penalty to the privacy cost (specifically, the privacy cost increases by the privacy cost of the first lifting). 


The Laplace mechanism can also be restated in terms of approximate liftings: 
\begin{prop}[Laplace Mechanism for Liftings \cite{bartheProvingDifferentialPrivacy2016}]
    If $X_1\sim\Lap(\mu_1, \frac{1}{\varepsilon})$ and $X_2\sim\Lap(\mu_2, \frac{1}{\varepsilon})$, then $X_1(=)^{\#\varepsilon|\mu_1-\mu_2|}X_2$.
\end{prop}


Theorems \ref{implicationcouplingthm} and \ref{liftingcomposition} suggest the form of coupling proofs for privacy: given two ``runs'' of an algorithm on adjacent inputs, construct many smaller liftings between program variables in each run and compose these liftings together to show that a final implicatory lifting between the outputs of the two runs exists. 

\subsection{Proving SVT with couplings}

For illustrative purposes, we provide a lifting-based proof of privacy for a notoriously tricky algorithm, the Sparse Vector Technique (SVT), which is particularly for requiring an analysis that goes beyond standard composition. 
At a high level, SVT takes in a possibly infinite stream of input queries and a threshold value and outputs whether or not the input queries are above or below the threshold; see algorithm 1 for a full definition. 

However, unusually for differentially private algorithms, SVT can output a potentially unbounded number of ``below threshold'' queries before the first $c$ ``above threshold''s (or vice-versa), where $c$ is some constant set by the user; when $c=1$, SVT is also referred to as ``Above (or Below) Threshold''.
 Potential applications include, for example, checking that a series of inputs is within an expected range or, as the name suggests, privately determining which elements of a sparse vector are non-zero. 

Because SVT allows for a potentially unbounded number of ``below threshold'' query outputs, its analysis requires a non-standard approach; a naive composition approach that assigns a fixed cost to outputting the result of each query will immediately result in unbounded overall privacy cost. 
Indeed, the analysis of SVT is notoriously difficult, with multiple published attempts at privacy proofs that were later shown to be incorrect\footnote{A textbook analysis of SVT, along with a discussion of bugged versions and incorrect privacy proofs, can be found at \cite{lyuUnderstandingSparseVector2016a}}. 

However, re-analyzing SVT using approximate liftings is relatively simple.

\begin{algorithm}
    \hspace*{\algorithmicindent}\textbf{Input}: $\mathcal{X}\in X^n$, $T\in \RR$, $Q=q_1, \ldots \in {(X^n\to \RR)}^*$ with sensitivity $\Delta$, $c\in \NN$.
    \begin{algorithmic}[1]
        \caption{Sparse Vector Technique}\label{couplingAlg}
        \State $\varepsilon_1, \varepsilon_2 \gets \frac{\varepsilon}{2},
        \rho \gets \Lap(\frac{\Delta}{\varepsilon_1})$, $count \gets 0$
		\For{$q_i \in Q$} 
			\State $z\gets \Lap(\frac{2c\Delta}{\varepsilon_2})$
            \If{$q_i(\mathcal{X}) + z \geq T + \rho$}
                \State\textbf{output} $\top$
                \State$count\gets count+1$
                \If{$count \geq c$}
                    \State$\textbf{break}$
                \EndIf
            \Else
                \State\textbf{output} $\bot$
            \EndIf
		\EndFor
    \end{algorithmic}
\end{algorithm}


\begin{thm}
    Sparse Vector Technique is $\varepsilon$-differentially private. 
\end{thm}

\begin{proof}[Proof (adapted from an informal proof of \cite{bartheProvingDifferentialPrivacy2016})]
    Consider two runs of SVT with adjacent inputs $\mathcal{X}\sim\mathcal{X}'$, respectively. We are aiming to show that $SVT(\mathcal{X}, T, Q, c)\{(a, b): a=\sigma \implies b=\sigma\}^{\#\varepsilon}SVT(\mathcal{X}', T, Q, c)$ is a valid lifting. 

    Fix some output $\sigma \in \{\bot, \top\}^n$. Let $A = \{i:\sigma_i = \top\}$ be the indices of queries that are measured to be above the threshold. Note that $|A| = c$. 
    
    For every program variable $x$, let $x\brangle{1}$ and $x\brangle{2}$ represent the value of $x$ in $SVT(\mathcal{X}, T, Q, c)$ and $SVT(\mathcal{X}', T, Q, c)$, respectively, so, for example, $q_i(\mathcal{X})\brangle{1} = q_i(\mathcal{X})$ and $q_i(\mathcal{X})\brangle{2} = q_i(\mathcal{X}')$. 

    Let $\tilde{T}=T + \rho$. Then $\tilde{T} \sim \Lap(T, \frac{\Delta}{\varepsilon_1})$, so the lifting $\tilde{T}\brangle{1} +\Delta (=)^{\#\varepsilon_1}\tilde{T}\brangle{2}$ exists. 

    Let $S_i = q_i(\mathcal{X}) + z_i$, so $S_i \sim\Lap(q_i(\mathcal{X}), \frac{2c\Delta}{\varepsilon_2})$.

    For all $i$ such that $0\leq i < n$, $i\notin A$, we construct the lifting $z_i\brangle{1} (=)^{\#0}z_i\brangle{2}$. 

    Then note that because $\tilde{T}\brangle{1}+\Delta = \tilde{T}\brangle{2}$ and $z_i\brangle{1} = z_i \brangle{2}$, we know that $S_i\brangle{1} < \tilde{T}\brangle{1} \implies S_i\brangle{2} < \tilde{T}\brangle{2}$. This means that for all such $i$, if the condition on line 4 is not satisfied in the first run, then it also is not satisfied in the second run.

    For all $i\in A$, create the lifting $z_i\brangle{1}(=)^{\#\frac{\varepsilon_2}{c}}z_i\brangle{2} - q_i(\mathcal{X})+q_i(\mathcal{X}')-\Delta$, or equivalently, \\$S_i\brangle{1} +\Delta (=)^{\#\frac{\varepsilon_2}{c}} S_i\brangle{2}$. Note that the lifting has cost $\frac{\varepsilon_2}{c}$ since $|q_i(\mathcal{X})-q_i(\mathcal{X}')|\leq \Delta$. Like before, this means that if the condition on line 4 is satisfied in the first run, it must also be satisfied in the second run. 

    Then again because $\tilde{T}\brangle{1} +\Delta = \tilde{T}\brangle{2}$, $S_i\brangle{1} \geq \tilde{T}\brangle{1} \implies S_i\brangle{2} \geq \tilde{T}\brangle{2}$

    Thus, for all $i$, $SVT(\mathcal{X}, T, Q, c)_i = \sigma_i \implies SVT(\mathcal{X}', T, Q, c)_i = \sigma_i$, so $SVT(\mathcal{X}, T, Q, c)\{(a, b): a=\sigma \implies b=\sigma\}^{\#\varepsilon_1+\varepsilon_2}SVT(\mathcal{X}', T, Q, c)$.

    By Theorem \ref{implicationcouplingthm}, SVT is $\varepsilon$-differentially private. 
\end{proof}
