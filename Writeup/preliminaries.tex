
\section{Differential Privacy}

Differential privacy is a mathematically robust approach to privacy; in brief, differential privacy ensures that it is unlikely for an adversary to distinguish between whether or not one person's data was used in a private algorithm. To do this, differentially private algorithms rely on randomization, especially through the addition of statistical noise.

More precisely then, for any output $\sigma$ of a private algorithm $A$, the probability of obtaining $\sigma$ for a dataset with some individual Alex is close (measured by a multiplicative factor) to the probability of obtaining $\sigma$ for the same dataset with Alex removed or Alex's data changed.

We will consider \textbf{datasets} $\mathcal{X}\in X^n$ of size $n$ where $X$ is the set of all possible individual data points.

We first define what it means for datasets to be ``similar'' to each other. 

\begin{defn}
    Two datasets $\mathcal{X}=(x_1, \ldots, x_n), \mathcal{X}'=(x'_1, \ldots, x'_n)\in X^n$ are \textbf{adjacent} (denoted by $\mathcal{X}\sim\mathcal{X}'$) if $|\{i: x_i\neq x'_i\}|\leq 1$\footnote{A common variant is to define adjacency by the removal or addition of an entry, rather than by the change of an entry}.
\end{defn}

We thus formalize privacy under this framework as follows.
\begin{defn}[Pure Differential Privacy]
    For some $\varepsilon>0$, a randomized algorithm $A$ is $\varepsilon$-differentially private if, for all pairs of adjacent datasets $X\sim X'$ and all events $E \subseteq \im(A)$, \[\PP[A(X) \in E]\leq e^\varepsilon \PP[A(X')\in E]\]
    If there exists some $\varepsilon>0$ such that $A$ is $\varepsilon$-differentially private, we call $A$ ``differentially private'' or simply ``private'' without reference to a specific $\varepsilon$.
\end{defn}

The privacy parameter $\varepsilon$ is traditionally thought of as analogous to the `privacy cost' of a program; the larger $\varepsilon$ is, the more privacy is ``lost''. In our analysis of differentially private algorithms, we thus aim to minimize the ``cost'' of an algorithm.

We call the problem of deciding whether or not an algorithm is differentially private the decision problem of privacy.

We also introduce the concept of max divergence as a convenient way to ``measure'' privacy cost.

\begin{defn}[Max Divergence]
    For any two probability distributions $P, Q$ over a shared event space $E$, the max-divergence of $P$ and $Q$ is 
    $D_{\infty}(P||Q) = \max_{e\in E}\ln\left(\frac{P(e)}{Q(e)}\right)$.
\end{defn}

It immediately follows from the definition that an algorithm $A$ is $\varepsilon$-DP if and only if for all adjacent inputs $X\sim X'$, $D_{\infty}(A(X)||A(X'))\leq \varepsilon$; thus, max-divergence is one way to represent the ``true'' or ``minimal'' privacy cost of an algorithm.

An extremely useful property of differential privacy is that differentially private programs can be \textbf{sequentially composed} with a linear degradation in privacy:

\begin{thm}[Standard Composition \cite{dworkrothmonograph}]
    If $A$ is $\varepsilon_1$-differentially private and, for all $\sigma$, $B(\sigma, \cdot)$ is $\varepsilon_2$-differentially private, then $B(A(X), X)$ is $\varepsilon_1+\varepsilon_2$-differentially private. 
\end{thm}

Composition therefore allows us to view privacy parameters $\varepsilon$ as a ``budget'' for privacy-leaking operations in a program. Many common differentially private algorithms are thus built out of well-known private components combined together, which also lend themselves to straightforward analyses. 

\subsection{Sensitivity and the Laplace Mechanism}

Because we are typically interested in analyzing \textit{functions} of a dataset (for example, the average age of a town), it is often useful to examine differential privacy through a similar model - instead of comparing two adjacent datasets $X\sim X'$, we compare \textbf{queries} $f(X)$ and $f(X')$. In this world, we care about the \textit{sensitivity} of functions: how much a function \textit{changes} when considering adjacent inputs. 
Specifically, the ($\ell_1$-)sensitivity of a function $f: X\to \RR$, often denoted $\Delta f$, is defined as $\Delta f = \max_{X\sim X'}||f(X)-f(X')||_1$.

If we know a function's sensitivity, we can easily make it differentially private through the use of the Laplace Mechanism.


Recall that the Laplace distribution $\Lap(\mu, b)$ with mean $\mu$ and spread parameter $b$ is the probability distribution with probability density function $f(x) = \frac{1}{2b}\exp(-\frac{|x-\mu|}{b})$. If $\mu =0$, we may abbreviate $\Lap(0, b)$ as $\Lap(b)$. 

The Laplace Mechanism, as expected, simply adds noise sampled from the Laplace distribution to a query result. In particular, the noise is dependent on the sensitivity of the input function; as expected, the higher the sensitivity of a function is, the more noise the Laplace mechanism will add to it.   

\begin{thm}[Theorem 3.6~\cite{dworkrothmonograph}]
    For a function $f$ with sensitivity $\Delta$, $A(X) = f(X) + \Lap(\frac{\Delta}{\varepsilon})$ is $\varepsilon$-differentially private. 
\end{thm}

We will eventually consider a program model where we are given a potentially infinite \textit{sequence} of real-valued query functions $q_0, q_1, \ldots$, each with sensitivity at most $\Delta$.

\section{Couplings and Liftings}

In this section we introduce approximate liftings, which are probabilistic tools that allow for the structured creation of proofs of differential privacy.

Approximate liftings are closely related to probabilistic couplings, which themselves are a commonly used tool in probabilistic analysis.

\begin{defn}[Couplings]
    A coupling between two distributions $A$ and $B$ is a joint distribution $C$ such that $\pi_1(C)=A$ and $\pi_2(C)=B$, where $\pi_1(C)$ and $\pi_2(C)$ are the first and second marginals of $C$, respectively. 
\end{defn}

In particular, couplings are useful when analyzing the relationship between two probablistic processes. [past literature on couplings]

A previous line of work has extended the concept of couplings to reason about privacy and private processes: \textbf{approximate liftings} \cite{BartheOlmedo2013,bartheKopfOlmedo2012ProbabilisticRelationalReasoningforDifferentialPriv,HsuThesis2017,BartheEtAl2016} allow us to apply couplings to the realm of differential privacy. 

\begin{defn}[$\varepsilon$-Lifting]
    Let $A_1, A_2$ be two sample spaces. We say a distribution $\mu_1$ on $A_1$ and $\mu_2$ on $A_2$ are related by the $\mathbf{\varepsilon}$\textbf{-lifting} of the relation $\Psi\subseteq A_1\times A_2$ (written $\mu_1(\Psi)^{\#\varepsilon}\mu_2$) if there exist two \textbf{witness distributions} $\mu_L, \mu_R$ on $A_1\times A_2$ such that\begin{enumerate}
        \item $\pi_1(\mu_L) = \mu_1$ and $\pi_2(\mu_R) = \mu_2$
        \item $\supp(\mu_L), \supp(\mu_R)\subseteq \Psi$
        \item $\sup_{E\subseteq A_1\times A_2}(\PP_{x\gets \mu_L}[x\in E]- e^\varepsilon \PP_{x\gets \mu_R}[x\in E])\leq 0$
    \end{enumerate}
\end{defn}

In some sense, approximate liftings can be considered ``half-couplings'', where ``half'' (the first marginal) of $\mu_L$ is coupled with ``half'' (the second marginal) of $\mu_R$. 

Because of the close relationship between couplings and approximate liftings, we will often use ``couplings'' to generically refer to both approximate liftings and couplings in the technical sense.

As expected, there is a close connection between approximate liftings and differential privacy: an algorithm being $\varepsilon$-differentially private is equivalent to the distributions of the algorithms given adjacent inputs being related by the $\varepsilon$-lifting of the equality relation.

\begin{thm}[\cite{BartheEtAl2016}]
    An algorithm $A(X)$ is $\varepsilon$-differentially private if and only if, for all adjacent inputs $X\sim X'$, $A(X)(=)^{\#\varepsilon}A(X')$.
\end{thm}

However, we will generally relax the lifted relation from equality to implication, which still allows us to prove that an algorithm is private:

\begin{thm}[\cite{BartheEtAl2016}]\label{implicationcouplingthm}
    If for all adjacent input sequences $X\sim X'$ and outputs $\sigma$ of $A$, $A(X)\{(a, b): a=\sigma\implies b=\sigma\}^{\#\varepsilon}A(X')$, then $A(X)$ is $\varepsilon-$differentially private.
\end{thm}

Almost every standard result about differential privacy can be restated in terms of couplings; for this paper, we will primarily rely on the fact that couplings can be composed and that we can couple together Laplace random variables. 

\begin{thm}[Composition of Liftings\cite{BartheEtAl2016}]\label{liftingcomposition}
    Let $A_1, B_2, A_2, B_2$ be distributions over $S_1, T_1, S_2, T_2$, respectively and let $R_1\subseteq S_1\times T_1$, $R_2\subseteq S_2\times T_2$ be relations. If $A_1 R_1^{\#\varepsilon_1}B_1$ is a valid lifting and we can construct $A_2R_2^{\#\varepsilon_2}B_2$ under the assumption that the predicate $A_1 R_1 B_1$ is true, then $A_2 R_2^{\#\varepsilon_1+\varepsilon_2}B_2$.
\end{thm}

\sky{Would an example here be useful?}

\begin{prop}[Laplace Mechanism for Liftings \cite{BartheEtAl2016}]
    If $X_1\sim\Lap(\mu_1, \frac{1}{\varepsilon})$ and $X_2\sim\Lap(\mu_2, \frac{1}{\varepsilon})$, then $X_1(=)^{\#\varepsilon|\mu_1-\mu_2|}X_2$.
\end{prop}


Theorems \ref{implicationcouplingthm} and \ref{liftingcomposition} suggest the form of coupling proofs for privacy: given two ``runs'' of an algorithm on adjacent inputs, construct many smaller liftings between program variables in each run and compose these liftings together to show that a final implicatory lifting between the outputs of the two runs exists. 

\subsection{Proving SVT with couplings}

For illustrative purposes, we provide a lifting-based proof of privacy for a notoriously tricky algorithm, the Sparse Vector Technique (SVT), which is particularly notable for requiring an analysis that goes beyond standard composition.

At a high level, SVT takes in a possibly infinite stream of input queries and a threshold value and outputs whether or not the input queries are above or below the threshold.

Unusually for differentially private algorithms, SVT can output a potentially unbounded number of ``below threshold'' queries before the first $c$ ``above threshold''s (or vice-versa), where $c$ is some constant set by the user; when $c=1$, SVT is also referred to as ``Above (or Below) Threshold''. Potential applications include, for example, checking that a series of inputs is within an expected range or, appropriately, privately determining which elements of a sparse vector are non-zero. 

Because SVT allows for a potentially unbounded number of ``below threshold'' query outputs, its analysis requires a non-standard approach; a naive composition approach that assigns a fixed cost to outputting the result of each query will immediately result in unbounded privacy cost as well. 
Indeed, the analysis of SVT is notoriously difficult, with multiple published attempts at privacy proofs that were later shown to be incorrect\footnote{A textbook analysis of SVT, along with a discussion of bugged versions and incorrect privacy proofs, can be found at \cite{10.14778/3055330.3055331}}. 

However, re-analyzing SVT using approximate liftings can be relatively simple. Our proof is derived from an informal proof of \cite{BartheEtAl2016}.

\begin{algorithm}
    \hspace*{\algorithmicindent}\textbf{Input}: $\mathcal{X}\in X^n$, $T\in \RR$, $Q=q_1, \ldots \in {(X^n\to \RR)}^*$ with sensitivity $\Delta$, $c\in \NN$.
    \begin{algorithmic}[1]
        \caption{Sparse Vector Technique}\label{couplingAlg}
        \State $\varepsilon_1, \varepsilon_2 \gets \frac{\varepsilon}{2},
        \rho \gets \Lap(\frac{\Delta}{\varepsilon_1})$, $count \gets 0$
		\For{$q_i \in Q$} 
			\State $z\gets \Lap(\frac{2c\Delta}{\varepsilon_2})$
            \If{$q_i(\mathcal{X}) + z \geq T + \rho$}
                \State\textbf{output} $\top$
                \State$count\gets count+1$
                \If{$count \geq c$}
                    \State$\textbf{break}$
                \EndIf
            \Else
                \State\textbf{output} $\bot$
            \EndIf
		\EndFor
    \end{algorithmic}
\end{algorithm}


\begin{thm}
    Sparse Vector Technique is $\varepsilon$-differentially private. 
\end{thm}

\begin{proof}
    Consider two runs of SVT with adjacent inputs $\mathcal{X}\sim\mathcal{X}'$, respectively. We are aiming to show that $SVT(\mathcal{X}, T, Q, c)\{(a, b): a=\sigma \implies b=\sigma\}^{\#\varepsilon}SVT(\mathcal{X}', T, Q, c)$ is a valid lifting. 

    Fix some output $\sigma \in \{\bot, \top\}^n$. Let $A = \{i:\sigma_i = \top\}$ be the indices of queries that are measured to be above the threshold. Note that $|A| = c$. 
    
    For every program variable $x$, let $x\brangle{1}$ and $x\brangle{2}$ represent the value of $x$ in $SVT(\mathcal{X}, T, Q, c)$ and $SVT(\mathcal{X}', T, Q, c)$, respectively, so, for example, $q_i(\mathcal{X})\brangle{1} = q_i(\mathcal{X})$ and $q_i(\mathcal{X})\brangle{2} = q_i(\mathcal{X}')$. 

    Let $\tilde{T}=T + \rho$. Then $\tilde{T} \sim \Lap(T, \frac{\Delta}{\varepsilon_1})$, so the lifting $\tilde{T}\brangle{1} +\Delta (=)^{\#\varepsilon_1}\tilde{T}\brangle{2}$ exists. 

    Let $S_i = q_i(\mathcal{X}) + z_i$, so $S_i \sim\Lap(q_i(\mathcal{X}), \frac{2c\Delta}{\varepsilon_2})$.

    For all $i$ such that $0\leq i < n$, $i\notin A$, we construct the lifting $z_i\brangle{1} (=)^{\#0}z_i\brangle{2}$. 

    Then note that because $\tilde{T}\brangle{1}+\Delta = \tilde{T}\brangle{2}$ and $z_i\brangle{1} = z_i \brangle{2}$, we know that $S_i\brangle{1} < \tilde{T}\brangle{1} \implies S_i\brangle{2} < \tilde{T}\brangle{2}$. This means that for all such $i$, if the condition on line 4 is not satisfied in the first run, then it also is not satisfied in the second run.

    For all $i\in A$, create the lifting $z_i\brangle{1}(=)^{\#\frac{\varepsilon_2}{c}}z_i\brangle{2} - q_i(\mathcal{X})+q_i(\mathcal{X}')-\Delta$, or equivalently, \\$S_i\brangle{1} +\Delta (=)^{\#\frac{\varepsilon_2}{c}} S_i\brangle{2}$. Note that the lifting has cost $\frac{\varepsilon_2}{c}$ since $|q_i(\mathcal{X})-q_i(\mathcal{X}')|\leq \Delta$. Like before, this means that if the condition on line 4 is satisfied in the first run, it must also be satisfied in the second run. 

    Then again because $\tilde{T}\brangle{1} +\Delta = \tilde{T}\brangle{2}$, $S_i\brangle{1} \geq \tilde{T}\brangle{1} \implies S_i\brangle{2} \geq \tilde{T}\brangle{2}$

    Thus, for all $i$, $SVT(\mathcal{X}, T, Q, c)_i = \sigma_i \implies SVT(\mathcal{X}', T, Q, c)_i = \sigma_i$, so $SVT(\mathcal{X}, T, Q, c)\{(a, b): a=\sigma \implies b=\sigma\}^{\#\varepsilon_1+\varepsilon_2}SVT(\mathcal{X}', T, Q, c)$.

    By Theorem \ref{implicationcouplingthm}, SVT is $\varepsilon$-differentially private. 
\end{proof}
