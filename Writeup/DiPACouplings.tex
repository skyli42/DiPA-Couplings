\documentclass[12pt]{article}

\usepackage[shortlabels]{enumitem} 
\usepackage{amsmath,amsfonts,amssymb,amsthm,bm,mathrsfs}
\usepackage{fancyhdr}
\usepackage[margin=1in]{geometry}
\usepackage{parskip}
\usepackage{tikz}
\usepackage{algorithm}
\usepackage{algpseudocode}
% \usepackage{mdframed}
\usepackage{hyperref}
\usepackage{xcolor, soul}
\sethlcolor{cyan}


\newcommand{\NN}{\mathbb{N}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\EE}{\mathbb{E}}
\newcommand{\notimplies}{\;\not\!\!\!\implies}
\newcommand{\gguard}[1][x]{\texttt{insample}\geq #1}
\newcommand{\lguard}[1][x]{\texttt{insample} < #1}
\newcommand{\gaguard}{n<N \text{ AND } \texttt{insample} \geq \texttt{x}}
\newcommand{\laguard}{n<N\text{ AND }\texttt{insample} < \texttt{x}}
\newcommand{\itgguard}{\texttt{input}\neq\tau \text{ AND } \texttt{insample} \geq \texttt{x}}
\newcommand{\itlguard}{\texttt{input}\neq\tau \text{ AND }\texttt{insample} < \texttt{x}}
\newcommand{\range}{\texttt{range}}
\newcommand{\brangle}[1]{\langle #1 \rangle}
\newcommand{\guard}{\texttt{guard}}
\newcommand{\trans}{\texttt{trans}}
\newcommand{\Lap}{\texttt{Lap}}
\newcommand{\gcycle}{\texttt{G}-cycle}
\newcommand{\lcycle}{\texttt{L}-cycle}
\newcommand{\sgn}{\texttt{sgn}}
\newcommand{\andtext}{\text{ AND }}
\newcommand{\ortext}{\text{ OR }}
\newcommand{\supp}{\texttt{supp}}

\newcommand{\im}{\texttt{im}}


\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\providecommand{\floor}[1]{ \lfloor #1 \rfloor }
\newtheorem{thm}{Theorem}[section]
\newtheorem{lemma}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}
\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\newtheorem{const}[thm]{Construction}
\newtheorem{examp}[thm]{Example}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{rmk}[thm]{Remark}
\newtheorem{clm}[thm]{Claim}

\newcommand{\isto}{\stackrel{\sim}{\smash{\longrightarrow}\rule{0pt}{0.4ex}}} 
\graphicspath{ {./} }
\bibliographystyle{plain} 


\begin{document}

\section{Introduction}

Differential privacy is a framework for privacy that gives rigorous guarantees on the amount of data leakage any one person's data can be subjected to when releasing statistical data. Since being introduced in 2006 \cite{DP2006}, differential privacy has become the gold standard for private statistical analysis. 
Differentially private algorithms, whose efficacy are characterized by a ``privacy cost'' $\varepsilon$, primarily rely on the addition of statistical noise, ensuring that statistical results remain approximately correct while preventing any one person's information from being revealed. 

Differentially private algorithms are notoriously tricky to analyze for correctness; most famously, the Sparse Vector Technique (SVT) algorithm has gone through multiple iterations, some of which were later shown to completely fail at protecting privacy\cite{10.14778/3055330.3055331}. Previous implementations of differential privacy by Apple have similarly been shown to have an increase from the claimed privacy cost by a factor of up to 16 \cite{appleleakprivacy}. 

Thus, much work has been done on developing methods for automatic verification of differentially private algorithms, both in their overall privacy and in the specific privacy costs they claim to achieve. 
Because even for limited programs the problem of determining if a program is differentially private is undecidable\cite{barthe.etal2020decidingdp}, previous work tends to focus on semi-decidability or further restricting program models. 

Recently, a line of work has emerged around \textbf{approximate liftings} \cite{BartheEtAl2016,bartheKopfOlmedo2012ProbabilisticRelationalReasoningforDifferentialPriv,BartheOlmedo2013,HsuThesis2017}. Approximate liftings are a generalization of probabilistic couplings, themselves a well-known technique in probability theory for analyzing relationships between random variables. 
Approximate liftings allow for a more structured proof approach to many algorithms that themselves are not conducive to a standard compositional analysis, such as SVT. Because of their structure, liftings also lend themselves to automated proof construction~\cite{AlbarghouthiHsu2018}. 

We first rewrite the major results of approximate liftings in \{not program logic\}\footnote{not sure how to describe this, also not sure if worth mentioning}. 
We then use approximate liftings to demonstrate that a certain limited class of programs, first described in \cite{chadhaLinearTimeDecidability2021}, are differentially private; interestingly, we show that our class of liftings completely characterizes this class of programs. Additionally, we demonstrate that the privacy of a natural generalization of this class of programs can be proven using liftings and almost immediately follows from the privacy of the smaller class. 

\section{Differential Privacy}

Differential privacy is a mathematically robust approach to privacy; most generally, differential privacy ensures that it is unlikely for an adversary to distinguish between whether or not one person's data was used in a private algorithm. To do this, differentially private algorithms rely on randomization, especially through the addition of statistical noise.

More precisely then, for a fixed output $\sigma$ of a private algorithm $A$, the probability of obtaining $\sigma$ for a dataset with some individual Alex is close (measured by a multiplicative factor) to the probability of obtaining $\sigma$ for the same dataset with Alex removed or Alex's data changed.

We will consider \textbf{datasets} $\mathcal{X}\in X^n$ of size $n$, where $X$ is the set of all possible rows in the dataset; each person is represented by a single row. 

We next define what it means for datasets to be ``similar'' to each other. 

\begin{defn}
    Two datasets $\mathcal{X}=(x_1, \ldots, x_n), \mathcal{X}'=(x'_1, \ldots, x'_n)\in X^n$ are \textbf{adjacent} (notated $\mathcal{X}\sim\mathcal{X}'$) if $|\{i: x_i\neq x'_i\}|\leq 1$\footnote{A common variant is to define adjacency by the removal or addition of an entry, rather than changing one}.
\end{defn}

We thus formalize privacy under this framework as follows.
\begin{defn}[Pure Differential Privacy]
    A randomized algorithm $A$ is $\varepsilon$-differentially private if, for all pairs of \textbf{adjacent} datasets $X$ and $X'$ and all events $E \subseteq \im(A)$, \[\PP[A(X) \in E]\leq e^\varepsilon \PP[A(X')\in E]\]
\end{defn}


An extremely useful property of differential privacy is that differentially private programs can be \textbf{sequentially composed} with a linear degradation in privacy:

\begin{thm}[Standard Composition]
    If $A$ is $\varepsilon_1$-differentially private and, for all $\sigma$, $B(\sigma, \cdot)$ is $\varepsilon_2$-differentially private, then $B(A(X), X)$ is $\varepsilon_1+\varepsilon_2$-differentially private. 
\end{thm}

Composition therefore allows us to view privacy parameters $\varepsilon$ as a ``budget'' for privacy-leaking operations in a program. Many\footnote{generic platitude - reword} common differentially private algorithms are thus built out of well-known private components combined together, which also lend themselves to straightforward analyses. 

\subsection{Sensitivity and the Laplace Mechanism}

Because we are typically interested in analyzing \textit{functions} of our raw dataset (for example, the average age of a town), it is often useful to examine differential privacy through a similar model - instead of comparing two adjacent datasets $X\sim X'$, we compare \textbf{queries} $f(X)$ and $f(X')$. In this world, we care about the \textit{sensitivity} of functions: how much a function \textit{changes} when considering adjacent inputs.  

\begin{defn}
    The ($\ell_1$-)sensitivity of a function $f: X\to \RR$, often denoted $\Delta f$, is defined as $\Delta f = \max_{X\sim X'}||f(X)-f(X')||_1$.
\end{defn}

Given a function's sensitivity, we can easily make it differentially private through the use of the \textbf{Laplace Mechanism}.

\begin{defn}
    The Laplace distribution $\Lap(\mu, b)$ with mean $\mu$ and spread parameter $b$ is the probability distribution with probability density function $f(x) = \frac{1}{2b}\exp(-\frac{|x-\mu|}{b})$. If $\mu =0$, we will often abbreviate $\Lap(0, b)$ as $\Lap(b)$. 
\end{defn}

The Laplace Mechanism, as expected, simply adds noise sampled from the Laplace distribution to a query result. 

\begin{thm}[Theorem 3.6~\cite{dworkrothmonograph}]
    For a function $f$ with sensitivity $\Delta$, $A(X) = f(X) + \Lap(\frac{\Delta}{\varepsilon})$ is $\varepsilon$-differentially private. 
\end{thm}

We will consider the scenario where we are given a potentially infinite \textit{sequence} of real-valued query functions $q_0, q_1, \ldots$, each with sensitivity at most $\Delta$.

\subsection{Deciding Privacy}

Because designing differentially private algorithms can be quite tricky, we would like to be able to automatically (i.e. algorithmically) verify whether or not a given program is private, especially for algorithms whose privacy proofs do not rely primarily on composition. 
Ideally, beyond just determining whether a program is private or not, if a program is private, we'd like to find a good bound on the privacy cost for the program as well. 

Unfortunately, even for relatively simple programs, just the basic problem is undecidable. 

\begin{thm}[\cite{barthe.etal2020decidingdp}]
    The problem of determining whether a program from a certain class of algorithms with assignments, conditionals, and while loops is $\varepsilon$-differentially private is undecidable\footnote{rephrase?}.
\end{thm}

Thus, we will derive a decision procedure for a very specific class of potentially private programs; in particular, this class of programs lends itself to a straightforward analysis by \textbf{approximate liftings}, which we now introduce. 

\section{Couplings and Liftings}

Probabilistic couplings are a common tool in probability theory; intuitively, couplings allow for the joint analysis of nominally unrelated probabilistic processes. 

\begin{defn}
    A coupling between two distributions $A$ and $B$ is a joint distribution $C$ such that $\pi_1(C)=A$ and $\pi_2(C)=B$, where $\pi_1(C)$ and $\pi_2(C)$ are the first and second marginals of $C$, respectively. 
\end{defn}

In particular, couplings can be useful when analyzing the relation between two probablistic processes; couplings were first formulated by [check name] to analyze the behaviour of markov chains and have close connections to concepts such as total variation distance and stochastic domination. 

As useful as standard couplings are, however, we must use more powerful machinery to properly reason about privacy.

\textbf{Approximate liftings} \cite{BartheOlmedo2013,bartheKopfOlmedo2012ProbabilisticRelationalReasoningforDifferentialPriv,HsuThesis2017,BartheEtAl2016} allow us to apply couplings to the realm of differential privacy. 

\begin{defn}
    Let $A_1, A_2$ be two probability spaces\footnote{may need to formally rewrite this at some point}. We say a distribution $\mu_1$ on $A_1$ and $\mu_2$ on $A_2$ are related by the $\mathbf{\varepsilon}$\textbf{-lifting} of the relation $\Psi\subseteq A_1\times A_2$ (written $\mu_1\Psi^{\#\varepsilon}\mu_2$) if there exist two \textbf{witness distributions} $\mu_L, \mu_R$ on $A_1\times A_2$ such that\begin{enumerate}
        \item $\pi_1(\mu_L) = \mu_1$ and $\pi_2(\mu_R) = \mu_2$
        \item $\supp(\mu_L), \supp(\mu_R)\subseteq \Psi$
        \item $\sup_{E\subseteq A_1\times A_2}(\PP_{x\gets \mu_L}[x\in E]- e^\varepsilon \PP_{x\gets \mu_R}[x\in E])\leq 0$
    \end{enumerate}
\end{defn}

The similarities between the third condition and the definition of differential privacy should be clear. Indeed, there is a close connection between approximate liftings and differential privacy:

\begin{thm}
    An algorithm $A(X)$ is $\varepsilon$-differentially private if and only if, for all adjacent input sequences $X\sim X'$, $A(X)(=)^{\#\varepsilon}A(X')$.
\end{thm}

If we are solely aiming to show that a program is private, we can instead work with the following relaxation: 

\begin{thm}\label{implicationcouplingthm}
    If for all adjacent input sequences $X\sim X'$ and outputs $\sigma$ of $A$, $A(X)\{(a, b): a=\sigma\implies b=\sigma\}^{\#\varepsilon}A(X')$, then $A(X)$ is $\varepsilon-$differentially private.
\end{thm}

As expected, the foundational results of differential privacy can be restated in terms of liftings:

\begin{prop}[Laplace Mechanism for Liftings]
    If $X_1\sim\Lap(\mu_1, \frac{1}{\varepsilon})$ and $X_2\sim\Lap(\mu_2, \frac{1}{\varepsilon})$, then $X_1(=)^{\#\varepsilon|\mu_1-\mu_2|}X_2$.
\end{prop}

\begin{thm}[Composition of Liftings]\label{liftingcomposition}
    Let $A_1, B_2, A_2, B_2$ be distributions over $S_1, T_1, S_2, T_2$, respectively and let $R_1\subseteq S_1\times T_1$, $R_2\subseteq S_2\times T_2$ be relations. If $A_1 R_1^{\#\varepsilon_1}B_1$ and $A_1 R_1 B_1\implies A_2R_2^{\#\varepsilon_2}B_2$, then $A_2 R_2^{\#\varepsilon_1+\varepsilon_2}B_2$.
\end{thm}

The structure of theorems \ref{implicationcouplingthm} and \ref{liftingcomposition} suggests the format that coupling proofs of privacy take: given two ``runs'' of an algorithm on adjacent inputs, construct many smaller liftings between program variables in each run and compose these liftings together to show that a final implicatory lifting between the outputs of the two runs exists. 

\subsection{Proving SVT with couplings}

A classic algorithm that requires analysis beyond standard composition is Sparse Vector Technique (SVT). Given a possibly infinite stream of inputs and a threshold value, SVT will output if the queries are above or below the threshold (with noise on both the query and the threshold). 

Unusually for differentially private algorithms, SVT can output a potentially unbounded number of ``below threshold'' queries before the first $c$ ``above threshold''s (or vice-versa), where $c$ is some constant set by the user; when $c=1$, SVT is frequently also referred to as ``Above (or Below) Threshold''. Potential applications include, for example, checking that a series of inputs is within an expected range or, appropriately, privately determining the non-zero elements of a sparse vector. 

Because SVT allows for a potentially unbounded number of ``below threshold'' query outputs, its analysis requires a non-standard approach; a naive composition approach that assigns a fixed cost to outputting the result of each query will immediately result in unbounded privacy cost as well. 
Indeed, the analysis of SVT is notoriously difficult, with multiple published attempts at privacy proofs that were later shown to be incorrect\footnote{A textbook analysis of SVT, along with a discussion of bugged versions and incorrect privacy proofs, can be found at \cite{10.14778/3055330.3055331}}. 

However, re-analyzing SVT using approximate liftings can be relatively simple. 

\begin{algorithm}
    \hspace*{\algorithmicindent}\textbf{Input}: $\mathcal{X}\in X^n$, $T\in \RR$, $Q=q_1, \ldots \in {(X^n\to \RR)}^*$ with sensitivity $\Delta$, $c\in \NN$.
    \begin{algorithmic}[1]
        \caption{Sparse Vector Technique}\label{couplingAlg}
        \State $\varepsilon_1, \varepsilon_2 \gets \frac{\varepsilon}{2},
        \rho \gets \Lap(\frac{\Delta}{\varepsilon_1})$, $count \gets 0$
		\For{$q_i \in Q$} 
			\State $z\gets \Lap(\frac{2c\Delta}{\varepsilon_2})$
            \If{$q_i(\mathcal{X}) + z \geq T + \rho$}
                \State\textbf{output} $\top$
                \State$count\gets count+1$
                \If{$count \geq c$}
                    \State$\textbf{break}$
                \EndIf
            \Else
                \State\textbf{output} $\bot$
            \EndIf
		\EndFor
    \end{algorithmic}
\end{algorithm}


\begin{thm}
    Sparse Vector Technique is $\varepsilon$-differentially private. 
\end{thm}

\begin{proof}
    Consider two runs of SVT with adjacent inputs $\mathcal{X}\sim\mathcal{X}'$, respectively. We are aiming to show that $SVT(\mathcal{X}, T, Q, c)\{(a, b): a=\sigma \implies b=\sigma\}^{\#\varepsilon}SVT(\mathcal{X}', T, Q, c)$ is a valid lifting. 

    Fix some output $\sigma \in \{\bot, \top\}^n$. Let $A = \{i:\sigma_i = \top\}$ be the indices of queries that are measured to be above the threshold. Note that $|A| = c$. 
    
    For every program variable $x$, let $x\brangle{1}$ and $x\brangle{2}$ represent the value of $x$ in $SVT(\mathcal{X}, T, Q, c)$ and $SVT(\mathcal{X}', T, Q, c)$, respectively, so, for example, $q_i(\mathcal{X})\brangle{1} = q_i(\mathcal{X})$ and $q_i(\mathcal{X})\brangle{2} = q_i(\mathcal{X}')$. 

    Let $\tilde{T}=T + \rho$. Then $\tilde{T} \sim \Lap(T, \frac{\Delta}{\varepsilon_1})$, so $\tilde{T}\brangle{1} +\Delta (=)^{\#\varepsilon_1}\tilde{T}\brangle{2}$. 

    Let $S_i = q_i(\mathcal{X}) + z_i$, so $S_i \sim\Lap(q_i(\mathcal{X}), \frac{2c\Delta}{\varepsilon_2})$.

    For all $i$ such that $0\leq i < n$, $i\notin A$, we construct the lifting $z_i\langle 1\rangle (=)^{\#0}z_i\langle 2\rangle$. 

    Then note that $\tilde{T}\brangle{1}+\Delta = \tilde{T}\brangle{2}\land z_i\brangle{1} = z_i \brangle{2} \implies (S_i\brangle{1} < \tilde{T}\brangle{1} \implies S_i\brangle{2} < \tilde{T}\brangle{2} )$.

    For all $i\in A$, create the lifting $z_i\brangle{1}(=)^{\#\frac{\varepsilon_2}{c}}z_i\brangle{2} - q_i(\mathcal{X})+q_i(\mathcal{X}')-\Delta$, or equivalently, \\$S_i\brangle{1} +\Delta (=)^{\#\frac{\varepsilon_2}{c}} S_i\brangle{2}$. Note that this costs $\frac{\varepsilon_2}{c}$ since $|q_i(\mathcal{X})-q_i(\mathcal{X}')|\leq \Delta$.

    Then \[\tilde{T}\brangle{1} +\Delta = \tilde{T}\brangle{2} \land S_i\brangle{1} + \Delta = S_i\brangle{2} \implies (S_i\brangle{1} \geq \tilde{T}\brangle{1} \implies S_i\langle 2\rangle \geq \tilde{T}\brangle{2})\]

    Thus, for all $i$, $SVT(\mathcal{X}, T, Q, c)_i = \sigma_i \implies SVT(\mathcal{X}', T, Q, c)_i = \sigma_i$, so $SVT(\mathcal{X}, T, Q, c)\{(a, b): a=\sigma \implies b=\sigma\}^{\#\varepsilon_1+\varepsilon_2}SVT(\mathcal{X}', T, Q, c)$.

    By Theorem \ref{implicationcouplingthm}, SVT is $\varepsilon$-differentially private. 
\end{proof}

\section{Automatically Proving Privacy using Couplings}

We begin by building up a program model for SVT-style algorithms. There are three major components of SVT: taking in a threshold value and adding Laplace noise to it, taking in input and adding Laplace noise to it, and comparing the noisy threshold to the noisy input. 

\subsection{Individual Transitions}
We will model programs as finite state automata, with each state of the automaton representing a possible program state. Under this paradigm, we begin with the simplest possible program: a single transition between two program states. 

\begin{defn}[Transitions]
    Let $\mathcal{C}=\{\texttt{true}, \lguard[\texttt{x}], \gguard[\texttt{x}]\}$ be a set of \textbf{transition guards}. Let $Q$ be a set of states with each state $q\in Q$ having an associated real value for a variable $\texttt{x}$. Additionally, let $P(q): Q\to \RR^{\geq 0}\times \RR^{\geq 0}$ be a function that associates each state state with two \textbf{noise parameters} $P(q) = (d_q, d_q')$. Finally, let $\Gamma$ be a finite alphabet of \textbf{output symbols}. 

    Then given two states $q, q'\in Q$, a \textbf{transition} from $q$ to $q'$ is defined as the tuple $t = (q, q', c, \sigma,\tau)$ where $c\in \mathcal{C}$, $\sigma\in \Gamma\cup\{\texttt{insample}, \texttt{insample}'\}$, and $\tau$ is a boolean value denoting whether or not the stored value of $\texttt{x}$ will be updated. At all times, we will assume that there exists most one transition from $q\in Q$ to $q'\in Q$. 
\end{defn}

\begin{defn}[Taking a transition]
    Fix some $\varepsilon>0$, which we will treat as a program parameter.

    Consider some program state $q\in Q$ with noise parameters $P(q) = (d_q, d_q')$. Let $z\sim \Lap(0, \frac{1}{d_q\varepsilon})$ and $z'\sim\Lap(0, \frac{1}{d_q'\varepsilon})$ be independent random noises sampled from Laplace distributions with spread parameters $\frac{1}{d_q\varepsilon}$ and $\frac{1}{d_q'\varepsilon}$, respectively.

    For a state $q\in Q$ and input value $\texttt{in}\in \RR$ read at $q$, let $\texttt{insample} = \texttt{in}+z$ and $\texttt{insample}' = \texttt{in}+z'$ be noisy versions of the input read at $q$. 

    Let $\sigma\in \Gamma\cup\{(\texttt{insample}, a, b), (\texttt{insample}', a, b)\}$ be a potential output of a transition. For measurability reasons, note that we must associate real-valued outputs with an interval $(a, b)$. Intuitively, $\sigma = (\texttt{insample}, a, b)$ represents the possibility that $\texttt{insample}$ was output with a value in the interval $(a, b)$. 

    Then given a initial value $x_q\in \RR$ for $\texttt{x}$, a possible transition $t=(q, q', c, \sigma, \tau)$ from $q$ to another state $q'\in Q$ is \textbf{taken} if $c$ is true and, if $\sigma\in \{(\texttt{insample}, a, b), (\texttt{insample}', a', b')\}$, $t$ outputs $\texttt{insample}$ or $\texttt{insample}'$ as appropriate with a value in the interval $(a, b)$ or $(a', b')$, respectively. 
\end{defn}

In general, we will assume that at all states $q$, $x_q$ has been sampled from some Laplace distribution $\Lap(\hat{\mu_q}, \frac{1}{\hat{d_{q}}\varepsilon})$, where $\hat{d_{q}}$ is the spread parameter for $\texttt{insample}$ at some previous state. 

\subsection{Privacy}

\begin{defn}[Transition probabilities]
    Consider a single transition $t=(q, q', c, \sigma, \tau)$ from state $q\in Q$ to $q'\in Q$. Additionally, let $x_q\sim \Lap(\hat{\mu_q}, \frac{1}{\hat{d_q}\varepsilon})$ be the initial stored value of $\texttt{x}$ at $q$. 

    Let $\sigma_0$ be a \textit{potential} output of $t$. In particular, if $\sigma\in \{\texttt{insample}, \texttt{insample}'\}$, then let $\sigma_0 = (\texttt{insample}, a, b)$ or $\sigma_0 = (\texttt{insample}', a', b')$ as appropriate. Otherwise, $\sigma_0 = \sigma\in \Gamma$. 
    
    Then let $(u, v), (u', v')\in \RR_{\infty}$ be defined as follows:
    \begin{align*}
        (u, v) &= \begin{cases}
        (-\infty, \infty) & c=\texttt{true}\land \sigma_0 \neq (\texttt{insample}, a, b)\\
        (a, b) &c=\texttt{true}\land \sigma_0 = (\texttt{insample}, a, b)\\
        (-\infty, \texttt{x}_0) & a=\lguard\land \sigma_0 \neq (\texttt{insample}, a, b)\\
        (a, \min(\texttt{x}_0, b)) &c=\lguard\land \sigma_0 = (\texttt{insample}, a, b)\\
        (\texttt{x}_0, \infty) & c=\gguard\land \sigma_0 \neq (\texttt{insample}, a, b)\\
        (\max(\texttt{x}_0, a),b) &c=\gguard\land \sigma_0 = (\texttt{insample}, a, b)\\
    \end{cases}\\
    (u', v')& = (a', b')\end{align*}

    Then, given an input $\texttt{in}$ at $q$, the \textbf{probability} that $t$ is taken with output $\sigma_0$ is defined as \[
        \PP[x_q, t, \texttt{in}, \sigma_0] = \begin{cases}
            \int_u^v \Lap_{\texttt{in}, \frac{1}{d_q\varepsilon}}(z)dz & \sigma_0 \neq (\texttt{insample}', a', b') \\
            \int_{u'}^{v'}\Lap_{\texttt{in}, \frac{1}{d'_q\varepsilon}}(z')dz'\int_u^v \Lap_{\texttt{in}, \frac{1}{d_q\varepsilon}}(z)dz& \sigma_0 = (\texttt{insample}', a', b')
        \end{cases}
    \]
    where $\Lap_{\mu, s}(x)$ is the PDF of a Laplace distribution with mean $\mu$ and spread parameter $s$.
\end{defn}


Recall that $\texttt{in}$, in reality, represents a \textbf{function} of some underlying dataset. This means that `closeness' in this context is defined as follows:

\begin{defn}[Adjacency]
    Two inputs $\texttt{in}\sim_{\Delta} \texttt{in}'$ are $\Delta$-adjacent if $|\texttt{in}-\texttt{in}'|\leq \Delta$. If $\Delta$ is not specified, we assume that $\Delta = 1$. 
\end{defn}

We can now define what it means  to be \textbf{differentially private}.

\begin{defn}[$d\varepsilon$-differential privacy for a transition]
    Given two initial values $x_q, x_q'$, a transition $t=(q, q', c, \sigma, \tau)$ is \textbf{$d\varepsilon$-differentially private} for some $d>0$ if $\forall \varepsilon> 0$, for all adjacent inputs $\texttt{in}\sim \texttt{in}'$ and possible outputs $\sigma\in \Gamma\cup\{(\texttt{insample}, a, b), (\texttt{insample}', a', b')\}$, $\PP[x_q, t, \texttt{in}, \sigma]\leq e^{d\varepsilon}\PP[x_q', t, \texttt{in}', \sigma]$. 

    Recall that $x_q$ and $x_q'$ are treated as random variables drawn from a Laplace distribution. 
\end{defn}

Note that we slightly redefine $\varepsilon$-differential privacy as $d\varepsilon$-differential privacy, treating $\varepsilon$ as a universal scaling parameter that can be fine-tuned by users for their own purposes. 
In particular, we argue that this definition is functionally equivalent\footnote{\cite{chadhaLinearTimeDecidability2021} notes that it is not entirely clear how this differs from standard differential privacy, but that the known decidability result does not apply here - {\color{red} maybe something to investigate}}, since if we are targeting $\varepsilon^*$-differential privacy, we can always take $\varepsilon = \frac{\varepsilon^*}{d}$.

\subsubsection{Couplings}

For every transition $t$ between two states $q$ and $q'$, we can show that $t$ is differentially private using a series of liftings. 

\begin{lemma}\label{indTransitionCoupling}
    Suppose that $x_q\brangle{1}\sim \Lap(\hat{\mu_q}\brangle{1}, \frac{1}{\hat{d_q}\varepsilon}), x_q\brangle{2}\sim\Lap(\hat{\mu_q}\brangle{2}, \frac{1}{\hat{d_q}\varepsilon})$ are two initial values of $\texttt{x}$ at state $q\in Q$. 

    Consider some transition $t = (q, q', c, \sigma, \tau)$ from $q$ to $q'\in Q$. Let $P(q) = (d_q, d_q')$.

    Let $\texttt{in}\brangle{1}\sim \texttt{in}\brangle{2}$ be arbitrary and let $\sigma\brangle{1}$, $\sigma\brangle{2}$ be random variables representing possible outputs of $t$ given inputs $\texttt{in}\brangle{1}$ and $\texttt{in}\brangle{2}$, respectively. 

    Then $\forall \varepsilon>0$ and for all $\gamma_x, \gamma_q, \gamma_q'\in [-1, 1]$ that satisfy the constraints \[
        \begin{cases}
          \gamma_q\leq\gamma_x & c = \lguard[\texttt{x}]\\
          \gamma_q\geq\gamma_x & c = \gguard[\texttt{x}]\\
          \gamma_q=0 & \sigma = \texttt{insample}\\
          \gamma_q'=0 & \sigma = \texttt{insample}'
        \end{cases},
      \]
      the lifting $\sigma\brangle{1}\{(a, b): a=\sigma\implies b=\sigma\}^{\#d\varepsilon}\sigma\brangle{2}$ is valid for $d = (|\hat{\mu_q}\brangle{1}-\hat{\mu_q}\brangle{2}+\gamma_x|)\hat{d_q}+(|-\texttt{in}\brangle{1}+\texttt{in}\brangle{2}-\gamma_q|)d_q+(|-\texttt{in}\brangle{1}+\texttt{in}\brangle{2}-\gamma_q'|)d_q'$, and therefore $t$ is $d\varepsilon$-differentially private. 
\end{lemma}

\begin{proof}
Fix $\varepsilon>0$.

We will analyze the behaviour of two different \textbf{runs} of $t$, one with input $\texttt{in}$ and one with input $\texttt{in}'$. 

At a high level, for every Laplace-distributed variable, we will couple the value of the variable in one run with its value in the other \textbf{shifted} by some amount. 

We differentiate between the values of variables in the first and second run by using angle brackets $\brangle{k}$, so, for example, we will take $x_q\brangle{1}$ to be the value of $\texttt{x}$ at state $q$ in the run of $t$ with input $\texttt{in}\brangle{1}$ and $x_q\brangle{2}$ to be the value of $\texttt{x}$ in the run of $t$ with input $\texttt{in}\brangle{2}$. 

We thus want to create the lifting $\sigma\brangle{1}\{(a, b): a=\sigma\implies b=\sigma\}\sigma\brangle{2}$. We must guarantee two things: that if the first transition is taken, then the second is also taken and that both runs output the same value $\sigma$ when taking the transition. Note that if $c = \texttt{true}$, the first condition is trivially satisfied and when $\sigma\in \Gamma$, the second condition is trivially satisfied. 



Recall that that $x_q$ is sampled from a Laplace distribution, so $x_q\brangle{1}\sim \Lap(\hat{\mu_q}\brangle{1}, \frac{1}{\hat{d_q}\varepsilon})$ and $x_q\brangle{1}\sim \Lap(\hat{\mu_q}\brangle{2}, \frac{1}{\hat{d_q}\varepsilon})$.

Then we can first create the lifting $x_q\brangle{1}+\gamma_x (=)^{\#(|\hat{\mu_q}\brangle{1}-\hat{\mu_q}\brangle{2}+\gamma_x|)\hat{d_q}\varepsilon}x_q\brangle{2}$.

Additionally, create the lifting $z\brangle{1} (=)^{\#(|-\texttt{in}\brangle{1}+\texttt{in}\brangle{2}-\gamma_q|)d_q\varepsilon}z\brangle{2} - \texttt{in}\brangle{1}+\texttt{in}\brangle{2}-\gamma_q$. 

This is equivalent to creating the lifting $\texttt{insample}\brangle{1} +\gamma_q{(=)}^{\#(|-\texttt{in}\brangle{1}+\texttt{in}\brangle{2}-\gamma_q|)d_q\varepsilon}\texttt{insample}\brangle{2}$.

Finally, create the lifting $z'\brangle{1} (=)^{\#(|-\texttt{in}\brangle{1}+\texttt{in}\brangle{2}-\gamma_q'|)d_q'\varepsilon}z'\brangle{2} - \texttt{in}\brangle{1}+\texttt{in}\brangle{2}-\gamma_q'$. As before, this is equivalent to creating the lifting $\texttt{insample}'\brangle{1} +\gamma_q'{(=)}^{\#(|-\texttt{in}\brangle{1}+\texttt{in}\brangle{2}-\gamma_q'|)d_q'\varepsilon}\texttt{insample}'\brangle{2}$.

If $c=\lguard[\texttt{x}]$ and $\gamma_q\leq \gamma_x$, then \begin{align*}
    \texttt{insample}\brangle{1}<x_q\brangle{1}&\implies \texttt{in}\brangle{1}+z\brangle{1}<x_q\brangle{1}\\
    &\implies \texttt{in}\brangle{1}+z\brangle{2}-\texttt{in}\brangle{1}+\texttt{in}\brangle{2}+\gamma_q<x_q\brangle{2}-\gamma_x\\
    &\implies \texttt{insample}\brangle{2}<x_q\brangle{2}
\end{align*}

Similarly, if $c=\gguard[\texttt{x}]$ and $\gamma_q\geq \gamma_x$, then \begin{align*}
    \texttt{insample}\brangle{1}\geq x_q\brangle{1}&\implies \texttt{in}\brangle{1}+z\brangle{1}\geq x_q\brangle{1}\\
    &\implies \texttt{in}\brangle{1}+z\brangle{2}-\texttt{in}\brangle{1}+\texttt{in}\brangle{2}+\gamma_q\geq x_q\brangle{2}-\gamma_x\\
    &\implies \texttt{insample}\brangle{2}\geq x_q\brangle{2}
\end{align*}

With these liftings, we have ensured that if the first run takes transition $t$, then the second run does as well. 

Now, if $t$ outputs $\texttt{insample}$ and $\gamma_q=0$, then clearly we have that $\texttt{insample}\brangle{1}=\texttt{insample}\brangle{2}$, so $\sigma\brangle{1} = (\texttt{insample}, a, b)\implies \sigma\brangle{2}=(\texttt{insample}, a, b)$.

Similarly, if $\gamma_q'=0$, we have that $\sigma\brangle{1} = (\texttt{insample}', a, b)\implies \sigma\brangle{2}=(\texttt{insample}', a, b)$. 

Thus, if $t$ outputs a real number in the interval $(a, b)$ in the first run, it must also output a real number in the same interval in the second run. 

Thus, given the constraints \[
  \begin{cases}
    \gamma_q\leq\gamma_x & c = \lguard[\texttt{x}]\\
    \gamma_q\geq\gamma_x & c = \gguard[\texttt{x}]\\
    \gamma_q=0 & \sigma = \texttt{insample}\\
    \gamma_q'=0 & \sigma = \texttt{insample}'
  \end{cases},
\]
this is sufficient to create the lifting $\sigma\brangle{1}\{(a, b): a=\sigma\implies b=\sigma\}^{\#d\varepsilon}\sigma\brangle{2}$, where the cost $d = (|\hat{\mu_q}\brangle{1}-\hat{\mu_q}\brangle{2}+\gamma_x|)\hat{d_q}+(|-\texttt{in}\brangle{1}+\texttt{in}\brangle{2}-\gamma_q|)d_q+(|-\texttt{in}\brangle{1}+\texttt{in}\brangle{2}-\gamma_q'|)d_q'$. 

By an application of theorem \ref{implicationcouplingthm}, $\PP[x_q\brangle{1}, t, \texttt{in}\brangle{1}, \sigma]\leq e^{d\varepsilon}\PP[x_q\brangle{2}, t, \texttt{in}\brangle{2}, \sigma]$. Because $\texttt{in}\brangle{1}\sim\texttt{in}\brangle{2}$ are arbitrary adjacent inputs and $\sigma$ is an arbitrary possible output of $t$, this implies that $t$ is $d\varepsilon$-differentially private. 
\end{proof}

We can thus think of couplings for a transition as being parameterized by $\gamma_x$, $\gamma_q$, and $\gamma_q$. 

\begin{defn}[Coupling strategies for a transition]
    A \textbf{coupling strategy} for a transition $t_i = (q_i, q_{i+1}, c_i, \sigma_i, \tau_i)$ is a tuple $C_i = (\gamma_x^{(i)}, \gamma_i, \gamma_i')\in [-1, 1]^3$. 
\end{defn}

\begin{defn}[Validity of a coupling strategy]
    A coupling strategy $C_i =(\gamma_x^{(i)}, \gamma_i, \gamma_i')$ for a transition $t_i$ is \textbf{valid} if the constraints \[
        \begin{cases}
          \gamma_i\leq\gamma_x^{(i)} & c_i = \lguard[\texttt{x}]\\
          \gamma_i\geq\gamma_x^{(i)} & c_i = \gguard[\texttt{x}]\\
          \gamma_i=0 & \sigma_i = \texttt{insample}\\
          \gamma_i'=0 & \sigma_i = \texttt{insample}'
        \end{cases},
      \]
      are all satisfied. 
\end{defn}

In particular, a valid coupling proof gives an upper bound on the privacy cost of any individual transition. 
\begin{prop}\label{indivTransitionCouplingProp}
    For a transition $t_i$, if there exists a valid coupling strategy $C_i=(\gamma_x^{(i)}, \gamma_i, \gamma_i')$ given initial $\texttt{x}$ values centred at $\hat{\mu_q}\brangle{1}$ and $\hat{\mu_q}\brangle{2}$, then $t_i$ is $d\varepsilon$-differentially private for some 
    \[d\leq \max_{\texttt{in}\brangle{1}\sim\texttt{in}\brangle{2}} (|\hat{\mu_q}\brangle{1}-\hat{\mu_q}\brangle{2}+\gamma_x^{(i)}|)\hat{d_q}+(|-\texttt{in}\brangle{1}+\texttt{in}\brangle{2}-\gamma_i|)d_q+(|-\texttt{in}\brangle{1}+\texttt{in}\brangle{2}-\gamma_i'|)d_q'.\]
\end{prop}
\begin{proof}
    Follows immediately from lemma \ref{indTransitionCoupling}.
\end{proof}

\subsection{Multiple Transitions}

Of course, in practice we would like to analyze the behaviour of programs with more than two program states.

We start with \textit{paths} of program states. 

\begin{defn}[Program paths]
    Consider some set of program states $Q$. A program \textbf{path} is a sequence of transitions $t_0, t_1, \ldots, t_{n-1}$ such that for all $i\in 0\ldots n-1$, $t_i = (q_i, q_{i+1}, c_i, \sigma_i, \tau_i)$ for some $c_i, \sigma_i, \tau_i$. We will often notate a path $\rho$ as $\rho = q_0\to q_1\to \ldots \to q_n$. 
    
    Additionally, if $\tau_0 = \texttt{true}$ and $c_0 = \texttt{true}$ (i.e.\ the first transition in any path always assigns its noised input value into $\texttt{x}$), then $\rho$ is a \textbf{complete path}. We call this condition the \textbf{initialization} condition.
\end{defn}
\begin{defn}[Taking a path]
    Consider some complete path $\rho = q_0\to \ldots \to q_n$ and let $\texttt{x}_i$ for all $i\in 1\ldots n$ be the value of $\texttt{x}$ at each program state $q_i$. Note that we can safely ignore $\texttt{x}_0$ because of the initialization condition. As before, for a program state $q_i\in Q$ with noise parameters $P({q_i}) = (d_{q_i}, d_{q_i}')$, let $z_i\sim \Lap(0, \frac{1}{d_{q_i}\varepsilon})$ and $z_i'\sim\Lap(0, \frac{1}{d_{q_i}'\varepsilon})$. 
    Further, given an input $\texttt{in}\in \RR^n$ and possible output $\sigma \in (\Gamma\cup\{(\texttt{insample}, a, b), (\texttt{insample}', a, b)\})^n$, let $\texttt{insample}_i = \texttt{in}_i+z_i$ and $\texttt{insample}_i' = \texttt{in}_i+z_i'$. $\texttt{x}$ will be updated with $\texttt{insample}$ at a transition $t_i$ if and only if $\tau_i = \texttt{true}$. In other words, $\texttt{x}_i = \begin{cases}
        \texttt{x}_{i-1} & \tau_{i-1} =\texttt{false}\\
        \texttt{insample}_{i-1} &\tau_{i-1}=\texttt{true}
    \end{cases}$. 

    Then $\rho$ is \textbf{taken} if, $\forall i\in 0\ldots n-1$, $c_i$ is satisfied for $\texttt{insample}_i$ and $\texttt{x}_i$ and, if $t_i$ outputs a real value, it is of the form $(\texttt{insample}_i, a, b)$ or $(\texttt{insample}_i', a', b')$, as appropriate. 
\end{defn}

\subsubsection{Privacy}

We can naturally  extend the definition of probability on a single transition to an entire path recursively.

\begin{defn}
    Given a path $\rho = q_0\to q_1\to \ldots \to q_n$, the \textbf{tail} of $\rho$ is defined as $tail(\rho) = q_1\to q_2 \to \ldots\to q_n$. 

    We may additionally use the notation $\rho_{i:j}$ to represent the subpath $q_i\to q_{i+1}\to \ldots \to q_j$ of $\rho$. Using this notation, $tail(\rho) = \rho_{i:} = \rho_{i:n}$.
\end{defn}

\begin{defn}[Path probabilities]
    Consider a path $\rho = q_0\to q_1\to \ldots \to q_n$ of length $n$. Let $t_0=(q_0, q_1, c_0, \sigma_0, \tau_0)$ between states $q$ and $q'$. Additionally, let $\texttt{x}_0$ be the initial value of $\texttt{x}$ at $q_0$. 
    
    If $\sigma_0 \in \{\texttt{insample}, \texttt{insample}'\}$, then let $\sigma_0 = (\texttt{insample}, a, b)$ or $\sigma_0 = (\texttt{insample}', a', b')$ as appropriate. 

    Additionally, let $(u, v), (u', v')\in \RR_{\infty}$ be defined as follows:
    \begin{align*}
        (u, v) &= \begin{cases}
        (-\infty, \infty) & c_0=\texttt{true}\land \sigma_0 \neq (\texttt{insample}, a, b)\\
        (a, b) &c_0=\texttt{true}\land \sigma_0 = (\texttt{insample}, a, b)\\
        (-\infty, \texttt{x}_0) & c_0=\lguard\land \sigma_0 \neq (\texttt{insample}, a, b)\\
        (c, \min(\texttt{x}_0, d)) &c_0=\lguard\land \sigma_0 = (\texttt{insample}, a, b)\\
        (\texttt{x}_0, \infty) & c_0=\gguard\land \sigma_0 \neq (\texttt{insample}, a, b)\\
        (\max(\texttt{x}_0, c), d) &c_0=\gguard\land \sigma_0 = (\texttt{insample}, a, b)\\
    \end{cases}\\
    (u', v')& = (a', b')\end{align*}

    Then, given an initial $\texttt{x}$-value $\texttt{x}_0$, an input sequence $\texttt{in}\in \RR^n$, and an output sequence $\sigma\in (\Gamma\cup\RR)^n$, the probability of $\rho$ is defined as \[
        \PP[\texttt{x}_0, \rho, \texttt{in}, \sigma] = \begin{cases}
            1 & n = 0\\
            \int_u^v \Lap_{\texttt{in}_0, \frac{1}{d_0\varepsilon}}(z)dz\PP[\texttt{x}_0, \rho_{1:}, \texttt{in}_{1:}, \sigma_{1:}] & \sigma_0 \neq \texttt{insample}' \land \tau_0 = \texttt{false}\\
            \int_u^v \Lap_{\texttt{in}_0, \frac{1}{d_0\varepsilon}}(z)\PP[z, \rho_{1:}, \texttt{in}_{1:}, \sigma_{1:}]dz  & \sigma_0 \neq \texttt{insample}'\land \tau_0=\texttt{true} \\
            \int_{u'}^{v'}\Lap_{\texttt{in}_0, \frac{1}{d'_0\varepsilon}}(z')dz'\int_u^v \Lap_{\texttt{in}_0, \frac{1}{d_0\varepsilon}}(z)dz\PP[\texttt{x}_0, \rho_{1:}, \texttt{in}_{1:}, \sigma_{1:}]& \sigma_0 = \texttt{insample}'\land \tau_0 = \texttt{false}\\
            \int_{u'}^{v'}\Lap_{\texttt{in}_0, \frac{1}{d'_0\varepsilon}}(z')dz'\int_u^v \Lap_{\texttt{in}_0, \frac{1}{d_0\varepsilon}}(z)\PP[z, \rho_{1:}, \texttt{in}_{1:}, \sigma_{1:}]dz& \sigma_0 = \texttt{insample}'\land \tau_0 = \texttt{true}
        \end{cases}
    \]
    where $\Lap_{\mu, s}(x)$ is the PDF of a Laplace distribution with mean $\mu$ and spread parameter $s$.
\end{defn}

For a complete path $\rho$, note that the initial value of $\texttt{x}$ is irrelevant, so we will shorthand $\PP[\texttt{x}_0, \rho, \texttt{in}, \sigma]$ to $\PP[\rho, \texttt{in}, \sigma]$.

Additionally, because we now read in a \textit{sequence} of real-valued inputs, we need to slightly modify our definition of adjacency.

\begin{defn}[Adjacency for a sequence of inputs]
    Two input sequences $\{\alpha_i\}_{i=1}^n, \{\beta_i\}_{i=1}^n$ of length $n$ are $\Delta$-adjacent (notated $\alpha \sim_{\Delta}\beta$) if, for all $i\in [1\ldots n]$, $|\alpha_i-\beta_i|\leq \Delta$. 

    If $\Delta$ is not specified, we assume that $\Delta = 1$. 
\end{defn}

Thus, we get the following definition of privacy:

\begin{defn}[$d\varepsilon$-differential privacy for a path]
    A complete path $\rho$ of length $n$ is $d\varepsilon$-differentially private for some $d>0$ if $\forall \varepsilon>0$, for all adjacent input sequences $\alpha\sim \beta$ of length $n$ and all possible output sequences $\sigma$ of length $n$, $\PP[\rho, \alpha, \sigma]\leq e^{d\varepsilon}\PP[\rho, \beta, \sigma]$.
\end{defn}

\subsubsection{Concatenating couplings}

Let $\rho[\texttt{in}]$ be a random variable representing the output of $\rho$ given input sequence $\texttt{in}$. 

In order to show that a program path $\rho$ is differentially private, for all adjacent inputs $\alpha\sim\beta$ and all possible outputs $\sigma$, we want to create the coupling $\rho[\alpha]\{(a, b): a=\sigma\implies b=\sigma\}^{\#d\varepsilon}\rho[\beta]$ for some $d>0$. 

Ideally, we would like to simply create couplings for each individual transition in $\rho$ as before and compose them together to create this overall coupling. Indeed, this approach is almost sufficient; the constraints imposed upon shifts for a coupling for transition $t_i$ depend solely on the shift at the most recent \textbf{assignment transition} in $\rho$ (i.e. the most recent transition $t_j$ such that $\tau_j = \texttt{true}$). 
The coupling shifts for \textit{non-assignment transitions} can thus never impact each other. 

\begin{defn}[Assignment transitions]
    Let $A_\rho = \{t_i=(q_i, q_{i+1}, c_i, \sigma_i, \tau_i): \tau_i = \texttt{true}\}$ be the set of \textbf{assignment transitions} in a path $\rho$. 

    For every transition $t_i$ in $\rho$, let $t_{at(i)}$ be the most recent assignment transition in $\rho$; i.e., $at(i) = \max\{j<i: t_j\in A_\rho\}$. If such a $j$ does not exist, we set $at(i)=-1$. 
\end{defn}

In particular, note that for transition $t_i$, $\gamma_x = \gamma_{at(i)}$, where $\gamma_{-1}$ is the shift applied to the initial $\texttt{x}$-values $\texttt{x}_0\brangle{1}$ and $\texttt{x}_0\brangle{2}$.

Thus, for an individual transition $t_i$ of $\rho$. From proposition \ref{indivTransitionCouplingProp}, we have a family of valid coupling strategies $C_i(\gamma_{at(i)}, \gamma_i, \gamma_i')$. 

We can merge these coupling strategies together to create a proof of privacy for the entire path: 

\begin{lemma}\label{multTransitionsCouplingProof}
    Let $\rho = q_0\to \ldots \to q_n$ be a complete path of length $n$. Let $\texttt{in}\brangle{1}\sim \texttt{in}\brangle{2}$ be arbitrary adjacent input sequences of length $n$. Additionally, fix some potential output $\sigma$ of $\rho$ of length $n$ and let $\sigma\brangle{1}$, $\sigma\brangle{2}$ be random variables representing possible outputs of $\rho$ given inputs $\texttt{in}\brangle{1}$ and $\texttt{in}\brangle{2}$, respectively. Additionally, for all $q_i$, let $P(q_i) = (d_i, d_i')$.

    Then $\forall \varepsilon>0$ and for all $\{\gamma_i, \gamma_i'\}_{i=0}^{n-1}$ that, for all $i$, satisfy the constraints \[
        \begin{cases}
          \gamma_i\leq\gamma_{at(i)} & c_i = \lguard[\texttt{x}]\\
          \gamma_i\geq\gamma_{at(i)} & c_i = \gguard[\texttt{x}]\\
          \gamma_i=0 & \sigma_i = \texttt{insample}\\
          \gamma_i'=0 & \sigma_i = \texttt{insample}'
        \end{cases},
      \]
      the lifting $\sigma\brangle{1}\{(a, b): a=\sigma\implies b=\sigma\}^{\#d\varepsilon}\sigma\brangle{2}$ is valid for $d = \sum_{i=0}^{n-1}(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i|)d_i+(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i'|)d_i'$, and therefore $t$ is $d\varepsilon$-differentially private. 
\end{lemma}
\begin{proof}
    From the proof of lemma \ref{indTransitionCoupling}, we know that we can create the couplings $\texttt{insample}_i\brangle{1} +\gamma_i{(=)}^{\#(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i|)d_i\varepsilon}\texttt{insample}_i\brangle{2}$ and $\texttt{insample}_i'\brangle{1} +\gamma_i'{(=)}^{\#(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i'|)d_i'\varepsilon}\texttt{insample}_i'\brangle{2}$ for all $q_i$ in $\rho$. 

    Additionally, for some fixed $q_i$ in $\rho$, if we have the coupling $\texttt{x}_i\brangle{1}+\gamma_x (=)^{\#(|\hat{\mu_i}\brangle{1}-\hat{\mu_i}\brangle{2}+\gamma_x|)\hat{d_i}\varepsilon}x_i\brangle{2}$, where $\texttt{x}_i\brangle{1}\sim \Lap(\hat{\mu_i}\brangle{1}, \frac{1}{\hat{d_i}\varepsilon})$ and $\texttt{x}_i\brangle{2}\sim \Lap(\hat{\mu_i}\brangle{2}, \frac{1}{\hat{d_i}\varepsilon})$, then subject to the constraints \[
        \begin{cases}
          \gamma_i\leq\gamma_x & c_i = \lguard[\texttt{x}]\\
          \gamma_i\geq\gamma_x & c_i = \gguard[\texttt{x}]\\
          \gamma_i=0 & \sigma_i = \texttt{insample}_i\\
          \gamma_i'=0 & \sigma_i = \texttt{insample}_i'
        \end{cases},
      \]
    the coupling $\sigma_i\brangle{1}\{(a, b): a=\sigma_i\implies b=\sigma_i\}^{\#d\varepsilon}\sigma_i\brangle{2}$ is valid for some $d$. 

    Indeed, note that for all $i$, $\texttt{x}_i = \texttt{insample}_{at(i)}$ by definition. Thus, we have that $\texttt{x}_i\brangle{1}+\gamma_x (=)^{\#(|-\texttt{in}_{at(i)}\brangle{1}+\texttt{in}_{at(i)}\brangle{2}+\gamma_{at(i)}|)d_{at(i)}\varepsilon}x_i\brangle{2}$, and we must satisfy the constraints \[
        \begin{cases}
          \gamma_i\leq\gamma_{at(i)} & c_i = \lguard[\texttt{x}]\\
          \gamma_i\geq\gamma_{at(i)} & c_i = \gguard[\texttt{x}]\\
          \gamma_i=0 & \sigma_i = \texttt{insample}_i\\
          \gamma_i'=0 & \sigma_i = \texttt{insample}_i'
        \end{cases}
      \]
      for all $i$.

    Thus, we can put all of these couplings together to show that the coupling $\sigma_i\brangle{1}\{(a, b): a=\sigma_i\implies b=\sigma_i\}^{\#d\varepsilon}\sigma_i\brangle{2}$ is valid for some $d>0$.

    In particular, note that we have created at most one pair of couplings (for $\texttt{insample}$ and $\texttt{insample}$) for each $q_i$. Thus, the total coupling cost associated with each $q_i$ is at most $(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i|)d_i+(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i'|)d_i'$, 
    which gives us an overall coupling cost of $d = \sum_{i=0}^{n-1}(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i|)d_i+(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i'|)d_i'$.
\end{proof}
\begin{defn}
    For a complete path $\rho$ of length $n$ and adjacent input sequences $\texttt{in}\brangle{1}\sim \texttt{in}\brangle{2}$, a \textbf{coupling strategy} is two functions $\bm{\gamma}(\texttt{in}\brangle{1}, \texttt{in}\brangle{2}):\RR^n\times \RR^n\to [-1, 1]^n$ and $\bm{\gamma}'(\texttt{in}\brangle{1}, \texttt{in}\brangle{2}):\RR^n\times \RR^n\to [-1, 1]^n$ that produce shifts for each transition of $\rho$ dependent on the input sequences. 

    If $\texttt{in}\brangle{1}$ and $\texttt{in}\brangle{2}$ are clear from context, we will often shorthand notating a coupling strategy as $\bm{\gamma}$ and $\bm{\gamma}'$. 
\end{defn}

\begin{defn}
    For a complete path $\rho$ of length $n$, a coupling strategy $C_\rho = (\bm{\gamma}, \bm{\gamma}')$ is \textbf{valid} if $\forall \texttt{in}\brangle{1}\sim\texttt{in}\brangle{2}$, $\bm{\gamma}(\texttt{in}\brangle{1}, \texttt{in}\brangle{2})$ and $\bm{\gamma}'(\texttt{in}\brangle{1}, \texttt{in}\brangle{2})$ satisfy the constraints \[
        \begin{cases}
          \gamma_i\leq\gamma_{at(i)} & c_i = \lguard[\texttt{x}]\\
          \gamma_i\geq\gamma_{at(i)} & c_i = \gguard[\texttt{x}]\\
          \gamma_i=0 & \sigma_i = \texttt{insample}\\
          \gamma_i'=0 & \sigma_i = \texttt{insample}'
        \end{cases}.
      \]
\end{defn}

\subsubsection{Optimizing Privacy}

\begin{defn}
    For a complete path $\rho$ of length $n$, the \textbf{cost} of a coupling strategy $C_\rho=(\bm{\gamma}, \bm{\gamma}')$ is \[cost(C_\rho) = \max_{\texttt{in}\brangle{1}\sim\texttt{in}\brangle{2}}\sum_{i=0}^{n-1}(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i|)d_i+(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i'|)d_i'.\]

    Additionally, let $G$ be the set of all valid coupling strategies $C_\rho=(\bm{\gamma}, \bm{\gamma}')$ for $\rho$. Then the \textbf{coupling cost} of $\rho$ is 
    \[cost(\rho) = \min_{(\bm{\gamma}, \bm{\gamma}')\in G}cost((\bm{\gamma}, \bm{\gamma}')).\]
\end{defn}

As before, the existence of a valid coupling strategy upper bounds the privacy cost of any path. 

\begin{prop}
    If $C_\rho=(\bm{\gamma}, \bm{\gamma}')$ is valid, then $\rho$ is $cost(C_\rho)\varepsilon$-differentially private.
\end{prop}

\begin{proof}
    Follows immediately from lemma \ref{multTransitionsCouplingProof}.
\end{proof}

\begin{cor}
    Any complete path $\rho$ is $cost(\rho)\varepsilon$-differentially private. Further, for all complete paths $\rho$, $cost(\rho)<\infty$. 
\end{cor}

\begin{proof}
    The first claim follows immediately from definitions. 
    
    The second claim follows by considering a coupling strategy $(\bm{\gamma}, \bm{\gamma}')$ where $\forall \texttt{in}\brangle{1}\sim\texttt{in}\brangle{2}, \bm{\gamma} = \bm{\gamma}' = \bm{0}$. Note that $(\bm{\gamma}, \bm{\gamma}')$ is trivially valid. Since $\texttt{in}\brangle{1}\sim\texttt{in}\brangle{2}$, $cost(\rho)\leq cost(C_\rho(\bm{0}))\leq \sum_{i=0}^{n-1}(d_i+d_i')$, which is finite for all fixed $\rho$. 
\end{proof}


\begin{prop}
    The cost of a coupling strategy over a fixed path $\rho$ is maximized when, for every transition, the difference between the input values is $1$. In other words,
    \begin{align*}
        &\max_{\texttt{in}\brangle{1}\sim \texttt{in}\brangle{2}} \sum_{i=0}^{n-1}(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i|)d_i+(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i'|)d_i' \\
        = &\max_{\Delta\in \{-1, 1\}} \sum_{i=0}^{n-1}(|\Delta-\gamma_i|)d_i+(|\Delta-\gamma_i'|)d_i'
    \end{align*}
\end{prop}
\begin{proof}
    (Vishnu)
\end{proof}

Note then, that the process of finding the optimal coupling cost of a path $\rho$ can be formulated as a linear program.
 

\subsection{Branching}

\begin{defn}[Branching program]
    Given a set of program states $Q$, a branching program $B$ is a finite set of complete paths over $Q$ such that for all $\rho=q_0\to\ldots\to q_n, \rho'=q'_0\to\ldots\to q'_m\in B$, $q_0=q'_0$. $B$ must also satisfy the following properties: \begin{enumerate}
        \item If any transition $t$ in any path $\rho\in B$ is of the form $(q, q', c, \sigma, \tau)$, then no other transitions of the form $(q, q^*, c, \sigma', \tau')$ for $q, q', q^*\in Q$ exist in any path of $B$. Additionally, if any transition $t$ in any path $\rho\in B$ is of the form $(q, q', \texttt{true}, \sigma, \tau)$, then transitions of the form $(q, q^*, \lguard[\texttt{x}], \sigma', \tau')$ or $(q, q^*, \lguard[\texttt{x}], \sigma', \tau')$ do not exist in any path of $B$.
        \item If a transition of the form $(q, q', \lguard[\texttt{x}], \sigma, \tau)$ exists in any path in $B$ and a transition of the form $(q, q^*, \gguard[\texttt{x}], \sigma', \tau')$ exists in any (potentially different) path in $B$, then $\sigma \neq \sigma'$. Additionally, at least one of $\sigma\in \Gamma$, $\sigma'\in \Gamma$ is true.
    \end{enumerate} 
    We will refer to the first condition as \textbf{determinism} and the second condition as \textbf{output distinction}.
\end{defn}

\subsubsection{Privacy}

\begin{defn}[DP for branching programs]
    A branching program is DP if [standard def]
\end{defn}

\begin{prop}
    A branching program $B$ is DP if and only if for every complete path in $B$, etc.
\end{prop}
\begin{proof}
    Each potential output of $B$ uniquely determines a path in $B$ by output distinction and determinism.
\end{proof}


We can do no better than assigning coupling strategies for each path independently. 
\begin{defn}[Coupling strategy]
    A assignment of coupling strategies 
\end{defn}

\begin{prop}
    Optimal cost is dependent on path (Vishnu)
\end{prop}

\subsection{Loops}

\begin{defn}[Looping path]
    Consider a complete path $\rho = q_0\to\ldots \to q_n$ such that for some $i<n$, $q_i = q_n$. WLOG suppose also that $\forall j\neq i$, $q_j \neq q_n$. A looping path $L_\rho$ is the infinite set of paths $\{q_0\to\ldots\to q_{i-1}\to (q_i\to\ldots\to q_{n-1})^k\to q_n| k\in \NN\}$, where $(q_i\to\ldots\to q_{n-1})^k$ means that the subpath $(q_i\to\ldots\to q_{n-1})^k$ is iterated $k$ times. 
    Additionally, $L_\rho$ must satisfy the properties of \textbf{determinism} and \textbf{output distinction} as with branching programs.
\end{defn}

\begin{defn}[Looping path privacy]
    A looping path $L_\rho$ is $d\varepsilon$-differentially private for $d>0$ if for all complete paths $\rho'$ in $L_\rho$, for all possible outputs $\sigma_{\rho'}$ of $\rho'$ and input sequences $\texttt{in}\brangle{1}\sim \texttt{in}\brangle{2}$, $\forall \varepsilon>0, \PP[\rho', \sigma_{\rho'}, \texttt{in}\brangle{1}]\leq e^{d\varepsilon}\PP[\rho', \sigma_{\rho'}, \texttt{in}\brangle{2}]$.
\end{defn}

\begin{prop}
    A looping path $L_\rho$ is $d\varepsilon$-differentially private for $d>0$ if and only if for all complete paths $\rho'$ in $L_\rho$, $\rho'$ is $d\varepsilon$-differentially private. 
\end{prop}

\begin{defn}[Coupling strategies]
    A \textbf{coupling strategy} for a looping path $L_\rho$, where $\rho=q_0\to\ldots \to q_n$ is an assignment of shifts $\gamma_i, \gamma_i'$ for each transition in $\rho$ as a function of the input differences. 
\end{defn}

\begin{defn}[Validity]
    A coupling strategy $C_{L_\rho}=(\bm{\gamma}, \bm{\gamma}')$ for a looping path $L_\rho$ is \textbf{valid} if, for all paths $\rho'$ of $A$, the following constraints hold for all adjacent input sequences $\alpha\sim\beta$ and for all $i$:
    \begin{itemize}
        \item If $c_i = \lguard[\texttt{x}]$, then $\gamma_i\leq\gamma_{at(i)}$
        \item If $c_i = \gguard[\texttt{x}]$, then $\gamma_i\geq\gamma_{at(i)}$
        \item If $\sigma_i = \texttt{insample}$, then $\gamma_i=0$
        \item If $\sigma_i = \texttt{insample}'$, then $\gamma_i'=0$
    \end{itemize}
\end{defn}

Note that given a complete path $\rho'$ in a looping path $L_\rho$, a coupling strategy $C_A$ induces a coupling strategy $C_{\rho'}$ for $\rho'$.

\begin{defn}
    The \textbf{cost} of a coupling strategy $C_{L_\rho} = (\bm{\gamma}, \bm{\gamma}')$ for a looping path $L_\rho$ is \begin{align*}
    cost(C_{L_\rho}) &= \sup_{\rho'\in L_{\rho}}\max_{\texttt{in}\brangle{1}\sim \texttt{in}\brangle{2}} \sum_{i=0}^{|\rho'|-1}(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i|)d_i+(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i'|)d_i'\\
    &=\sup_{\rho'\in L_\rho}cost(C_{\rho'})
\end{align*}
    Further, let $G_{L_\rho}$ be the set of all valid coupling strategies for $L_\rho$. Then the \textbf{coupling cost} of $L_\rho$ is \[
        cost(L_\rho) = \min_{C_{L_\rho}\in G_{L_\rho}}cost(C_{L_\rho})
    \]
\end{defn}

\begin{prop}
    Given a valid coupling strategy $C_{L_\rho}$ for a looping path $L_\rho$, $L_\rho$ is $cost(C_{L_\rho})\varepsilon$-differentially private. 
\end{prop}
\begin{proof}
    Let $\rho'$ be a complete path in $L_\rho$ and let $C_{\rho'}$ be the coupling strategy for $\rho'$ derived from $C_A$. We know from lemma \ref{multTransitionsCouplingProof} that, if $C_A$ is valid, then the lifting $\sigma\brangle{1}\{(a, b): a=\sigma\implies b=\sigma\}^{\#cost(C_{\rho'})\varepsilon}\sigma\brangle{2}$ is valid, 
    and therefore for all possible outputs $\sigma$ of $\rho'$ and adjacent inputs $\texttt{in}\brangle{1}\sim\texttt{in}\brangle{2}$, $\forall \varepsilon>0, \PP[\rho', \sigma, \texttt{in}\brangle{1}]\leq e^{cost(C_{\rho'})\varepsilon}\PP[\rho', \sigma, \texttt{in}\brangle{2}]\leq e^{cost(C_{L_\rho})\varepsilon}\PP[\rho', \sigma, \texttt{in}\brangle{2}]$.
\end{proof}
\begin{cor}
    A looping path $L_\rho$ is $cost(L_\rho)\varepsilon$-differentially private. 
\end{cor}



\begin{lemma}\label{finiteCostConstraintLemma}
    For a looping path $L_\rho$, given adjacent input sequences $\texttt{in}\brangle{1}\sim \texttt{in}\brangle{2}$, a valid coupling strategy $C_{L_\rho} = (\mathbf{\gamma}, \mathbf{\gamma}')$ has finite cost $cost(C_{L_\rho})<\infty$ if and only if the following constraint applies for all $i$:
    \begin{itemize}
        \item If $t_i$ is in a cycle and $c_i\neq\texttt{true}$, then $\gamma_i = -\texttt{in}\brangle{1}_i+\texttt{in}\brangle{2}_i$ and $\gamma_i' = -\texttt{in}\brangle{1}_i+\texttt{in}\brangle{2}_i$.
    \end{itemize}
\end{lemma}

\begin{proof}
    {\color{red} TODO: check the $c_i\neq \texttt{true}$ condition}

    ($\impliedby$)

    Let $T$ be the set of transitions $t_i$ in $L_\rho$ such that $t_i$ is \textbf{not} in a cycle. Note that $T$ is independent of any choice of path(s) through $L_\rho$. 

    Fix a complete path $\rho'$ in $L_\rho$ and let $C_\rho'$ be the coupling strategy for $\rho'$ induced by $C_{L_\rho}$. 

    Let $D_\rho$ be the set of transitions $t_i$ in $\rho$ such that $t_i$ is in a cycle in $L_\rho$, i.e., $t_i\notin T$.  

    If the given constraint holds, then we know that $\max_{\texttt{in}\brangle{1}\sim\texttt{in}\brangle{2}}\sum_{i: t_i\in D_\rho}(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i|)d_i+(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i'|)d_i' = 0$

    So \begin{align*}
        cost(C_\rho) = \max_{\texttt{in}\brangle{1}\sim\texttt{in}\brangle{2}}&\sum_{i: t_i\in D_\rho}(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i|)d_i+(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i'|)d_i'\\
        &+\sum_{i: t_i\notin D_\rho}(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i|)d_i+(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i'|)d_i'\\
        = \max_{\texttt{in}\brangle{1}\sim\texttt{in}\brangle{2}}&\sum_{i: t_i\in T}(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i|)d_i+(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i'|)d_i'\\
        \leq \sum_{i:t_i\in T}(2d_i& + 2d_i')\\
        \leq |T|\max_{i:t_i\in T}&(2d_i + 2d_i')
    \end{align*}

    ($\implies$)

    Suppose that some transition $t_i$ is in a cycle $C$ in $A$ and $\gamma_i\neq -\texttt{in}\brangle{1}_i+\texttt{in}\brangle{2}_i$ or $\gamma_i'\neq  -\texttt{in}\brangle{1}_i+\texttt{in}\brangle{2}_i$. Then $\exists \texttt{in}\brangle{1}\sim \texttt{in}\brangle{2}$ such that $(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i|)d_i+(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i'|)d_i'>0$.

    Fix such a $\texttt{in}\brangle{1}\sim \texttt{in}\brangle{2}$. 

    Let $\rho_k$ be a complete path in $A$ with $C$ iterated $k$ times. Then for all $k\in \NN$, \begin{align*}
        cost(\rho_k) \geq k((|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i|)d_i+(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i'|)d_i'),
    \end{align*}
    so for all $M\in \RR$, $\exists \rho_k$ such that $cost(\rho_k) > M$.
\end{proof}

\begin{lemma}\label{cycleGammaConstraints}
    If a coupling strategy $C=(\mathbf{\gamma}, \mathbf{\gamma}')$ for a looping path $L_\rho$ is valid and has finite cost, then the following must hold for all $i$:
    \begin{enumerate}
        \item If $t_i$ is in a cycle and $c_i = \lguard[\texttt{x}]$, then $\gamma_i = -\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}$ and $\gamma_{at(i)} = 1$.
        \item If $t_i$ is in a cycle and $c_i = \gguard[\texttt{x}]$, then $\gamma_i = -\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}$ and $\gamma_{at(i)} = -1$.
    \end{enumerate}
\end{lemma}
\begin{proof}
    We will show (1). (2) follows symmetrically.

    Consider some $t_i$ in a cycle where $c_i = \lguard[\texttt{x}]$. Because $C$ is has finite cost, we know from lemma \ref{finiteCostConstraintLemma} that $\gamma_i = -\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}$ for all  $\texttt{in}_i\brangle{1}\sim\texttt{in}_i\brangle{2}$. In particular, when $-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}=1$, then $\gamma_i=1$. 
    
    Further, because $\gamma_{at(i)}$ must be greater than $\gamma_i$ for all $\texttt{in}_i\brangle{1}\sim\texttt{in}_i\brangle{2}$ for $C$ to be valid, we must have that $\gamma_{at(i)}=1$.
\end{proof}
\begin{lemma}
    If a valid finite cost coupling strategy $C = (\gamma, \gamma')$ exists for a looping path $L_\rho$, then there exists a valid finite cost coupling strategy $C^*= (\gamma^*, \gamma^{*\prime})$ such that for all $i\in AT(L_\rho)$, $\gamma_i^*\in \{-1, 0, 1\}$. 
\end{lemma}
\begin{proof}
    TBD
\end{proof}

\subsection{Programs}

\begin{defn}[Program]
    Given a fixed set of program states $Q$, A [come up with a good name] program $P$ is a set of complete paths on $Q$ with the closure property that, for every complete path $\rho = q_0\to \ldots \to q_n$ in $P$, if, $q_i = q_j$ and $i\neq j$, then the complete path $\rho_k = q_0\to \ldots \to (q_i \to \ldots \to q_j)^k \to \ldots \to q_n\in P$ for all $k\in \NN$. Additionally, $P$ must satisfy the determinism and output distinction conditions of 
\end{defn}

\begin{defn}[Path Classes]
    For a complete path $\rho=q_0\to \ldots \to q_n$ in a program $P$, let $\bar{\rho}$ be $\rho$ with all cycles removed. $\bar{\rho}$ can be defined by an iterative process where $\rho^0 = \rho$, and, given that $\rho^k =q_0^k\to \ldots \to q_{n_k}^k$, if there exists some $i\neq j$ such that $q_i^k=q_j^k$, then $\rho^{k+1} = q_0^k\to \ldots \to q_i^k \to q_{j+1}^k\to \ldots\to q_{n_k}^k$. $\bar{\rho}$ is the first such $\rho^k$ where there are no $i\neq j$ such that $q_i^k=q_j^k$. 
    {\color{red} Edge case: the program is just one big cycle}

    Then we can define the equivalence relation $\sim_p$ such that $\rho\sim_p\rho'$ if $\bar{\rho} = \bar{\rho'}$. Note then that the equivalence classes of $\sim_p$ correspond to the set of all acyclic complete paths in $P$. {\color{red} TODO: double check this} We will call these equivalence classes \textbf{path classes}.
\end{defn}

\begin{defn}
    For each path class of a program $P$, a coupling strategy [...]
\end{defn}

\begin{prop}
    If valid coupling + constraint holds for every path class, then program is differentially private. 
\end{prop}

\subsection{DiPA}

\begin{defn}[DiPA]
    A DiPA $A$ is a tuple (...) [copy this def]
\end{defn}

\begin{defn}
    A DiPA $A$ is differentially private if [copy this def]
\end{defn}

\begin{prop}[informal]
    The class of programs captured by [above] is exactly the set of programs captured by DiPA. 
\end{prop}





\subsubsection{Deciding Privacy}


\begin{lemma}
    If there exists some valid coupling strategy $S$ for a DiPA $A$ with $cost(S)<\infty$, then $A$ is $cost(S)$-DP.
\end{lemma}
\begin{proof}
    Follows immediately from [before].
\end{proof}

\begin{defn}[Leaking Pair, etc from DiPA]
    [...]
\end{defn}

\begin{thm}[from DiPA]\label{DiPACounterexamplesThm}
    If a DiPA $A$ has a leaking cycle, leaking pair, disclosing cycle, or privacy violating path, then $A$ is not $d\varepsilon$-differentially private for any $d>0$. 
\end{thm}

Note that for any path in $A$, we have a list of constraints that a coupling strategy $C=(\mathbf{\gamma}, \mathbf{\gamma}')$ can satisfy\begin{enumerate}
    \item If $c_i = \lguard[\texttt{x}]$, then $\gamma_i\leq\gamma_{at(i)}$
    \item If $c_i = \gguard[\texttt{x}]$, then $\gamma_i\geq\gamma_{at(i)}$
    \item If $\sigma_i = \texttt{insample}$, then $\gamma_i=0$
    \item If $\sigma_i = \texttt{insample}'$, then $\gamma_i'=0$
    \item If $t_i$ is in a cycle and $c_i\neq \texttt{true}$, then $\gamma_i = -\texttt{in}\brangle{1}_i+\texttt{in}\brangle{2}_i$
    \item If $t_i$ is in a cycle and $c_i\neq \texttt{true}$, then $\gamma_i' = -\texttt{in}\brangle{1}_i+\texttt{in}\brangle{2}_i$
\end{enumerate}


If all constraints are statisfied, then $A$ is private. 


\begin{lemma}
    If there does not exist a valid coupling strategy for a DiPA $A$ with finite cost, then $A$ is not differentially private. 
\end{lemma}
\begin{proof}
    Consider a ``maximially'' satisfied coupling strategy $C=(\mathbf{\gamma}, \mathbf{\gamma}')$; i.e. there is no other coupling strategy $C'$ for $A$ such that $C'$ satisfies more constraints than $C$. By lemma [tbd], we are allowed to only consider coupling strategies $C=(\gamma, \gamma')$ such that, for all $i\in AT(A)$, $\gamma_i \in \{-1, 0, 1\}$. 

    Fix some looping path $\rho$ in $A$ such that at least one constraint is not satisfied by $C$ as applied to $\rho$.

    By assumption, at least one constraint is unsatisfied by $C$. We will show that in every case, $A$ must contain at least one of a leaking cycle, leaking pair, disclosing cycle, or privacy violating path. By theorem \ref{DiPACounterexamplesThm}, this is sufficient to show that $A$ is not $d\varepsilon$-differentially private for any $d>0$.

    \textbf{Case 1: (1) is unsatisfied for $\gamma_i$}

    \textbf{Case 2: (2) is unsatisfied for $\gamma_i$}

    This case is exactly symmetric to case (1).

    \textbf{Case 3: (3) is unsatisfied for $\gamma_i$}

    First note that if $t_i$ is in a cycle, then that cycle will be a disclosing cycle because $t_i$ outputs $\texttt{insample}$. Thus, we will assume that $t_i$ is not in a cycle.

    Because $C$ is maximal, setting $\gamma_i=0$ must violate at least one of constraints (1) or (2) for $\gamma_i$ or (1) for some $\gamma_l$ such that $at(l) = i$.

    \textbf{Case 3a: Satisfying (3) for $\gamma_i$ would violate (1) for $\gamma_i$}

    This means that $\gamma_{at(i)}<0$. 

    \textbf{Case 3b: Satisfying (3) for $\gamma_i$ would violate (1) for $\gamma_i$}

    This case is exactly symmetric to case (3a).

    \textbf{Case 3c: Satisfying (3) for $\gamma_i$ would violate (1) for some $\gamma_l$ where $at(l) = i$}

    Note that $t_i$ must be an assignment transition. Further, we know that $\gamma_l>0$ and $c_l = \lguard[\texttt{x}]$. 
    
    Because $C$ is maximal, setting $\gamma_l=0$ would now violate either constraint (1) for some $\gamma_{l'}$ where $at(l') = l$ or constraint (5) for $\gamma_l$. Note that because $\gamma_l>0$, constraint (2) cannot be newly violated for some $\gamma_{l'}$ where $at(l') = l$.

    If setting $\gamma_l = 0$ would violate constraint (1) for some $\gamma_{l'}$ where $at(l')=l$, then. 

    \textbf{Case 4: (4) is unsatisfied for $\gamma_i'$}
    
    Because $C$ is maximal, setting $\gamma_i'=0$ must violate some other constraint. In particular, this must mean that constraint (6) is now violated. However, this would imply that $t_i$ is in a cycle, and so the cycle containing $t_i$ would be a disclosing cycle.

    \textbf{Case 5: (5) is unsatisfied for $t_i$:} Because $C$ is maximal, we know that if $\gamma_i = -\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}$ then another constraint must be violated. In particular, at least one of constraints (1), (2), or (3) must be violated for $\gamma_i$. 
    
    \textbf{Case 5a: Satisfying (5) for $t_i$ would violate (1)}

    If (1) is now violated, then either $t_i$ is an assignment transition or $c_i = \lguard[\texttt{x}]$ and $\gamma_{at(i)}<1$. If $t_i$ is an assignment transition, then the cycle containing $t_i$ has a transition with a non-$\texttt{true}$ guard ($t_i$) and an assignment transition, so it must be a leaking cycle. 

    Otherwise, if $t_i$ is not an assignment transition, $c_i = \lguard[\texttt{x}]$, and constraint (1) is violated for $\gamma_i$, we must have that $\gamma_{at(i)}<1$ due to other constraints.
    
    Consider all assignment transitions in $\rho$ before $t_i$. Note that if any such assignment transition is in a cycle, then that cycle must be a leaking cycle since either the assignment transition is in the same cycle as $t_i$ or there must be some non-$\texttt{true}$ transition in the cycle because otherwise $t_i$ is unreachable. {\color{red} make sure to add a condition to programs so that this is bad}

    So assume that all assignment transitions in $\rho$ before $t_i$ are not in a cycle. Then if $c_{at(i)} \neq \lguard[\texttt{x}]$, because $C$ is maximal, this must mean that $t_{at(i)}$ outputs $\texttt{insample}$. Note that the path from $t_{at(i)+1}$ to $t_i$ is an $\texttt{AL}$-path (since there are no assignment transitions on it) and $t_i$ is in an $\texttt{L}$-cycle since $t_i$ is in a cycle and $c_i = \lguard[\texttt{x}]$. 
    Then the path from $t_{at(i)}$ (an assignment transition that outputs $\texttt{insample}$) to $t_i$ is a privacy violating path. 

    If $c_{at(i)} = \lguard[\texttt{x}]$, then let $c_{at(j)}$ be the earliest assignment transition such that $c_{at(j)} = \lguard[\texttt{x}]$ and $\gamma_{at(j)} < 1$ and, for all assignment transitions $t_{at(k)}$ between $t_{at(j)}$ and $t_i$, $c_{at(k)} = \lguard[\texttt{x}]$ and $\gamma_{at(k)} < 1$. Note that such an $t_{at(j)}$ must exist. 

    If $t_{at(j)} = t_{at(i)}$, then setting $\gamma_{at(i)} =1$ must violate either constraint (2) for some other $\gamma_l$ such that $at(l)=at(i)$, or constraint (3) for $\gamma_{at(i)}$. Without loss of generality, we will assume that $l\neq i$. If constraint (3) would be violated, then as before, there exists a privacy violating path from $t_{at(j)}$ to $t_i$. 
    If constraint (2) would be violated for some $\gamma_l$ such that $at(l)=at(i)$, then either $t_l$ must output $\texttt{insample}$ or $t_l$ must be in a cycle. 
    
    Suppose that $i<l$; then that the path from $t_i$ to $t_l$ is both an $\texttt{AG}$-path and an $\texttt{AL}$-path (since there are no assignment transitions on it). Thus, if $t_l$ outputs $\texttt{insample}$, there exists a privacy violating path from $t_i$ to $t_l$ and if $t_l$ is in a cycle, then the cycle containing $t_i$ and the cycle containing $t_l$ together make up a leaking pair, since the cycle containing $t_l$ is a $\texttt{G}$-cycle by definition. 
    Symmetrically, if $l>i$, then either the path from $t_l$ to $t_i$ is a privacy violating path or the cycle containing $t_l$ and the cycle containing $t_i$ make up a leaking pair.
    
    Otherwise, note that the path from $t_{at(j)}$ to $t_i$ is an $\texttt{AL}-$path. Since $C$ is maximal, we cannot set $\gamma_{at(k)}=1$ for $\gamma_{at(j)}$ or for any of the other assignment transitions $t_{at(k)}$ between $t_{at(j)}$ and $t_i$ without violating another constraint. In particular, either constraint (2) for some $\gamma_l$ such that $at(l) = at(j)$ or constraint (3) would be violated for $\gamma_{at(j)}$. 
    If constraint (3) would be violated for $\gamma_{at(j)}$ then $t_{at(j)}$ outputs $\texttt{insample}$, so as before, there is a privacy violating path from $t_{at(j)}$ to $t_i$. Otherwise if constraint (2) would be violated for some $\gamma_l$ such that $at(l) = at(j)$, then as before, $\gamma_l$ must either output $\texttt{insample}$ or $t_l$ is in a cycle. 
    Just like before, this means that there must be either a privacy violating path from $t_l$ to $t_i$ or the cycle containing $t_l$ and the cycle containing $t_i$ together make up a leaking pair. 

    \textbf{Case 5b: Satisfying (5) for $t_i$ would violate (2)}

    This case is exactly symmetric to case (5a).

    \textbf{Case 5c: Satisfying (5) for $t_i$ would violate (3)}

    If (3) would be violated, then $t_i$ must output $\texttt{insample}$. Then the cycle containing $t_i$ must be a disclosing cycle. 
    
    \textbf{Case 6: (6) is unsatisfied for $t_i$:} Because $C$ is maximal, we know that if $\gamma_i' = -\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}$ then another constraint must be violated for $\gamma_i'$. In particular, constraint (4) must be violated, since no other constraint involves $\gamma_i'$. 
    Then $t_i$ is a transition in a cycle that outputs $\texttt{insample}'$, so $A$ has a disclosing cycle.
\end{proof}


\begin{thm}
    A DiPA $A$ is $d\varepsilon$-differentially private for some $d>0$ if and only if there exists some valid coupling strategy $S$ for $A$ with $cost(S)<\infty$. 
\end{thm}

\subsection{An algorithm for deciding privacy}

Observe that the constraints imposed on valid coupling strategies for a complete path $\rho$ only depend on the shifts associated with \textit{assignment transitions} in $\rho$. 

In particular, this lends itself to conceptualizing complete paths by splitting them up based on assignment transitions. 

\begin{defn}
    A \textbf{segment} of a (complete) path $\rho = q_0\to\ldots\to q_n$ is a subpath $q_i \to q_{i+1}\to \ldots \to q_j$ of $\rho$ such that $t_i \in A_\rho$; for all $i<k<j$, $t_k \notin A_\rho$; and either $j=n$ or $t_j \in A_\rho$.
\end{defn}

In other words, a segment is a subpath of $\rho$ between two consecutive assignment transitions (or between the last assignment transition and the end of the path). Splitting up a path into segments thus allows us to think about a single value of $\texttt{x}$ at a time.

\begin{prop}
    [Vishnu's segment graph overview here]
\end{prop}

\subsection{Minimizing a privacy budget}

If we have a differentially private program, we'd also like to optimize its privacy cost. We can do so via couplings: 

\begin{prop}
    Introduce linear program here - maybe this is a definition?
\end{prop}

\begin{prop}
    Introduce approximate version here
\end{prop}

\begin{prop}
    Optimal linear program always has cost at worst approx version; there is indeed a separation between the optimal + approx
\end{prop}

\begin{prop}
    Approximate version is an approximation of the optimal by a factor linear in the number of segments. 
\end{prop}

\begin{prop}
    Approximate version can be solved in polytime
\end{prop}

\begin{conj}[IF I HAVE TIME LOOK INTO THIS]
    Optimal coupling cost $\leq$ cost given by original DiPA analysis. 
\end{conj}

\begin{conj}
    Optimal coupling cost = ``true'' optimal privacy cost
\end{conj}

\noindent\hrulefill

\section{TBD: Older Writing}
\subsection{A Program Model}

We start with a basic, ``straight-line'' program model. 

\begin{defn}\label{SSADefn}
    A simple segment automaton (SSA) $A(x)$ with initial value $x\in \RR$ is a tuple $(Q, \Sigma, C, \Gamma, q_{init}, X, P, \delta)$ where\begin{itemize}
        \item $Q$ is a finite set of states
        \item $\Sigma = \RR$ is the input alphabet
        \item $C = \{\texttt{true}, \lguard, \gguard\}$ is a set of transition \textbf{guards}
        \item $\Gamma$ is a finite output alphabet
        \item $q_{init}\in Q$ is the starting state
        \item $X = \{\texttt{x}, \texttt{insample}, \texttt{insample}'\}$ is a set of real-valued program variables
        \item $P: Q\to \QQ\times \QQ^{\geq 0}\times \QQ\times  \QQ^{\geq 0}$ is a function that assigns a series of Laplace distribution parameters to each state for sampling
        \item $\delta: (Q\times C)\to Q\times (\Gamma\cup\{\texttt{insample}, \texttt{insample}'\})$ is a (partial) transition function. 
    \end{itemize}
    Additionally, $\delta$ is restricted such that \begin{itemize}  
        \item For every state $q\in Q$,  $\delta(q, c)$ can be defined for \textbf{at most one} $c\in C$. 
        \item There are no cycles in the graph of $A$; i.e., for every path $\rho = q_{init} \to q_1\to\ldots\to q_n$ in $A$ starting from $q_{init}$, $q_{init}$ and $q_i$ are all pairwise distinct. 
    \end{itemize}

    Note in particular that $A(x)$ is parameterized by some initial real value $x$, stored in the variable $\texttt{x}$. Importantly, we will treat $x$ as a random variable drawn from some Laplace distribution.
\end{defn}

An SSA $A(x)$ runs as follows:
\begin{itemize}
    \item The variable $\texttt{x}$ has a stored real value, which is initialized to $x$. 
    \item At \textbf{every} state $q\in Q$, $A$ will read in some real-valued input value $a$. Here, $a$ corresponds to the ``true'' value of a query function $q_i(X)$. Let $P(q) = (\mu, b, \mu', b')$. 
    The variables $\texttt{insample}$ and $\texttt{insample}'$ are initialized such that $\texttt{insample} = a + \Lap(\mu, b)$ and $\texttt{insample}' = a + \Lap(\mu', b')$.
    \item If $\delta(q, \texttt{true}) = (q', \sigma)$, then $A$ transitions to $q'$ and outputs $\sigma \in(\Gamma\cup\{\texttt{insample}, \texttt{insample}'\})$. Similarly if $\lguard$ (symmetrically, $\gguard$) and $\delta(q, \lguard) = (q', \sigma)$ (symmetrically, $\delta(q, \gguard) = (q', \sigma)$), then then $A$ transitions to $q'$ and outputs $\sigma \in(\Gamma\cup\{\texttt{insample}, \texttt{insample}'\})$.
    \item If, at a state $q\in Q$, a guard $c$ is valid (e.g. $c=\lguard$ and $\lguard$) and $\delta(q, c)$ is not defined (including if $\delta(q, c)$ is not defined for any $c$), the automaton terminates.
    \item If $q = q_{init}$, then $\texttt{x}$ is \textbf{assigned} so that $\texttt{x}\gets \texttt{insample}$ after the transition comparison.
\end{itemize}

Note that, without loss of generality, we can assume that $P(q) = (0, b, 0, b')$ by shifting the inputs appropriately. Thus, we will frequently abuse notation and write $P(q) = (b, b')$. 


\begin{defn}
    A path $\rho$ of an SSA $A(x)$ is a sequence of states $r_0\to r_1\to\ldots\to r_n$ such that for every $i\in\{0, 1,\ldots, n-1\}$, there exists some guard $c\in C$ such that $\delta(q_i, c) = (q_{i+1}, \sigma)$ for some output $\sigma$. 
\end{defn}

Given a path $\rho = r_0\to r_1\to \ldots \to r_n$ in $A$, we will notate the transition $r_i\to r_{i+1}$ with $\trans(r_i)$ and the guard (i.e. $\texttt{true}, \lguard$, or $\gguard$) of $\trans(r_i)$ as $\guard(r_i)$. 

For technical reasons, whenever either $\texttt{insample}$ or $\texttt{insample}'$ are output by an SSA, we must define an interval $(a, b)$ that contains the output. Thus, when a transition outputs $\texttt{insample}$ or $\texttt{insample}'$, we say that $\sigma$ is of the form $(\texttt{insample}, c, d)$ or $(\texttt{insample}', c, d)$ for $c, d\in R_\infty$. 

If such a tuple is output, it can be interpreted as $\texttt{insample}$ or $\texttt{insample}'$ being output with the outputted real value falling within the interval $(c, d)$. 

Importantly, this allows us to define the \textbf{probability} of an SSA traversing a specified path with a specified output. 

\begin{defn}
    Let $A(x)$ be an SSA, $\rho = r_0\to r_1\to \ldots \to r_n$ be a path in $A$, and let $\sigma$ be a possible output of $A$. Additionally, let $\alpha \in \RR^*$ be a sequence of real-valued inputs. 

    Then $\PP[x, \rho^{(\alpha, \sigma)}]$ is the probability of $A$ outputting $\sigma$ while traversing path $\rho$ with $\texttt{x} = x$ at the initial state and input sequence $\alpha$.
    
    In particular, we can define $\PP[x, \rho^{(\alpha, \sigma)}]$ inductively. Let $\delta(r_0, \guard(r_0))=(q, \sigma_0)$ and $P(r_0) = (\mu, b, \mu', b')$. If $\sigma_0 \in \{\texttt{insample}, \texttt{insample}'\}$, then let $\sigma_0 = (\texttt{insample}, c, d)$ or $\sigma_0 = (\texttt{insample}', c', d')$ as appropriate. 

    Additionally, let $(u, v), (u', v')\in \RR_{\infty}$ be defined as follows:
    \begin{align*}
        (u, v) &= \begin{cases}
        (-\infty, \infty) & \guard(r_0)=\texttt{true}\land \sigma_0 \neq \texttt{insample}\\
        (c, d) &\guard(r_0)=\texttt{true}\land \sigma_0 = \texttt{insample}\\
        (-\infty, x) & \guard(r_0)=\lguard\land \sigma_0 \neq \texttt{insample}\\
        (c, \min(x, d)) &\guard(r_0)=\lguard\land \sigma_0 = \texttt{insample}\\
        (x, \infty) & \guard(r_0)=\gguard\land \sigma_0 \neq \texttt{insample}\\
        (\max(x, c), d) &\guard(r_0)=\gguard\land \sigma_0 = \texttt{insample}\\
    \end{cases}\\
    (u, v)& = (c', d')\end{align*}
    
    Then \[
        \PP[x, \rho^{(\alpha, \sigma)}] = \begin{cases}
            1 & |\rho| = 0\\
            \int_u^v \Lap_{\mu+a, b}(z)dz\PP[x, tail(\rho^{(\alpha, \sigma)})]& \sigma_0 \neq \texttt{insample}' \land r_0 \neq q_{init}\\
            \int_{u'}^{v'}\Lap_{\mu'+a, b'}(z')dz'\int_u^v \Lap_{\mu+a, b}(z)dz\PP[x, tail(\rho^{(\alpha, \sigma)})]& \sigma_0 = \texttt{insample}' \land r_0 \neq q_{init}\\
            \int_u^v \Lap_{\mu+a, b}(z)\PP[z, tail(\rho^{(\alpha, \sigma)})]dz& \sigma_0 \neq \texttt{insample}' \land r_0 = q_{init}\\
            \int_{u'}^{v'}\Lap_{\mu'+a, b'}(z')dz'\int_u^v \Lap_{\mu+a, b}(z)\PP[z, tail(\rho^{(\alpha, \sigma)})]dz& \sigma_0 = \texttt{insample}' \land r_0 = q_{init}
        \end{cases}
    \] 
    where $\Lap_{\mu, b}(x)$ is the PDF of a Laplace distribution with mean $\mu$ and spread parameter $b$ and $tail(\rho) = r_1\to\ldots\to r_n$.
\end{defn}

We now work towards defining what it means for an SSA to be differentially private. Recall that $\alpha$ is, in reality, a sequence of \textbf{functions} of some underlying dataset. This means that adjacency in this context is defined as follows:

\begin{defn}
    Two input sequences $\alpha, \alpha'$ of length $n$ are $\Delta$-adjacent if, for all $i\in [n]$, $|\alpha_i-\alpha'_i|\leq \Delta$. 

    Similarly, two paths $\rho^{(\alpha, \sigma)}$ and $\rho^{(\alpha', \sigma)}$ are $\Delta$-adjacent if $\alpha$ and $\alpha'$ are adjacent. 

    If $\Delta$ is not specified, we assume that $\Delta = 1$. 
\end{defn}

We can now define what it means for SSAs to be \textbf{differentially private}.

\begin{defn}
    An SSA $A(x)$ with initial value $x$ is $d\varepsilon$-differentially private if there exists some $d>0$ such that $\forall \varepsilon> 0$, for all paths $\rho$, possible outputs $\sigma$, and adjacent input sequences $\alpha\sim \alpha'$, $\PP[x, \rho^{(\alpha, \sigma)}]\leq e^{d\varepsilon}\PP[x, \rho^{(\alpha', \sigma)}]$. 

    Recall that $x$ is treated as a random variable drawn from a Laplace distribution. 
\end{defn}

Note that we slightly redefine $\varepsilon$-differential privacy as $d\varepsilon$-differential privacy, treating $\varepsilon$ as a universal scaling parameter that can be fine-tuned by users for their own purposes. 
In particular, we argue that this definition is functionally equivalent\footnote{\cite{chadhaLinearTimeDecidability2021} notes that it is not entirely clear how this differs from standard differential privacy, but that the known decidability result does not apply here - {\color{red} maybe something to investigate}}, since if we target $\varepsilon^*$-differential privacy, we can always take $\varepsilon = \frac{\varepsilon^*}{d}$.

\subsection{Coupling Strategies}

For an SSA $A(x)$ as defined above, there are a finite set of \textbf{strategies}, using approximate liftings, that we can use to show that $A(x)$ is $d\varepsilon$-differentially private. 


These \textbf{coupling strategies} are comprised of a series of liftings that, when combined together, will prove that $A$ is private. 

As a preliminary step, we fix $\varepsilon>0$ as a generic privacy scale parameter, as described previously. 

\subsubsection{A Discrete Set of Coupling Strategies}

First, fix some possible output $\sigma$ of $A$. Note that this implicitly also determines some path $\rho$ in $A$, since SSAs have no branching. Fix two adjacent datasets $X\sim X'$; this also determines two adjacent input sequences $\alpha, \alpha'$. We will consider the adjacent paths $\rho^{(\alpha, \sigma)}$ and $\rho^{(\alpha', \sigma)}$

For this path, we are aiming to construct the lifting $\rho(X)\{(a, b): a=o \implies b=o\}^{\#d\varepsilon}\rho(X')$. 

In particular, because SSAs have no branching, we must only ensure that all transitions in $\rho$ are taken and, if a real-value $r$ is output, that $A(X)$ outputting $r$ implies $A(X')$ outputting $r$ as well. 

We claim that, in all cases, we can select one of three \textbf{coupling strategies} that will allow us to construct the larger lifting for the entire segment. 

We will first set up some preliminary notation. Let $\rho = r_0\to r_1\to\ldots r_n$ where $r_0 = q_{init}$ and let $\sigma = \sigma_1\sigma_2\cdots\sigma_n$. 

For all states $r_i$, let $P(r_i) = (\frac{1}{d_i\varepsilon}, \frac{1}{d'_i\varepsilon})$ and let $z_i\sim \Lap(\frac{1}{d_i\varepsilon}), z'_i\sim \Lap(\frac{1}{d'_i\varepsilon})$ be the noises added to the input for $\texttt{insample}$ and $\texttt{insample}'$ at each state, respectively. Additionally, suppose that $\texttt{x} = x_0\sim \Lap(\mu_x, \frac{1}{d_x\varepsilon})$ initially.

Similarly, let $\texttt{in}_i$ for $i \in \{0,\ldots, n\}$ represent the input value read at each state $r_i$ and let $x$ be the value of the stored variable of $A$ after $q_0$. Note that $\texttt{insample}_i = \texttt{in}_i + z_i$ by definition.

For all of these variables $v$, let $v\brangle{1}$ represent its value in a run of $A(X)$, and let $v\brangle{2}$ represent its value in a run of $A(X')$. For example, this means that $\texttt{in}_i \brangle{1}= \alpha_i$ and $\texttt{in}_i\brangle{2} = \alpha'_i$. 
In particular, we will overload notation and use $\sigma\brangle{k}$ to represent the random variable corresponding to the output of run $k$\footnote{As distinguished from the fixed output $\sigma$ from before}.


We call the three coupling strategies we can apply $S^L, S^G$, and $S^N$. 

\textbf{Coupling Strategies 1 and 2}: $S^L$ and $S^G$. 

Suppose that $\trans(r_0)$ does not output $\texttt{insample}$. If it does, then we cannot use $S^L$, and must use $S^N$.

Create the lifting $z_0\brangle{1} (=)^{\#2d_0\varepsilon} z_0\brangle{2} + \texttt{in}_0\brangle{2}- \texttt{in}_0\brangle{1} - 1$. 
Note that since $\texttt{insample}_0$ gets assigned into $\texttt{x}$ and $\texttt{insample}_0 = \texttt{in}_0 + z_0$, this is equivalent to constructing the lifting $x\brangle{1} + 1 (=)^{\#2d_0\varepsilon}x\brangle{2}$. 

Recall that $|\texttt{in}_0\brangle{1}-\texttt{in}_0\brangle{2}|\leq 1$ since the input sequences $\alpha, \alpha'$ are (1-)adjacent; this is why the lifting has a cost of $2d_0\varepsilon$. 

We must ensure that the initial transition guard $\guard(r_0)$ is satisfied. This is a unique situation because this guard is dependent on the \textit{initial} value of $\texttt{x} = x_0$; all later guards will depend on the value that $\texttt{x}$ takes \textit{after} this transition. 

If $\guard(r_0) = \texttt{true}$ this is trivially satisfied. Otherwise, if $\guard(r_0) = \lguard$, then if we construct $x_0\brangle{1}+1(=)^{\#d_x\varepsilon}x_0\brangle{2}$, we have that $\texttt{insample}_0\brangle{1} < x_0\brangle{1}+1\implies \texttt{insample}_0\brangle{2}-1<x_0\brangle{2}-1$. 

Similarly, if $\guard(r_0) = \gguard$, then if we construct $x_0\brangle{1}(=)^{\#0}x_0\brangle{2}$, we have that $\texttt{insample}_0\brangle{1} \geq x_0\brangle{1}\implies \texttt{insample}_0\brangle{2} \geq x_0\brangle{2}$.

Although we can freely couple $x_0\brangle{1}$ and $x_0\brangle{2}$ together in this case, we will see that with more complicated families of automata, there may be additional restrictions on $x_0$ that constrain our ability to do so in the future. 

We now consider all transitions after the initial transition. Fix some $i\in\{1, \ldots, n-1\}$. 

If $\trans(r_i)$ outputs $\texttt{insample}$, then construct the lifting $z_i\brangle{1} (=)^{\#d_i}z_i\brangle{2} + \texttt{in}_i\brangle{2}-\texttt{in}_0\brangle{1}$. This is equivalent to constructing the lifting $\texttt{insample}\brangle{1} (=)^{\#d_i}\texttt{insample}\brangle{2}$.

Similarly, if $\trans(r_i)$ outputs $\texttt{insample}'$, then construct the lifting \\$\texttt{insample}'\brangle{1} (=)^{\#(d'_i, 0)} \texttt{insample}'\brangle{2}$.


Otherwise if $\guard(r_i) = \lguard$, construct the lifting $z_i\brangle{1} (=)^{\#(0, 0)}z_i\brangle{2}$. If $\trans(r_i)$ doesn't output $\texttt{insample}$ and $\guard(r_i) = \gguard$, construct the lifting $z_i\brangle{1} + 2 (=)^{\#(2\epsilon_i, 0)}z_i\brangle{2}$. 

Because every transition must have an output, we can construct our final lifting by creating liftings for each character of the output; i.e. creating the liftings $\sigma_i\brangle{1}\{(a, b): o = a\implies o=b\}^{\#d_i}\sigma_i\brangle{2}$ for all $i$. 

We claim that if $\sigma_i \in \Gamma$ and $\guard(a_i) \in \{\lguard, \texttt{true}\}$, we can construct the lifting $\sigma_i\brangle{1}\{(a, b): a = \sigma_i \implies b = \sigma_i\}^{\#0}\sigma_i\brangle{2}$. 

We demonstrate why this holds for $\guard(a_i) = \lguard$: \begin{align*}\sigma_i\brangle{1} = \sigma_i&\implies A(X)\text{ takes }\trans(a_i)\\
&\implies \texttt{in}_i\langle 1 \rangle + z_i\langle 1 \rangle < x\langle 1 \rangle\\
&\implies\texttt{in}_i\langle 1 \rangle +1 + z_i\langle 2 \rangle < x\langle 2 \rangle\\
&\implies\texttt{in}_i\langle 2 \rangle + z_i\langle 2 \rangle < x\langle 2 \rangle\\
&\implies \mathcal{A}(X')\text{ takes }\trans(a_i)\\
&\implies \sigma_i\brangle{2} = \sigma_i
\end{align*}

When $\sigma_i = \texttt{insample}$ or $\sigma_i = \texttt{insample}'$, a similar analysis holds, with the additional caveat that $\texttt{insample}\brangle{1} = \texttt{insample}\brangle{2}$ and $\texttt{insample}'\brangle{1} = \texttt{insample}'\brangle{2}$ hold, as guaranteed by a previous lifting. 

Similarly, if $\sigma_i \in \Gamma$ and $\guard(r_i) = \gguard$, then we can construct the lifting $\sigma_i\brangle{1}\{(a, b): a = \sigma_i \implies b = \sigma_i\}^{\#2d_i}\sigma_i\brangle{2}$.

However, if $\sigma_i = \texttt{insample}$ and $\guard(r_i) = \gguard$, the only lifting we can construct is $\sigma_i\brangle{1}\{(a, b): a = \sigma_i \implies b = \sigma_i\}^{\#\infty}\sigma_i\brangle{2}$. If this is the case, we say $r_i$ is \textit{faulty} (in the context of $S^L$).

Intuitively, with some overhead initial privacy cost, we assign 0 cost to every transition with guard $\lguard$ and twice the standard cost to every transition with guard $\gguard$, which is why we call this strategy $S^L$ (for ``less than'').

Indeed, we have the following transition cost function for $i\in\{1, \ldots, n-1\}$:
\[
    c^L(t_i) = \begin{cases}
        0 & \sigma_i \in \Gamma \land \guard(t_i)\neq \gguard\\
        d_i & \sigma_i = \texttt{insample}\land \guard(t_i)\neq \gguard\\
        d'_i & \sigma_i = \texttt{insample}'\land \guard(t_i)\neq \gguard\\
        2d_i & \sigma_i \in \Gamma \land \guard(t_i) =\gguard\\
        \infty & \sigma_i = \texttt{insample} \land \guard(t_i) =\gguard\\
        2d_i +d'_i& \sigma_i = \texttt{insample}' \land \guard(t_i) =\gguard
    \end{cases}    
\] 

By sequential composition of liftings, we have $\rho_\sigma(X)\{(a, b): a = \sigma_k \implies b = \sigma_k\}^{\#d_L\varepsilon}\rho_\sigma(X')$, where the total privacy cost $d_L^\rho$ of $S^L$ on path $\rho$ is \[
	d_L^\rho=2d_0+ \sum_{i\in\{1, \ldots, n-1\}}c^L(t_i)
\]

Note that for an SSA, $d_L < \infty$ if and only if no transitions in $d_L$ are faulty. 

The construction and cost of $S^G$ is exactly symmetric. 

\textbf{Coupling Strategy 3:} $S^N$.

As mentioned, there are occasional restrictions on when $S^L$ and $S^G$ can be used to prove the privacy of a segment. In particular, if $\trans(r_0)$ outputs $\texttt{insample}$, or if both a $\lguard$ and a $\gguard$ transition output $\texttt{insample}$, then neither $S^G$ nor $S^L$ are valid. For this scenario, we define the coupling strategy $S^N$ as follows. 

Fix some $i\in\{0, \ldots, n-1\}$. 

For all states $r_i$, construct the lifting $z_i\brangle{1} (=)^{\#(d_i\varepsilon, 0)}z_i\brangle{2}+ \texttt{in}_i\brangle{2}- \texttt{in}_i\brangle{1}$. This is equivalent to constructing the lifting $\texttt{insample}\brangle{1} (=)^{\#d_i\varepsilon}\texttt{insample}\brangle{2}$. For $i=0$, this specifically also is equivalent to constructing the lifting $x\brangle{1} (=)^{\#d_0\varepsilon}x\brangle{2}$

Again, if $\trans(r_i)$ outputs $\texttt{insample}'$, then construct the lifting \\$\texttt{insample}'\brangle{1} (=)^{\#(d'_i, 0)} \texttt{insample}'\brangle{2}$.

As before, we must ensure that the initial transition guard $\guard(r_0)$ is satisfied.

We claim that $x_0\brangle{1}(=)^{\#0}x_0\brangle{2}$, which is sufficient to show that $\guard(r_0)$ is satisfied in $A(X)\implies \guard(r_0)$ is satisfied in $A(X')$.

We claim that if $\sigma_i \in \Gamma\cup\{\texttt{insample}\}$, we can construct the lifting $\sigma_i\brangle{1}\{(a, b): a = \sigma_i \implies b = \sigma_i\}^{\#d_i\varepsilon}\sigma_i\brangle{2}$. 

Otherwise, if $\sigma_i = \texttt{insample}'$, then we can construct the lifting $\sigma_i\brangle{1}\{(a, b): a = \sigma_i \implies b = \sigma_i\}^{\#(d_i+d'_i)\varepsilon}\sigma_i\brangle{2}$

This gives us the following transition cost function for $i\in [n-1]$:
\[
    c^N(t_i) =\begin{cases}
        d_i & \sigma_i \neq \texttt{insample}'\\
        d_i +d'_i& \sigma_i = \texttt{insample}'
    \end{cases}    
\] 


Thus by sequential composition of liftings, we have $\rho_\sigma(X)\{(a, b): a = \sigma_k \implies b = \sigma_k\}^{\#d_N\varepsilon}\rho_\sigma(X')$, where the total privacy cost $d_N^\rho$ of $S^N$ on path $\rho$ is \[d_N^\rho= \sum_{i\in [n-1]} c^N(t_i).\]

$S^N$ (the ``null'' coupling strategy) assigns each transition cost proportional to the spread parameter of the Laplace distribution being sampled from at each transition. With $S^N$, we gain flexibility in outputting $\texttt{insample}$ at the cost of every transition being ``costly''.

\subsubsection{Privacy}

\begin{defn}
    The coupling costs $d_N, d_L, d_G$ for an SSA $A$ are defined as \begin{align*}
        d_N &= \sup_{\rho} d_N^\rho\\
        d_L &= \sup_{\rho} d_L^\rho\\
        d_G &= \sup_{\rho} d_G^\rho
    \end{align*}
\end{defn}


\begin{prop}
    If an SSA $A(x)$ has coupling costs $d_N, d_L, d_G$, $A(x)$ is \\
    $\min\{d_N, d_L, d_G\}\varepsilon$-differentially private. 
\end{prop}

\begin{proof}
    For every output $\sigma$ and associated path $\rho$, we have shown that the lifting \[A(x)(X)\{(a, b): a = \sigma \implies b=\sigma\}^{\#\min\{d_N^{\rho}, d_L^{\rho}, d_G^{\rho}\}\varepsilon}A(x)(X')\] is valid for adjacent datasets $X\sim X'$. In particular, note that at least $d_N^\rho$ is always finite. 
    
    Because there are a finite set of paths through $A$, $d_N$, $d_L$, $d_G$ are always finite if for all $\rho$, $d_N^\rho$, $d_L^\rho$, and $d_G^\rho$ are finite, respectively.
    
    Thus, we can construct the lifting \[A(x)(X)\{(a, b): a = \sigma \implies b=\sigma\}^{\#\min\{d_N, d_L, d_G\}\varepsilon}A(x)(X'),\]
    which gives us the finite cost $d = \min\{d_N, d_L, d_G\}$.
    Applying theorem \ref{implicationcouplingthm} then completes the proof.
\end{proof}

It is worth noting that all SSAs are inherently $d\varepsilon$-differentially private for \textit{some} $d > 0$ because there are a finite number of paths through any SSA $A$.

Thus, we now examine an extension of SSAs that allows for loops in which this is not necessarily the case. 

\subsection{Loops}
\begin{defn}\label{LSADefn}
    A looping segment automaton (LSA) $A(x)$ with initial value $x\in \RR$ is a tuple $(Q, \Sigma, C, \Gamma, q_{init}, X, P, \delta)$ where $(Q, \Sigma, C, \Gamma, q_{init}, X, P, \delta)$ are defined exactly as in \ref{SSADefn}, \textbf{except} that $\delta$ has the following, changed set of restrictions: \begin{itemize}  
        \item \textbf{Determinism:} For any state $q\in Q$, if $\delta(q,\texttt{true})$ is defined, then $\delta(q,\lguard)$ and $\delta(q,\gguard)$ are not defined. 

        \item \textbf{Output Distinction:} For any state $q\in Q$, if $\delta(q, \gguard) = (q_1, o_1, b_1)$ and $\delta(q, \lguard) = (q_2, o_2, b_2)$, then $o_1\neq o_2$ and at least one of $o_1\in \Gamma$ and $o_2\in \Gamma$ is true.
        \item \textbf{No Branching:} If $\delta(q, \lguard)$ and $\delta(q, \gguard)$ {\color{red}figure out exactly how to define this later}
        \item Also $q_{init}$ can't be in a cycle. 
    \end{itemize}

    As with SSAs, $A(x)$ is parameterized by some initial real value $x$, stored in the variable $\texttt{x}$ and we will treat $x$ as a random variable drawn from some Laplace distribution.
\end{defn}

\begin{defn}
    A cycle $C$ in an SSA $A$ is a \gcycle\ if there exists a transition $t$ in $C$ with guard $\guard(t) = \gguard$. Similarly, $C$ is an \lcycle\ if there exists a transition $t$ in $C$ with guard $\guard(t) = \lguard$.
\end{defn}

Note that a cycle can be both an \lcycle~and a \gcycle.\ Also, we will assume that all executions of an LSA $A$ terminate; this means that every cycle in $A$ \textit{must} be either an \lcycle~or a \gcycle.

Paths, path probabilities, and the concept of $d\varepsilon$-differential privacy remain identical for LSAs as for SSAs. 

Importantly, the same three coupling strategies for SSAs are still valid proof strategies for LSAs. 

\begin{prop}\label{LSAcouplingsvalid}
    For an LSA $A$, if at least one of $S^N, S^L$, or $S^G$ have finite coupling cost on $A$, then $A$ is $\min\{\varepsilon_N, \varepsilon_L, \varepsilon_G\}$-differentially private. 
\end{prop}

The proof of validity for coupling strategies on SSAs holds for LSAs as well.

However, now that LSAs can \textit{fail} to be differentially private, it is worth exploring in exactly what scenarios LSAs will or will not be private, and what couplings have to say about them.

We begin by identifying three graph-theoretic structures that mean that an LSA is not private. 

\begin{defn}
    A \textbf{leaking pair} in an LSA $A$ is a pair of cycles $C, C'$ in $A$ such that there exists a path from $C$ to $C'$, $C$ is an \lcycle, and $C'$ is a \gcycle(or vice versa). 
\end{defn}

\begin{defn}
    A \textbf{disclosing cycle} in an LSA $A$ is a cycle $C$ in $A$ where a transition in $C$ outputs either $\texttt{insample}$ or $\texttt{insample}'$.
\end{defn}

\begin{defn}
    A \textbf{privacy violating path} in an LSA $A$ is a path $\rho = q_0\to q_1\to\ldots\to q_n$ in $A$ such that one of the following conditions holds:\begin{itemize}
        \item $q_0= q_{init}$, $\trans(q_0)$ outputs $\texttt{insample}$, and $q_n$ is in a \gcycle\ or an \lcycle.
        \item $q_n$ is in a \gcycle (symmetrically, \lcycle), $\guard(q_0) =\lguard$ (symmetrically, $\gguard$), and $\trans(q_0)$ outputs $\texttt{insample}$.
        \item $q_0$ is in a \gcycle (symmetrically, \lcycle), $\guard(q_n) =\lguard$ (symmetrically, $\gguard$), and $\trans(q_n)$ outputs $\texttt{insample}$.
    \end{itemize}
\end{defn}

\begin{prop}\label{LSAnotwellformed}
    If an LSA $A$ contains a leaking pair, a disclosing cycle, or privacy violating path, then $A$ is not $d\varepsilon$-differentially private for any $d>0$. 
\end{prop}

The proof can be found in~\cite{chadhaLinearTimeDecidability2021}.

Perhaps surprisingly, we can thus show that if none of the coupling strategies have finite coupling cost for an LSA $A$, then $A$ is not $d\varepsilon$-differentially private. 

\begin{lemma}
    For an LSA $A$, $d_N < \infty$ if and only if there is no cycle in $A$. Further, if there exists an \lcycle~in $A$, then $d_G = \infty$ and if there exists a \gcycle~in $A$, then $d_L = \infty$. 
\end{lemma}
\begin{proof}
    Follows immediately from the coupling strategies cost functions. 
\end{proof}

\begin{lemma}
    For an LSA $A$, there exists a global bound $N_A\in \NN$ such that every path $\rho$ in $A$ has at most $N_A$ non-cycle transitions. 
\end{lemma}
\begin{proof}
    Follows from the fact that $A$ has a finite number of states. 
\end{proof}

\begin{lemma}\label{LSAnocouplingsnotwellformed}
    If $d_N =\infty, d_L=\infty$, and $d_G=\infty$, then $A$ must contain a leaking pair, a disclosing cycle, or a privacy violating path. 
\end{lemma}
\begin{proof}
    Because $d_N = \infty$, we know there must be some cycle $C$ in $A$. WLOG suppose that $C$ is an \lcycle. 
    
    If $C$ is also a \gcycle, then $C$ is a leaking pair with itself, so we can assume that $C$ is not also a \gcycle. Similarly, if $\trans(q_0)$ outputs $\texttt{insample}$, then there must be a privacy violating path from $q_0$ to $C$, so suppose $\trans(q_0)$ doesn't output $\texttt{insample}$. 

    Suppose that there are no disclosing cycles and no leaking pairs in $A$. Because there are no leaking pairs, a \gcycle~cannot exist in $A$. Additionally, because there are no disclosing cycles and no \gcycle{}s, every cycle transition $t$ must have $c^L(t) = 0$. Because there are a bounded number of non-cycle transitions in $A$, $d_L$ can only be $\infty$ if there exists a faulty transition with respect to $S^L$ in $A$. 
    Thus, there must be some transition with guard $\gguard$ that outputs $\texttt{insample}$; the path from or to this transition from $C$ must be a privacy violating path. 

    Now suppose that there are no privacy violating paths and no leaking pairs in $A$. If there is no privacy violating path, then there can be no faulty transitions with respect to $S^L$ in $A$ by the reasoning above. Because of the bound on non-cycle transitions in a path in $A$, $d_L=\infty$ only if there exists some cycle transition $t_i$ in $A$ with non-zero cost. 
    In particular, because there are no leaking pairs, every cycle in $A$ only has transitions with guard $\lguard$. In order for such a transition $t_i$ to have cost $c^L(t_i) > 0$, $t_i$ must output either $\texttt{insample}$ or $\texttt{insample}'$, creating a disclosing cycle.

    Finally, suppose that there are no privacy violating paths and no disclosing cycles in $A$. As before, there can be no faulty transitions with respect to $S^L$ in $A$ and every cycle transition with guard $\lguard$ or $\texttt{true}$ must have cost 0. Again because of the bound on non-cycle transitions in a path in $A$, this implies that there must be some cycle transition in $A$ with guard $\gguard$, creating a \gcycle.
\end{proof}

\begin{thm}
    An LSA $A$ is $d\varepsilon$-differentially private if and only if $\min\{d_N, d_L, d_G\}<\infty$.
\end{thm}
\begin{proof}
    This follows directly from proposition \ref{LSAcouplingsvalid}, proposition \ref{LSAnotwellformed}, and lemma \ref{LSAnocouplingsnotwellformed}.
\end{proof}

\subsection{Branching}

\begin{defn}
    A segment automaton (SA) $A(x)$ with initial value $x\in \RR$ is a tuple $(Q, \Sigma, C, \Gamma, q_{init}, X, P, \delta)$ where $(Q, \Sigma, C, \Gamma, q_{init}, X, P, \delta)$ are defined exactly as in \ref{SSADefn} and \ref{LSADefn}, except that $\delta$ has the following set of restrictions: \begin{itemize}  
        \item \textbf{Determinism:} For any state $q\in Q$, if $\delta(q,\texttt{true})$ is defined, then $\delta(q,\lguard)$ and $\delta(q,\gguard)$ are not defined. 

        \item \textbf{Output Distinction:} For any state $q\in Q$, if $\delta(q, \gguard) = (q_1, o_1, b_1)$ and $\delta(q, \lguard) = (q_2, o_2, b_2)$, then $o_1\neq o_2$ and at least one of $o_1\in \Gamma$ and $o_2\in \Gamma$ is true.
        \item $q_{init}$ is not in a cycle. 
    \end{itemize}

    As before, $A(x)$ is parameterized by some initial real value $x$, stored in the variable $\texttt{x}$ and we will treat $x$ as a random variable drawn from some Laplace distribution.
\end{defn}

Once branching gets added into the program model, a single coupling strategy no longer works for the entire automaton; instead, each distinct branch of the automaton will require a possibly different coupling strategy. 

\begin{defn}
    Consider a path $\rho$ in an SA $A$. Let $acyclic(\rho)$ be a function that given a path $\rho$, removes all cycles in $\rho$; i.e. if $\rho = q_0\to \ldots\to q_n$, $acyclic(\rho) = q_{x_0}\to \ldots \to q_{x_k}$, where $\{x_i\}_{i=0}^k$ is the longest possible subsequence of $[n]$ such that $i\neq j\implies q_{x_i}\neq q_{x_j}$. 
    
    Let $\equiv_b$ be an equivalence relation between paths of $A$ where $\rho\equiv_b\rho'$ iff $acyclic(\rho) = acyclic(\rho')$. Then $branches(A)$ is the set of equivalence classes of $\equiv_b$. 
\end{defn}

Note that there are a finite number of branches for every segment automaton. We aim to assign one coupling strategy to each \textbf{branch}. In particular, note that each branch taken in isolation is itself an LSA, so that every segment automaton can be viewed as a combined set of parallel and overlapping looping segment automata. 

As before, we can define the cost of each branch under each coupling stategy.

\begin{defn}
    Let $A(x)$ be a segment automaton. For a branch $B\in branches(A)$ of $A$, the coupling costs of $S^N, S^L$, and $S^G$ are, respectively,
    \begin{align*}
        d_N^{(B)} &= \sup_{\rho\in B} d_N^\rho\\
        d_L^{(B)} &= \sup_{\rho\in B} d_L^\rho\\
        d_G^{(B)} &= \sup_{\rho\in B} d_G^\rho
    \end{align*}
\end{defn}


\begin{prop}
    Consider an SA $A(x)$. If for all branches $B\in branches(A)$ there exists a coupling strategy $S_X^{(B)}$ with finite coupling cost $d_X^{(B)} <\infty$, then $A(x)$ is $d\varepsilon$-differentially private, where \[
        d = \max_{B\in branches(A)} d_X^{(B)}   
    \]
\end{prop}
\begin{proof}
    For every output $\sigma$ and associated path $\rho_\sigma$, we have the lifting \[
        A(x)(X)\{(a, b): a = \sigma \implies b=\sigma\}^{\#\min\{d_N^{(B)}, d_L^{(B)}, d_G^{(B)}\}\varepsilon}A(x)(X'),
    \]
    where $\rho_\sigma\in B\in branches(A)$. 

    This means that for all outputs $\sigma$ and adjacent datasets $X\sim X'$,
    \[\PP[A(X) = \sigma] \leq e^{d_X^{(B)}\varepsilon}\PP[A(X')=\sigma],\]
    where again $\rho_\sigma \in B$ and $d_X^{(B)}=\min\{d_N^{(B)}, d_L^{(B)}, d_G^{(B)}\}$.

    This means that for all outputs $\sigma$ and adjacent datasets $X\sim X'$,    
    \[\PP[A(X) = \sigma] \leq e^{\max_{B\in branches(A)}\{d_X^{(B)}\}\varepsilon}\PP[A(X')=\sigma],\]
    which completes the proof.
\end{proof}

For the exact same reason as LSAs, these coupling strategies indeed still completely characterize the privacy of SAs.

\begin{prop}
    An SA $A(x)$ is $d\varepsilon$-differentially private if and only if for all branches $B\in branches(A)$ there exists a coupling strategy with finite coupling cost $d_X^{(B)}$.
\end{prop}

\begin{proof}
    Because each branch of a segment automaton is an LSA, this again follows directly from proposition \ref{LSAcouplingsvalid}, proposition \ref{LSAnotwellformed} (from \cite{chadhaLinearTimeDecidability2021} the same result holds for segment automata), and lemma \ref{LSAnocouplingsnotwellformed}.
\end{proof}

\section{DiPA}

We now introduce the final extension to our program model. 

\begin{defn}[\cite{chadhaLinearTimeDecidability2021}]
    A DiP\footnote{\textbf{Di}fferentially \textbf{P}rivate} Automaton (DiPA) $A$ is a 7-tuple $(Q, \Sigma, C, \Gamma, q_{init}, X, P, \delta)$ where
    \begin{itemize}
        \item $Q$ is a finite set of states partitioned into input states $Q_{in}$ and non-input states $Q_{non}$. 
        \item $\Sigma = \RR$ is the input alphabet
        \item $C = \{\texttt{true}, \lguard, \gguard\}$ is a set of guard conditions
        \item $\Gamma$ is a finite output alphabet
        \item $q_{init}\in Q$ is the initial state
        \item $X = \{\texttt{x}, \texttt{insample}, \texttt{insample}'\}$ is the set of variables
        \item $P: Q\to \QQ\times \QQ^{\geq 0}\times \QQ\times  \QQ^{\geq 0}$ is a parameter function that assigns sampling parameters for the Laplace distribution for each state
        \item $\delta:(Q\times C)\to (Q\times (\Gamma \cup \{\texttt{insample}, \texttt{insample}'\})\times \{\texttt{true}, \texttt{false}\})$ is a partial transition function. 
    \end{itemize}
    In addition, $\delta$ must satisfy some additional conditions:
    
    \begin{itemize}
        \item \textbf{Determinism:} For any state $q\in Q$, if $\delta(q,\texttt{true})$ is defined, then $\delta(q,\lguard)$ and $\delta(q,\gguard)$ are not defined. 

        \item \textbf{Output Distinction:} For any state $q\in Q$, if $\delta(q, \gguard) = (q_1, o_1, b_1)$ and $\delta(q, \lguard) = (q_2, o_2, b_2)$, then $o_1\neq o_2$ and at least one of $o_1\in \Gamma$ and $o_2\in \Gamma$ is true.

        \item \textbf{Initialization:} The initial state $q_0$ has only one outgoing transition of the form $\delta(q_0, \texttt{true}) = (q, o, \texttt{true})$.

        \item \textbf{Non-input transition:} From any $q\in Q_{non}$, if $\delta(q, c)$ is defined, then $c=\texttt{true}$.
    \end{itemize}

    A DiPA $A$ functions almost identically to the previous automata we have defined, except that instead of only the first transition of $A$ assigning into $\texttt{x}$, now any \textbf{assignment transition} can re-assign the value of $\texttt{x}$ to be $\texttt{insample}$. In addition, DiPAs are no longer dependent on an initial value for $\texttt{x}$, since the first transition must always be a $\texttt{true}$ guard assignment transition.
\end{defn}

Note that we can treat a DiPA $A$ as a (possibly infinite, if an assignment transition is in a cycle) set of segment automata by ``splitting'' at every assignment transition in $A$. 


\begin{defn}
    For a path $\rho$ in a DiPA $A$, let $segments(\rho)$ be the set of subpaths of $\rho$ created by splitting $\rho=r_0\to\ldots\to r_n$ at each assignment transition. 
    
    More precisely, let $I$ be the ordered set of indices such that $\trans(r_{I_i})$ for $i\in [|I|]$ is an assignment transition. Then $segments(\rho) = \{r_0\to\ldots\to r_{I_0}, \ldots, r_0\to\ldots\to r_{I_k}\}$.
\end{defn}

\begin{defn}
    Let $A$ be a DiPA and let $P$ be the set of all paths through $A$. 
    
    Then $branches(A) = \bigcup_{\rho\in P}\bigcup_{\eta\in segments(\rho)} acyclic(\eta)$ be the set of branches in $A$.
\end{defn}

Note that every path in $A$ can be broken up into a sequence of branches, each from its own segment. 

\subsection{Joining Coupling Strategies}

Naively, the fact that we can separate a DiPA $A$ into a set of segment automata would suggest an approach of assigning a coupling strategy to each branch of $A$ as before and simply combining these coupling strategies in sequence. However, it is not always possible to arbitrarily join coupling strategies together. 

This is primarily because we can no longer freely decide the initial value for $\texttt{x}$ at the beginning of each segment, as we could with segment automata. Recall that for a fixed path $\rho = r_0\to\ldots\to r_n$, it was important that the initial transition guard $\guard(r_0)$ is satisfied. 
Notably, whether or not the initial guard is satisfied is dependent on the initialized value of $\texttt{x}$; since we had no additional restrictions on $\texttt{x}$, we were able to (for example) arbitrarily couple $x_0\brangle{1}+1(=)^{\#d_x\varepsilon}x_0\brangle{2}$.

However, now that we have joined multiple segment automata together, the initial value $x_0$ for a segment automata is actually the assigned value $\texttt{x}$ from the \textit{previous} segment automata. 
This means that $x_0\brangle{1}$ and $x_0\brangle{2}$ will already be coupled together, perhaps in a way such that coupling $\texttt{insample}_0\brangle{1}$ and $\texttt{insample}_0\brangle{2}$ will be impossible to both ensure the correct shift of $\texttt{x}$ for the new coupling strategy and so that the initial guard is satisfied.

For example, consider two paths $\rho = r_0\to\ldots\to r_n$ and $\rho' = q_1\to \ldots \to q_m$ with the assignment transition $r_n\to q_1$ connecting them, where $\guard(r_n) = \gguard$. We are aiming to choose one coupling strategy for each of $\rho$ and $\rho'$. 

If $S^L$ is chosen for $\rho$, then at the connecting assignment transition, $x_0$ is coupled such that $x_0\brangle{1}+1 =x_1\brangle{1}$. Further, we would like to couple $\texttt{insample}_0$ such that $\texttt{insample}_0\brangle{1} = \texttt{insample}_0\brangle{2}+1$. However, trying to create this lifting while also ensuring that the implication $\texttt{insample}_0\brangle{1} \geq x_0\brangle{1}\implies \texttt{insample}_0\brangle{2} \geq x_0\brangle{2}$ holds is impossible. 

Thus, we cannot choose $S^G$ for a segment that follows a segment with coupling strategy $S^L$ if the connecting assignment transition has guard $\gguard$. There are a series of similar restrictions on how coupling strategies can be connected for adjacent segments, which along with previous restrictions on coupling strategies (e.g. we cannot choose $S^G$ or $S^L$ if the first transition of a segment outputs $\texttt{insample}$).

\subsection{A Constraint System for Valid Couplings}

Based on the restrictions on joining segments together, we can construct a set of constraints on coupling strategies for a DiPA $A$ that, if solved, will give us a valid proof of $d\varepsilon$-differential privacy.

\begin{const}\label{constraintsystem}
    Consider a DiPA~$A$.
    
    For each branch $s_i\in branches(A)$, we can assign one of three coupling strategies $S_i \in \{S^L, S^G, S^N\}$. We would like to find an assignment of coupling strategies for each segment of each variable, subject to the following constraints: 

    \begin{enumerate}
        \item Constraints for valid couplings\begin{enumerate}
            \item For all $s_i$, if $\trans(s_i)$ outputs $\texttt{insample}$, then $S_i = S^N$.
            \item For all $s_i, s_j$ such that $s_i$ is directly followed by $s_j$, \begin{enumerate}
                \item If $\guard(s_j)=\lguard$ and $S_i = S^G$, then $S_j = S^G$. 
                \item If $\guard(s_j) = \gguard$ and $S_i = S^L$, then $S_j = S^L$.
                \item If $\guard(s_j) = \lguard$ and $S_i = S^N$, then $S_j\neq S^L$.
                \item If $\guard(s_j) = \gguard$ and $S_i = S^N$, then $S_j\neq S^G$.
            \end{enumerate}
           
        \end{enumerate}
        \item Constraints for finite cost\begin{enumerate}
            \item For all $s_i$, no cycle in $s_i$ has a transition that outputs $\texttt{insample}$ or $\texttt{insample}'$. 
            \item For all $s_i$, if $s_i$ has an $\texttt{L}$-cycle, then $S_i = S^L$.
            \item For all $s_i$, if $s_i$ has a $\texttt{G}$-cycle, then $S_i = S^G$. 
            \item For all segments $s_i$, there is no transition $\trans(a_k)$ in $s_i$ that is \textit{faulty}, i.e.:\begin{enumerate}
                \item If $s_i$ contains a $\lguard$ transition that outputs $\texttt{insample}$, then $S_i \neq S^G$.
                \item If $s_i$ contains a $\gguard$ transition that outputs $\texttt{insample}$, then $S_i \neq S^L$.
            \end{enumerate}
        \end{enumerate}
    \end{enumerate}
\end{const}

\begin{thm}\label{constraintsatisfiableprivatethm}
    Let $A$ be a DiPA.\ If $|branches(A)|< \infty$ and for each branch $B\in branches(A)$, there exists an assignment of coupling strategies to each segment that satisfies the constraint system defined in \ref{constraintsystem}, then $A$ is $d\varepsilon$-differentially private for \[d=\sum_{s_i\in branches(A)}d_{s_i},\]
    where $d_{s_i}$ is the cost of the satisfying assignment strategy $S_i$ for a branch $s_i$.  
\end{thm}
\begin{proof}
    Let $\rho$ be a path through $A$ that is composed of branches $s_{x_1}\to \ldots\to s_{x_k}$ and let $S_{x_1}, \ldots, S_{x_k}$ be the associated coupling strategies from the satisfying assignment. 

    Because of constraints (1a-1b), we can actually compose each coupling strategy in sequence to create a valid lifting $A(X)\{(a, b): a=\sigma \implies b=\sigma\}A(X')$ for all adjacent datasets $X\sim X'$ and possible outputs $\sigma$ of $\rho$. 

    In addition, we claim that the cost of the satisfying assignments $d_{s_i}$ is bounded for all $s_i$. There are two ways for a branch cost $d_{s_i}$ to be unbounded: either a cycle transition has non-zero cost, or a transition has to be faulty with respect to the chosen coupling strategy. From constraint (2d), we know that no transitions can be faulty, and we know from constraints (2a-2c) that every cycle transition has to have zero cost. 

    Finally, the fact that $|branches(A)|<\infty$ and every path can go through each branch at most one time gives us the bound on $d$. 
\end{proof}


\subsection{Well-formedness}

Similar to before, \cite{chadhaLinearTimeDecidability2021} define four structures in the graphs of DiPAs that characterize privacy for DiPAs. Within DiPAs, these graph structures can be defined as follows:\begin{itemize}
    \item \textbf{Leaking Cycles}: A cycle $C$ is a leaking cycle if one of the transitions in $C$ is an assignment transition.
    \item \textbf{Leaking Pair}: A pair of cycles $C$, $C'$ are a leaking pair if $C$ is an \lcycle, $C'$ is a \gcycle, and there exists a path from $C$ to $C'$ such that every assignment transition on the path has guard $\gguard$; or, symmetrically, $C$ is an \gcycle, $C'$ is a \lcycle, and there exists a path from $C$ to $C'$ such that every assignment transition on the path has guard $\lguard$.
    \item \textbf{Disclosing Cycle}: A cycle $C$ is a disclosing cycle if a transition in $C$ outputs either $\texttt{insample}$ or $\texttt{insample}'$. 
    \item \textbf{Privacy Violating Path}: A path $\rho = q_0\to\ldots \to q_n$ is a privacy violating path if any of the following conditions hold:\begin{itemize}
        \item $q_1\to\ldots q_n$ is a path whose assignment transitions all have guard $\gguard$ (resp.\ $\lguard$) such that $q_n$ is part of a \gcycle\ (resp.\ \lcycle) and $\trans(q_0)$ is an assignment transition that outputs $\texttt{insample}$. 
        \item $\rho$ is a path whose assignment transitions all have guard $\gguard$ (resp.\ $\lguard$) such that $q_n$ is part of a \gcycle\ (resp.\ \lcycle), $\guard(q_0) = \lguard$ (resp.\ $\gguard$), and $\trans(q_0)$ outputs $\texttt{insample}$.
        \item $\rho$ is a path whose assignment transitions all have guard $\gguard$ (resp.\ $\lguard$) such that $q_0$ is part of a \lcycle\ (resp.\ \gcycle), $\guard(q_{n-1}) = \gguard$ (resp.\ $\lguard$), and $\trans(q_{n-1})$ outputs $\texttt{insample}$.
    \end{itemize}
\end{itemize}



\begin{defn}
    A DiPA $A$ is \textbf{well-formed} if it does not have a leaking cycle, leaking pair, disclosing cycle, or privacy violating path. 
\end{defn}

Importantly, \cite{chadhaLinearTimeDecidability2021} have shown that the existence of these graph structures completely decides whether or not a DiPA is $d\varepsilon$-differentially private. 
\begin{thm}[\cite{chadhaLinearTimeDecidability2021}]
    A DiPA $A$ is $d\varepsilon$-differentially private for some $d > 0$ if and only if $A$ is well-formed. Further, the well-formedness of an automaton $A$ can be decided in linear time in the size of $A$. 
\end{thm}

We will leverage this result to show that the existence of valid coupling strategies is also a complete characterization of DiPAs.

\begin{lemma}\label{leakingcyclesbrancheslemma}
    For a DiPA $A$, $|branches(A)|< \infty$ if and only if $A$ has no leaking cycles. 
\end{lemma}

\begin{lemma}\label{unsatisfiablenoprivacylemma}
    Suppose a DiPA $A$ has a finite number of branches. If constraint system \ref{constraintsystem} is not satisfiable, there must exist a leaking cycle, a leaking pair, a disclosing cycle, or a privacy violating path in the graph of $A$.
\end{lemma}
\begin{proof}
    TBD, want to briefly discuss the best way to do this. 

    high level overview: very similar to the previous, one-segment, version of this, but we can chain constraints across $\texttt{AG}-$ and $\texttt{AL}-$paths.

    The reasoning gets a bit convoluted though, because there are a bunch of cases / you have to keep a bunch of assumptions hanging around.
\end{proof}

\begin{thm}
    A DiPA $A$ is $d\varepsilon$-differentially private if and only if $A$ has a finite number of branches and there exists a valid assignment of coupling strategies over all branches of $A$. 
\end{thm}
\begin{proof}
    Follows from theorem \ref{constraintsatisfiableprivatethm} and lemmas \ref{leakingcyclesbrancheslemma} and \ref{unsatisfiablenoprivacylemma}.
\end{proof}

\section{Bounds on Privacy}

So far, we have focused on the binary question of whether a DiPA is private or not for \textit{any} finite $d>0$. An obvious question remaining thus is how tight of a privacy cost bound can we obtain using couplings?

Recall that $S^G, S^L$, and $S^N$ are primarily characterized by \textbf{shifts}; that is, offseting variables from each other.

Indeed, we can generalize our discrete set of coupling strategies to a continuous family of coupling strategies by treating the offsets of each variable as parameters. By rephrasing in this way, we can derive a linear system:

[insert vishnu's linear program here]

If solvable, this linear system will thus give the best possible privacy cost obtainable using this family of coupling strategies. 

\begin{prop}
    An optimal solution to the linear program provides the minimal cost coupling over all shift coupling strategies. If the linear program is infeasible, then the DiPA is not $d\varepsilon$-differentially private for any $\varepsilon$. 
\end{prop}

\begin{thm}[optimistically]
    If a DiPA $A$ is $\varepsilon$-differentially private, then there exists some valid assignment of coupling strategies over all segments that has a total cost of $\varepsilon$ (i.e.\ coupling cost is tight). 
\end{thm}

\section{Multivariable DiPA}

In this section, we explore a natural extension of the DiPA model to demonstrate the utility of using couplings as proof infrastructure. Specifically, we introduce Generalized DiPAs (GDiPAs), which allow for an arbitrary finite set of variables and an expanded alphabet where multiple variables can be compared to the input simultaneously to determine transitions. 
This would, for example, allow for SVT-style algorithms that check for membership between or outside of two thresholds or indeed, membership within any finite union of intersections of halves\footnote{think there's a term for this I'm forgetting} of $\RR$. 

\subsection{GDiPA}

A GDiPA $A$ is a generalization of DiPA whose primary characteristics are that:
\begin{itemize}
	\item At every state, a (real-valued) input is read. Additionally, Laplace noise (with parameters set by the user) is added to the input. 
	\item The automaton has a stored finite set of (real-valued) variables $\mathcal{X}$. At each transition, the value of each variable can be updated with the noisy input value read in. 
	\item A transition can optionally assign the (noisy) input value read at the previous state into at most one program variable.
	\item The automaton will take transitions based on a boolean combination of comparisons between the noisy input and a subset of the stored variables. Importantly, noise is added independently to the input for each separate variable comparison. Alternatively, there can be exactly one guaranteed (\texttt{true}) transition out of a state. 
	\item At every transition, the automaton will output either \begin{enumerate}
		\item A symbol from a pre-defined finite alphabet ($\Gamma$)
		\item The noisy input value as compared to one of the input variables ($\texttt{insample}$)
		\item The input value with fresh Laplace noise ($\texttt{insample}'$)
	\end{enumerate}
	As with DiPAs, the output sequence of any GDiPA must uniquely determine a path through the automaton.
\end{itemize}

\subsection{Combining Separate Variable Couplings}
Consider a GDiPA $A$ with program variables $\mathcal{X}$. For each program variable $x\in \mathcal{X}$, we can define coupling strategies similar to with single variables. That is, for two runs of the automaton with adjacent inputs, we must ensure that if the first run takes a certain transition, the other run does as well. In particular, for real outputs, we must ensure that the outputs are equal. 

For each variable in $A$, we can consider a ``shadow'' automaton in a single variable that only has a single program variable. Such a shadow automaton would have the same underlying graph structure as $A$, but would only contain the transition guards and assignments that pertained to a single variable. 
For example, if we were considering such an automaton $A_x$ with respect to the variable $x$, a transition with guard ``$\lguard[x]$ and $\gguard[y]$'' would correspond to a transition with guard $\lguard[x]$ in $A_x$; a transition with guard ``$\gguard[y]$'' would correspond to a transition with guard $\texttt{true}$ in $A_x$.

Note that these automata are not, strictly speaking, DiPAs, since it is possible for a state to have multiple transitions with guard $\texttt{true}$ leaving it. 

Thus, each segment can be assigned a coupling strategy $S^N, S^L$, or $S^G$ as before based on these ``shadow'' automata, with similar constraints. 

\begin{const}\label{generalizedconstraintsystem}
    Consider a GDiPA $A$ with program variables $\mathcal{X}$. Let $\{s_i^{(x)}\}$ be the segments of $A$ for each variable $x\in \mathcal{X}$. 

    For each $x\in \mathcal{X}$ and segment $s_i^{(x)}$ for $x$, we can assign one of three coupling strategies $S_i^{(x)} \in \{S^L, S^G, S^N\}$. We would like to find an assignment of coupling strategies for each segment of each variable, subject to the following constraints: 

    \begin{enumerate}
        \item Constraints for valid couplings\begin{enumerate}
            \item For all $s_i^{(x)}$, if $\trans(s_i^{(x)})$ outputs $\texttt{insample}$, then $S_i^{(x)} = S^N$.
            \item For all $s_i^{(x)}, s_j^{(x)}$ such that $s_i^{(x)}$ is immediately followed by $s_j^{(x)}$, \begin{enumerate}
                \item If $\guard(s_j^{(x)})=\lguard$ and $S_i^{(x)} = S^G$, then $S_j^{(x)} = S^G$. 
                \item If $\guard(s_j^{(x)}) = \gguard$ and $S_i^{(x)} = S^L$, then $S_j^{(x)} = S^L$.
                \item If $\guard(s_j^{(x)}) = \lguard$ and $S_i^{(x)} = S^N$, then $S_j^{(x)}\neq S^L$.
                \item If $\guard(s_j^{(x)}) = \gguard$ and $S_i^{(x)} = S^N$, then $S_j^{(x)}\neq S^G$.
            \end{enumerate}
            \item For all segments $s_i^{(x)}$, there is no transition $\trans(a_k)$ in $s_i^{(x)}$ that is \textit{faulty}, i.e.:\begin{enumerate}
                \item If $s_i^{(x)}$ contains a $\lguard$ transition that outputs $\texttt{insample}$, then $S_i^{(x)} \neq S^G$.
                \item If $s_i^{(x)}$ contains a $\gguard$ transition that outputs $\texttt{insample}$, then $S_i^{(x)} \neq S^L$.
            \end{enumerate}
            \item If any transition in $s_i^{(x)}$ outputs $x$, then $S_i^{(x)} = S^N$. 
        \end{enumerate}
        \item Constraints for finite cost\begin{enumerate}
            \item For all $s_i^{(x)}$, no cycle in $s_i^{(x)}$ has a transition that outputs $\texttt{insample}$, $\texttt{insample}'$. 
            \item For all $s_i^{(x)}$, if $s_i^{(x)}$ has an $\texttt{L}$-cycle with respect to $x$, then $S_i^{(x)} = S^L$.
            \item For all $s_i^{(x)}$, if $s_i^{(x)}$ has a $\texttt{G}$-cycle with respect to $x$, then $S_i^{(x)} = S^G$. 
        \end{enumerate}
    \end{enumerate}

    This constraint system is \textbf{satisfiable} for a GDiPA $A$ if, for all variables $x\in \mathcal{X}$, there exists an assignment of all $S_i^{(x)}$ such that all constraints are satisfied. 
\end{const}

In particular, we can independently resolve constraints for each variable and combine them together.
\begin{thm}	
	For a GDiPA $\mathcal{A}$, for all variables $x$, if there exist a finite number of segments $s_i$, and for all segments $s_i$, the constraint system \ref{constraintsystem} is satisfied by an assignment $S_x$, then all $S_x$ assignments together induce a valid coupling proof that $\mathcal{A}$ is $\varepsilon$-DP. 
\end{thm}

\begin{proof}
	
	Fix some variable $x\in \mathcal{X}$. From before, we know that if \ref{generalizedconstraintsystem} is satisfied with respect to $x$, then the coupling 
	\[\mathcal{A}(X)(\mathcal{A}(X)\text{ takes transitions }T\text{ wrt }x\implies \mathcal{A}(X')\text{ takes transitions }T\text{ wrt }x)^{\#(\varepsilon_x, 0)}\mathcal{A}(X')\]
	is valid for some finite $\varepsilon_x$. 
		
	Because the noises on $\texttt{insample}$ are independent, and $((a \implies c) \land (b \implies d)) \implies ((a \land b) \implies (c \land d))$ and $((a \implies c) \lor (b \implies d)) \implies ((a \lor b) \implies (c \lor d))$,for every combined guard, we can construct the lifting 
	\[\mathcal{A}(X)(\mathcal{A}(X)\text{ takes transitions }T\implies \mathcal{A}(X')\text{ takes transitions }T)^{\#(\sum_{x\in\mathcal{X}}\varepsilon_x, 0)}\mathcal{A}(X')\]
	which gives us the lifting
	\[\mathcal{A}(X)(\mathcal{A}(X)=\sigma\implies \mathcal{A}(X')=\sigma)^{\#(\sum_{x\in\mathcal{X}}\varepsilon_x, 0)}\mathcal{A}(X')\]
\end{proof}

\begin{thm}[less optimistically]
    If, for each variable $x$, there exists a valid assignment of coupling strategies over all segments of a DiPA $A$ with respect to $x$, then $A$ is $d\varepsilon$-differentially private. 
\end{thm}

\begin{thm}[optimistically]
    A GDiPA $A$ is $d\varepsilon$-differentially private if and only if, for each variable $x$, there exists a valid assignment of coupling strategies over all segments of $A$ with respect to $x$. 
\end{thm}

\section{Conclusion}
We have shown how to use coupling techniques to prove privacy for a class of SVT-like programs first defined in \cite{chadhaLinearTimeDecidability2021} and discovered that couplings additionally characterize this class. We additionally showed that this can be done tractably, and that couplings can help provide lower bounds on privacy costs of these algorithms. 

Future work most naturally would focus on extensions of the program model. For the model, potential areas include removing the requirement for output to be deterministic of a path through the automaton, which would allow for algorithms such as Report Noisy Max to be captured by the model. Similarly, the alphabet of the automaton could be expanded to incorporate more than comparisons between two real numbers. 
Such extensions would naturally also require extensions of the class of couplings we define here, which are limited to ``shifts''. 

Additionally, we believe that couplings should completely characterize GDiPAs as well as DiPAs; proving this requires showing that a lack of well-formedness in any single variable generates a counterexample to privacy. 
In this vein, we would like to explore using couplings to \textit{disprove} privacy; the fact that shift couplings completely characterize DiPAs hints at the possibility of ``anti-couplings'' to generate counterexamples.

\section{Related Work}
The DiPA model and counterexamples to privacy are drawn from \cite{chadhaLinearTimeDecidability2021}. Approximate liftings were developed in \cite{bartheKopfOlmedo2012ProbabilisticRelationalReasoningforDifferentialPriv,BartheOlmedo2013} and applied to algorithms such as SVT in \cite{BartheEtAl2016}.
A full exploration of approximate liftings can be found in \cite{HsuThesis2017}. \cite{AlbarghouthiHsu2018} uses couplings; and in particular the ``shift'' couplings family we use, to create a heuristiccally successful program for proving the correctness of possible differentially private algorithms. 


{\color{red} need to reformat some citations at some point}
\bibliography{./dipalibrary}

\end{document} 