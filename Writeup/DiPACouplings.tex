\documentclass[12pt]{article}

\usepackage[shortlabels]{enumitem} 
\usepackage{amsmath,amsfonts,amssymb,amsthm,bm,mathrsfs}
\usepackage{fancyhdr}
\usepackage[margin=1in]{geometry}
\usepackage{parskip}
\usepackage{tikz}
\usepackage{algorithm}
\usepackage{algpseudocode}
% \usepackage{mdframed}
\usepackage{hyperref}
\usepackage{xcolor, soul}
\sethlcolor{cyan}


\newcommand{\NN}{\mathbb{N}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\EE}{\mathbb{E}}
\newcommand{\notimplies}{\;\not\!\!\!\implies}
\newcommand{\gguard}[1][x]{\texttt{insample}\geq #1}
\newcommand{\lguard}[1][x]{\texttt{insample} < #1}
\newcommand{\gaguard}{n<N \text{ AND } \texttt{insample} \geq \texttt{x}}
\newcommand{\laguard}{n<N\text{ AND }\texttt{insample} < \texttt{x}}
\newcommand{\itgguard}{\texttt{input}\neq\tau \text{ AND } \texttt{insample} \geq \texttt{x}}
\newcommand{\itlguard}{\texttt{input}\neq\tau \text{ AND }\texttt{insample} < \texttt{x}}
\newcommand{\range}{\texttt{range}}
\newcommand{\brangle}[1]{\langle #1 \rangle}
\newcommand{\guard}{\texttt{guard}}
\newcommand{\trans}{\texttt{trans}}
\newcommand{\Lap}{\texttt{Lap}}
\newcommand{\gcycle}{\texttt{G}-cycle}
\newcommand{\lcycle}{\texttt{L}-cycle}
\newcommand{\sgn}{\texttt{sgn}}
\newcommand{\andtext}{\text{ AND }}
\newcommand{\ortext}{\text{ OR }}
\newcommand{\supp}{\texttt{supp}}

\newcommand{\im}{\texttt{im}}


\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\providecommand{\floor}[1]{ \lfloor #1 \rfloor }
\newtheorem{thm}{Theorem}[section]
\newtheorem{lemma}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{obs}[thm]{Observation}
\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\newtheorem{const}[thm]{Construction}
\newtheorem{examp}[thm]{Example}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{rmk}[thm]{Remark}
\newtheorem{clm}[thm]{Claim}

\newcommand{\isto}{\stackrel{\sim}{\smash{\longrightarrow}\rule{0pt}{0.4ex}}} 
\graphicspath{ {./} }
\bibliographystyle{plain} 


\begin{document}

\section{Introduction}

Differential privacy is a framework for privacy that gives rigorous guarantees on the amount of data leakage any one person's data can be subjected to when releasing statistical data. Since being introduced in 2006 \cite{DP2006}, differential privacy has become the gold standard for private statistical analysis. 
Differentially private algorithms, whose efficacy are characterized by a ``privacy cost'' $\varepsilon$, primarily rely on the addition of statistical noise, ensuring that statistical results remain approximately correct while preventing any one person's information from being revealed. 

Differentially private algorithms are notoriously tricky to analyze for correctness; most famously, the Sparse Vector Technique (SVT) algorithm has gone through multiple iterations, some of which were later shown to completely fail at protecting privacy\cite{10.14778/3055330.3055331}. Previous implementations of differential privacy by Apple have similarly been shown to have an increase from the claimed privacy cost by a factor of up to 16 \cite{appleleakprivacy}. 

Thus, much work has been done on developing methods for automatic verification of differentially private algorithms, both in their overall privacy and in the specific privacy costs they claim to achieve. 
Because even for limited programs the problem of determining if a program is differentially private is undecidable\cite{barthe.etal2020decidingdp}, previous work tends to focus on semi-decidability or further restricting program models. 

Recently, a line of work has emerged around \textbf{approximate liftings} \cite{BartheEtAl2016,bartheKopfOlmedo2012ProbabilisticRelationalReasoningforDifferentialPriv,BartheOlmedo2013,HsuThesis2017}. Approximate liftings are a generalization of probabilistic couplings, themselves a well-known technique in probability theory for analyzing relationships between random variables. 
Approximate liftings allow for a more structured proof approach to many algorithms that themselves are not conducive to a standard compositional analysis, such as SVT. Because of their structure, liftings also lend themselves to automated proof construction~\cite{AlbarghouthiHsu2018}. 

We first rewrite the major results of approximate liftings in \{not program logic\}\footnote{not sure how to describe this, also not sure if worth mentioning}. 
We then use approximate liftings to demonstrate that a certain limited class of programs, first described in \cite{chadhaLinearTimeDecidability2021}, are differentially private; interestingly, we show that our class of liftings completely characterizes this class of programs. Additionally, we demonstrate that the privacy of a natural generalization of this class of programs can be proven using liftings and almost immediately follows from the privacy of the smaller class. 

\section{Differential Privacy}

Differential privacy is a mathematically robust approach to privacy; most generally, differential privacy ensures that it is unlikely for an adversary to distinguish between whether or not one person's data was used in a private algorithm. To do this, differentially private algorithms rely on randomization, especially through the addition of statistical noise.

More precisely then, for a fixed output $\sigma$ of a private algorithm $A$, the probability of obtaining $\sigma$ for a dataset with some individual Alex is close (measured by a multiplicative factor) to the probability of obtaining $\sigma$ for the same dataset with Alex removed or Alex's data changed.

We will consider \textbf{datasets} $\mathcal{X}\in X^n$ of size $n$, where $X$ is the set of all possible rows in the dataset; each person is represented by a single row. 

We next define what it means for datasets to be ``similar'' to each other. 

\begin{defn}
    Two datasets $\mathcal{X}=(x_1, \ldots, x_n), \mathcal{X}'=(x'_1, \ldots, x'_n)\in X^n$ are \textbf{adjacent} (notated $\mathcal{X}\sim\mathcal{X}'$) if $|\{i: x_i\neq x'_i\}|\leq 1$\footnote{A common variant is to define adjacency by the removal or addition of an entry, rather than changing one}.
\end{defn}

We thus formalize privacy under this framework as follows.
\begin{defn}[Pure Differential Privacy]
    A randomized algorithm $A$ is $\varepsilon$-differentially private if, for all pairs of \textbf{adjacent} datasets $X$ and $X'$ and all events $E \subseteq \im(A)$, \[\PP[A(X) \in E]\leq e^\varepsilon \PP[A(X')\in E]\]
\end{defn}


An extremely useful property of differential privacy is that differentially private programs can be \textbf{sequentially composed} with a linear degradation in privacy:

\begin{thm}[Standard Composition]
    If $A$ is $\varepsilon_1$-differentially private and, for all $\sigma$, $B(\sigma, \cdot)$ is $\varepsilon_2$-differentially private, then $B(A(X), X)$ is $\varepsilon_1+\varepsilon_2$-differentially private. 
\end{thm}

Composition therefore allows us to view privacy parameters $\varepsilon$ as a ``budget'' for privacy-leaking operations in a program. Many\footnote{generic platitude - reword} common differentially private algorithms are thus built out of well-known private components combined together, which also lend themselves to straightforward analyses. 

\subsection{Sensitivity and the Laplace Mechanism}

Because we are typically interested in analyzing \textit{functions} of our raw dataset (for example, the average age of a town), it is often useful to examine differential privacy through a similar model - instead of comparing two adjacent datasets $X\sim X'$, we compare \textbf{queries} $f(X)$ and $f(X')$. In this world, we care about the \textit{sensitivity} of functions: how much a function \textit{changes} when considering adjacent inputs.  

\begin{defn}
    The ($\ell_1$-)sensitivity of a function $f: X\to \RR$, often denoted $\Delta f$, is defined as $\Delta f = \max_{X\sim X'}||f(X)-f(X')||_1$.
\end{defn}

Given a function's sensitivity, we can easily make it differentially private through the use of the \textbf{Laplace Mechanism}.

\begin{defn}
    The Laplace distribution $\Lap(\mu, b)$ with mean $\mu$ and spread parameter $b$ is the probability distribution with probability density function $f(x) = \frac{1}{2b}\exp(-\frac{|x-\mu|}{b})$. If $\mu =0$, we will often abbreviate $\Lap(0, b)$ as $\Lap(b)$. 
\end{defn}

The Laplace Mechanism, as expected, simply adds noise sampled from the Laplace distribution to a query result. 

\begin{thm}[Theorem 3.6~\cite{dworkrothmonograph}]
    For a function $f$ with sensitivity $\Delta$, $A(X) = f(X) + \Lap(\frac{\Delta}{\varepsilon})$ is $\varepsilon$-differentially private. 
\end{thm}

We will consider the scenario where we are given a potentially infinite \textit{sequence} of real-valued query functions $q_0, q_1, \ldots$, each with sensitivity at most $\Delta$.

\subsection{Deciding Privacy}

Because designing differentially private algorithms can be quite tricky, we would like to be able to automatically (i.e. algorithmically) verify whether or not a given program is private, especially for algorithms whose privacy proofs do not rely primarily on composition. 
Ideally, beyond just determining whether a program is private or not, if a program is private, we'd like to find a good bound on the privacy cost for the program as well. 

Unfortunately, even for relatively simple programs, just the basic problem is undecidable. 

\begin{thm}[\cite{barthe.etal2020decidingdp}]
    The problem of determining whether a program from a certain class of algorithms with assignments, conditionals, and while loops is $\varepsilon$-differentially private is undecidable\footnote{rephrase?}.
\end{thm}

Thus, we will derive a decision procedure for a very specific class of potentially private programs; in particular, this class of programs lends itself to a straightforward analysis by \textbf{approximate liftings}, which we now introduce. 

\section{Couplings and Liftings}

Probabilistic couplings are a common tool in probability theory; intuitively, couplings allow for the joint analysis of nominally unrelated probabilistic processes. 

\begin{defn}
    A coupling between two distributions $A$ and $B$ is a joint distribution $C$ such that $\pi_1(C)=A$ and $\pi_2(C)=B$, where $\pi_1(C)$ and $\pi_2(C)$ are the first and second marginals of $C$, respectively. 
\end{defn}

In particular, couplings can be useful when analyzing the relation between two probablistic processes; couplings were first formulated by [check name] to analyze the behaviour of markov chains and have close connections to concepts such as total variation distance and stochastic domination. 

As useful as standard couplings are, however, we must use more powerful machinery to properly reason about privacy.

\textbf{Approximate liftings} \cite{BartheOlmedo2013,bartheKopfOlmedo2012ProbabilisticRelationalReasoningforDifferentialPriv,HsuThesis2017,BartheEtAl2016} allow us to apply couplings to the realm of differential privacy. 

\begin{defn}
    Let $A_1, A_2$ be two probability spaces\footnote{may need to formally rewrite this at some point}. We say a distribution $\mu_1$ on $A_1$ and $\mu_2$ on $A_2$ are related by the $\mathbf{\varepsilon}$\textbf{-lifting} of the relation $\Psi\subseteq A_1\times A_2$ (written $\mu_1\Psi^{\#\varepsilon}\mu_2$) if there exist two \textbf{witness distributions} $\mu_L, \mu_R$ on $A_1\times A_2$ such that\begin{enumerate}
        \item $\pi_1(\mu_L) = \mu_1$ and $\pi_2(\mu_R) = \mu_2$
        \item $\supp(\mu_L), \supp(\mu_R)\subseteq \Psi$
        \item $\sup_{E\subseteq A_1\times A_2}(\PP_{x\gets \mu_L}[x\in E]- e^\varepsilon \PP_{x\gets \mu_R}[x\in E])\leq 0$
    \end{enumerate}
\end{defn}

The similarities between the third condition and the definition of differential privacy should be clear. Indeed, there is a close connection between approximate liftings and differential privacy:

\begin{thm}
    An algorithm $A(X)$ is $\varepsilon$-differentially private if and only if, for all adjacent input sequences $X\sim X'$, $A(X)(=)^{\#\varepsilon}A(X')$.
\end{thm}

If we are solely aiming to show that a program is private, we can instead work with the following relaxation: 

\begin{thm}\label{implicationcouplingthm}
    If for all adjacent input sequences $X\sim X'$ and outputs $\sigma$ of $A$, $A(X)\{(a, b): a=\sigma\implies b=\sigma\}^{\#\varepsilon}A(X')$, then $A(X)$ is $\varepsilon-$differentially private.
\end{thm}

As expected, the foundational results of differential privacy can be restated in terms of liftings:

\begin{prop}[Laplace Mechanism for Liftings]
    If $X_1\sim\Lap(\mu_1, \frac{1}{\varepsilon})$ and $X_2\sim\Lap(\mu_2, \frac{1}{\varepsilon})$, then $X_1(=)^{\#\varepsilon|\mu_1-\mu_2|}X_2$.
\end{prop}

\begin{thm}[Composition of Liftings]\label{liftingcomposition}
    Let $A_1, B_2, A_2, B_2$ be distributions over $S_1, T_1, S_2, T_2$, respectively and let $R_1\subseteq S_1\times T_1$, $R_2\subseteq S_2\times T_2$ be relations. If $A_1 R_1^{\#\varepsilon_1}B_1$ and $A_1 R_1 B_1\implies A_2R_2^{\#\varepsilon_2}B_2$, then $A_2 R_2^{\#\varepsilon_1+\varepsilon_2}B_2$.
\end{thm}

The structure of theorems \ref{implicationcouplingthm} and \ref{liftingcomposition} suggests the format that coupling proofs of privacy take: given two ``runs'' of an algorithm on adjacent inputs, construct many smaller liftings between program variables in each run and compose these liftings together to show that a final implicatory lifting between the outputs of the two runs exists. 

\subsection{Proving SVT with couplings}

A classic algorithm that requires analysis beyond standard composition is Sparse Vector Technique (SVT). Given a possibly infinite stream of inputs and a threshold value, SVT will output if the queries are above or below the threshold (with noise on both the query and the threshold). 

Unusually for differentially private algorithms, SVT can output a potentially unbounded number of ``below threshold'' queries before the first $c$ ``above threshold''s (or vice-versa), where $c$ is some constant set by the user; when $c=1$, SVT is frequently also referred to as ``Above (or Below) Threshold''. Potential applications include, for example, checking that a series of inputs is within an expected range or, appropriately, privately determining the non-zero elements of a sparse vector. 

Because SVT allows for a potentially unbounded number of ``below threshold'' query outputs, its analysis requires a non-standard approach; a naive composition approach that assigns a fixed cost to outputting the result of each query will immediately result in unbounded privacy cost as well. 
Indeed, the analysis of SVT is notoriously difficult, with multiple published attempts at privacy proofs that were later shown to be incorrect\footnote{A textbook analysis of SVT, along with a discussion of bugged versions and incorrect privacy proofs, can be found at \cite{10.14778/3055330.3055331}}. 

However, re-analyzing SVT using approximate liftings can be relatively simple. 

\begin{algorithm}
    \hspace*{\algorithmicindent}\textbf{Input}: $\mathcal{X}\in X^n$, $T\in \RR$, $Q=q_1, \ldots \in {(X^n\to \RR)}^*$ with sensitivity $\Delta$, $c\in \NN$.
    \begin{algorithmic}[1]
        \caption{Sparse Vector Technique}\label{couplingAlg}
        \State $\varepsilon_1, \varepsilon_2 \gets \frac{\varepsilon}{2},
        \rho \gets \Lap(\frac{\Delta}{\varepsilon_1})$, $count \gets 0$
		\For{$q_i \in Q$} 
			\State $z\gets \Lap(\frac{2c\Delta}{\varepsilon_2})$
            \If{$q_i(\mathcal{X}) + z \geq T + \rho$}
                \State\textbf{output} $\top$
                \State$count\gets count+1$
                \If{$count \geq c$}
                    \State$\textbf{break}$
                \EndIf
            \Else
                \State\textbf{output} $\bot$
            \EndIf
		\EndFor
    \end{algorithmic}
\end{algorithm}


\begin{thm}
    Sparse Vector Technique is $\varepsilon$-differentially private. 
\end{thm}

\begin{proof}
    Consider two runs of SVT with adjacent inputs $\mathcal{X}\sim\mathcal{X}'$, respectively. We are aiming to show that $SVT(\mathcal{X}, T, Q, c)\{(a, b): a=\sigma \implies b=\sigma\}^{\#\varepsilon}SVT(\mathcal{X}', T, Q, c)$ is a valid lifting. 

    Fix some output $\sigma \in \{\bot, \top\}^n$. Let $A = \{i:\sigma_i = \top\}$ be the indices of queries that are measured to be above the threshold. Note that $|A| = c$. 
    
    For every program variable $x$, let $x\brangle{1}$ and $x\brangle{2}$ represent the value of $x$ in $SVT(\mathcal{X}, T, Q, c)$ and $SVT(\mathcal{X}', T, Q, c)$, respectively, so, for example, $q_i(\mathcal{X})\brangle{1} = q_i(\mathcal{X})$ and $q_i(\mathcal{X})\brangle{2} = q_i(\mathcal{X}')$. 

    Let $\tilde{T}=T + \rho$. Then $\tilde{T} \sim \Lap(T, \frac{\Delta}{\varepsilon_1})$, so $\tilde{T}\brangle{1} +\Delta (=)^{\#\varepsilon_1}\tilde{T}\brangle{2}$. 

    Let $S_i = q_i(\mathcal{X}) + z_i$, so $S_i \sim\Lap(q_i(\mathcal{X}), \frac{2c\Delta}{\varepsilon_2})$.

    For all $i$ such that $0\leq i < n$, $i\notin A$, we construct the lifting $z_i\langle 1\rangle (=)^{\#0}z_i\langle 2\rangle$. 

    Then note that $\tilde{T}\brangle{1}+\Delta = \tilde{T}\brangle{2}\land z_i\brangle{1} = z_i \brangle{2} \implies (S_i\brangle{1} < \tilde{T}\brangle{1} \implies S_i\brangle{2} < \tilde{T}\brangle{2} )$.

    For all $i\in A$, create the lifting $z_i\brangle{1}(=)^{\#\frac{\varepsilon_2}{c}}z_i\brangle{2} - q_i(\mathcal{X})+q_i(\mathcal{X}')-\Delta$, or equivalently, \\$S_i\brangle{1} +\Delta (=)^{\#\frac{\varepsilon_2}{c}} S_i\brangle{2}$. Note that this costs $\frac{\varepsilon_2}{c}$ since $|q_i(\mathcal{X})-q_i(\mathcal{X}')|\leq \Delta$.

    Then \[\tilde{T}\brangle{1} +\Delta = \tilde{T}\brangle{2} \land S_i\brangle{1} + \Delta = S_i\brangle{2} \implies (S_i\brangle{1} \geq \tilde{T}\brangle{1} \implies S_i\langle 2\rangle \geq \tilde{T}\brangle{2})\]

    Thus, for all $i$, $SVT(\mathcal{X}, T, Q, c)_i = \sigma_i \implies SVT(\mathcal{X}', T, Q, c)_i = \sigma_i$, so $SVT(\mathcal{X}, T, Q, c)\{(a, b): a=\sigma \implies b=\sigma\}^{\#\varepsilon_1+\varepsilon_2}SVT(\mathcal{X}', T, Q, c)$.

    By Theorem \ref{implicationcouplingthm}, SVT is $\varepsilon$-differentially private. 
\end{proof}

\section{Automatically Proving Privacy using Couplings}

We begin by building up a program model for SVT-style algorithms. There are three major components of SVT: taking in a threshold value and adding Laplace noise to it, taking in input and adding Laplace noise to it, and comparing the noisy threshold to the noisy input. 

{\color{red} TODO: add non-input transitions (still don't understand why they're useful) - very trivial since the guards of a non-input transition have to be $\texttt{true}$}

\subsection{Individual Transitions}
We will model programs as finite state automata, with each state of the automaton representing a possible program state. Under this paradigm, we begin with the simplest possible program: a single transition between two program states. 

\begin{defn}[Transitions]
    Let $\mathcal{C}=\{\texttt{true}, \lguard[\texttt{x}], \gguard[\texttt{x}]\}$ be a set of \textbf{transition guards}. Let $Q$ be a set of states with each state $q\in Q$ having an associated real value for a variable $\texttt{x}$. Additionally, let $P(q): Q\to \RR^{\geq 0}\times \RR^{\geq 0}$ be a function that associates each state state with two \textbf{noise parameters} $P(q) = (d_q, d_q')$. Finally, let $\Gamma$ be a finite alphabet of \textbf{output symbols}. 

    Then given two states $q, q'\in Q$, a \textbf{transition} from $q$ to $q'$ is defined as the tuple $t = (q, q', c, \sigma,\tau)$ where $c\in \mathcal{C}$, $\sigma\in \Gamma\cup\{\texttt{insample}, \texttt{insample}'\}$, and $\tau$ is a boolean value denoting whether or not the stored value of $\texttt{x}$ will be updated. At all times, we will assume that there exists most one transition from $q\in Q$ to $q'\in Q$. 
\end{defn}

\begin{defn}[Taking a transition]
    Fix some $\varepsilon>0$, which we will treat as a program parameter.

    Consider some program state $q\in Q$ with noise parameters $P(q) = (d_q, d_q')$. Let $z\sim \Lap(0, \frac{1}{d_q\varepsilon})$ and $z'\sim\Lap(0, \frac{1}{d_q'\varepsilon})$ be independent random noises sampled from Laplace distributions with spread parameters $\frac{1}{d_q\varepsilon}$ and $\frac{1}{d_q'\varepsilon}$, respectively.

    For a state $q\in Q$ and input value $\texttt{in}\in \RR$ read at $q$, let $\texttt{insample} = \texttt{in}+z$ and $\texttt{insample}' = \texttt{in}+z'$ be noisy versions of the input read at $q$. 

    Let $\sigma\in \Gamma\cup\{(\texttt{insample}, a, b), (\texttt{insample}', a, b)\}$ be a potential output of a transition. For measurability reasons, note that we must associate real-valued outputs with an interval $(a, b)$. Intuitively, $\sigma = (\texttt{insample}, a, b)$ represents the possibility that $\texttt{insample}$ was output with a value in the interval $(a, b)$. 

    Then given a initial value $x_q\in \RR$ for $\texttt{x}$, a possible transition $t=(q, q', c, \sigma, \tau)$ from $q$ to another state $q'\in Q$ is \textbf{taken} if $c$ is true and, if $\sigma\in \{(\texttt{insample}, a, b), (\texttt{insample}', a', b')\}$, $t$ outputs $\texttt{insample}$ or $\texttt{insample}'$ as appropriate with a value in the interval $(a, b)$ or $(a', b')$, respectively. 
\end{defn}

In general, we will assume that at all states $q$, $x_q$ has been sampled from some Laplace distribution $\Lap(\hat{\mu_q}, \frac{1}{\hat{d_{q}}\varepsilon})$, where $\hat{d_{q}}$ is the spread parameter for $\texttt{insample}$ at some previous state. 

\subsection{Privacy}

\begin{obs}[Transition probabilities]
    Consider a single transition $t=(q, q', c, \sigma, \tau)$ from state $q\in Q$ to $q'\in Q$. Additionally, let $x_q\sim \Lap(\hat{\mu_q}, \frac{1}{\hat{d_q}\varepsilon})$ be the initial stored value of $\texttt{x}$ at $q$. 

    Let $\sigma_0$ be a \textit{potential} output of $t$
    
    Then, given an input $\texttt{in}$ at $q$, the \textbf{probability} that $t$ is taken with output $\sigma_0$ in range $(a, b)\subseteq \RR$ is \[
        \PP[x_q, t, \texttt{in}, \sigma_0] = \begin{cases}
            \PP[c\text{ is satisfied}] & \sigma_0 =\sigma \\
            \PP[c\text{ is satisfied}\land \texttt{insample}\in(a, b)] & \sigma_0 = (\texttt{insample}, a, b)\\
            \PP[\texttt{insample}'\in (a', b')]\PP[c\text{ is satisfied}]& \sigma_0 = (\texttt{insample}', a', b')
        \end{cases}
    \]
    where $\Lap_{\mu, s}(x)$ is the PDF of a Laplace distribution with mean $\mu$ and spread parameter $s$.
\end{obs}

Note, in particular, that $c$ being satisfied and $\texttt{insample}\in (a, b)$ are not independent events.

\hrulefill{\color{red}Move this to proof section probably}

More precisely, if $(u, v), (u', v')\in \RR_{\infty}$ is defined as follows:
    \begin{align*}
        (u, v) &= \begin{cases}
            (-\infty, \infty) & c=\texttt{true}\land \sigma_0 \neq (\texttt{insample}, a, b)\\
            (a, b) &c=\texttt{true}\land \sigma_0 = (\texttt{insample}, a, b)\\
            (-\infty, \texttt{x}_0) & a=\lguard\land \sigma_0 \neq (\texttt{insample}, a, b)\\
            (a, \min(\texttt{x}_0, b)) &c=\lguard\land \sigma_0 = (\texttt{insample}, a, b)\\
            (\texttt{x}_0, \infty) & c=\gguard\land \sigma_0 \neq (\texttt{insample}, a, b)\\
            (\max(\texttt{x}_0, a),b) &c=\gguard\land \sigma_0 = (\texttt{insample}, a, b)\\
        \end{cases}\\
        (u', v')& = (a', b'),
    \end{align*}
    then, given an input $\texttt{in}$ at $q$, the probability that $t$ is taken with output $\sigma_0$ can be computed to be \[
        \PP[x_q, t, \texttt{in}, \sigma_0] = \begin{cases}
            \int_u^v \Lap_{\texttt{in}, \frac{1}{d_q\varepsilon}}(z)dz & \sigma_0 \neq (\texttt{insample}', a', b') \\
            \int_{u'}^{v'}\Lap_{\texttt{in}, \frac{1}{d'_q\varepsilon}}(z')dz'\int_u^v \Lap_{\texttt{in}, \frac{1}{d_q\varepsilon}}(z)dz& \sigma_0 = (\texttt{insample}', a', b')
        \end{cases}
    \]
    where $\Lap_{\mu, s}(x)$ is the PDF of a Laplace distribution with mean $\mu$ and spread parameter $s$.
\hrulefill


Recall that $\texttt{in}$, in reality, represents a \textbf{function} of some underlying dataset. This means that `closeness' in this context is defined as follows:

\begin{defn}[Adjacency]
    Two inputs $\texttt{in}\sim_{\Delta} \texttt{in}'$ are $\Delta$-adjacent if $|\texttt{in}-\texttt{in}'|\leq \Delta$. If $\Delta$ is not specified, we assume that $\Delta = 1$. 
\end{defn}

We can now define what it means  to be \textbf{differentially private}.

\begin{defn}[$d\varepsilon$-differential privacy for a transition]
    Given two initial values $x_q, x_q'$, a transition $t=(q, q', c, \sigma, \tau)$ is \textbf{$d\varepsilon$-differentially private} for some $d>0$ if $\forall \varepsilon> 0$, for all adjacent inputs $\texttt{in}\sim \texttt{in}'$ and possible outputs $\sigma\in \Gamma\cup\{(\texttt{insample}, a, b), (\texttt{insample}', a', b')\}$, $\PP[x_q, t, \texttt{in}, \sigma]\leq e^{d\varepsilon}\PP[x_q', t, \texttt{in}', \sigma]$. 

    Recall that $x_q$ and $x_q'$ are treated as random variables drawn from a Laplace distribution. 
\end{defn}

Note that we slightly redefine $\varepsilon$-differential privacy as $d\varepsilon$-differential privacy, treating $\varepsilon$ as a universal scaling parameter that can be fine-tuned by users for their own purposes. 
In particular, we argue that this definition is functionally equivalent\footnote{\cite{chadhaLinearTimeDecidability2021} notes that it is not entirely clear how this differs from standard differential privacy, but that the known decidability result does not apply here - {\color{red} maybe something to investigate}}, since if we are targeting $\varepsilon^*$-differential privacy, we can always take $\varepsilon = \frac{\varepsilon^*}{d}$.

\subsubsection{Couplings}

For every transition $t$ between two states $q$ and $q'$, we can show that $t$ is differentially private using a series of liftings. 

\begin{lemma}\label{indTransitionCoupling}
    Suppose that $x_q\brangle{1}\sim \Lap(\hat{\mu_q}\brangle{1}, \frac{1}{\hat{d_q}\varepsilon}), x_q\brangle{2}\sim\Lap(\hat{\mu_q}\brangle{2}, \frac{1}{\hat{d_q}\varepsilon})$ are two initial values of $\texttt{x}$ at state $q\in Q$. 

    Consider some transition $t = (q, q', c, \sigma, \tau)$ from $q$ to $q'\in Q$. Let $P(q) = (d_q, d_q')$.

    Let $\texttt{in}\brangle{1}\sim \texttt{in}\brangle{2}$ be arbitrary and let $\sigma\brangle{1}$, $\sigma\brangle{2}$ be random variables representing possible outputs of $t$ given inputs $\texttt{in}\brangle{1}$ and $\texttt{in}\brangle{2}$, respectively. 

    Then $\forall \varepsilon>0$ and for all $\gamma_x, \gamma_q, \gamma_q'\in [-1, 1]$ that satisfy the constraints \[
        \begin{cases}
          \gamma_q\leq\gamma_x & c = \lguard[\texttt{x}]\\
          \gamma_q\geq\gamma_x & c = \gguard[\texttt{x}]\\
          \gamma_q=0 & \sigma = \texttt{insample}\\
          \gamma_q'=0 & \sigma = \texttt{insample}'
        \end{cases},
      \]
      the lifting $\sigma\brangle{1}\{(a, b): a=\sigma\implies b=\sigma\}^{\#d\varepsilon}\sigma\brangle{2}$ is valid for $d = (|\hat{\mu_q}\brangle{1}-\hat{\mu_q}\brangle{2}+\gamma_x|)\hat{d_q}+(|-\texttt{in}\brangle{1}+\texttt{in}\brangle{2}-\gamma_q|)d_q+(|-\texttt{in}\brangle{1}+\texttt{in}\brangle{2}-\gamma_q'|)d_q'$, and therefore $t$ is $d\varepsilon$-differentially private. 
\end{lemma}

\begin{proof}
Fix $\varepsilon>0$.

We will analyze the behaviour of two different \textbf{runs} of $t$, one with input $\texttt{in}$ and one with input $\texttt{in}'$. 

At a high level, for every Laplace-distributed variable, we will couple the value of the variable in one run with its value in the other \textbf{shifted} by some amount. 

We differentiate between the values of variables in the first and second run by using angle brackets $\brangle{k}$, so, for example, we will take $x_q\brangle{1}$ to be the value of $\texttt{x}$ at state $q$ in the run of $t$ with input $\texttt{in}\brangle{1}$ and $x_q\brangle{2}$ to be the value of $\texttt{x}$ in the run of $t$ with input $\texttt{in}\brangle{2}$. 

We thus want to create the lifting $\sigma\brangle{1}\{(a, b): a=\sigma\implies b=\sigma\}\sigma\brangle{2}$. We must guarantee two things: that if the first transition is taken, then the second is also taken and that both runs output the same value $\sigma$ when taking the transition. Note that if $c = \texttt{true}$, the first condition is trivially satisfied and when $\sigma\in \Gamma$, the second condition is trivially satisfied. 



Recall that that $x_q$ is sampled from a Laplace distribution, so $x_q\brangle{1}\sim \Lap(\hat{\mu_q}\brangle{1}, \frac{1}{\hat{d_q}\varepsilon})$ and $x_q\brangle{1}\sim \Lap(\hat{\mu_q}\brangle{2}, \frac{1}{\hat{d_q}\varepsilon})$.

Then we can first create the lifting $x_q\brangle{1}+\gamma_x (=)^{\#(|\hat{\mu_q}\brangle{1}-\hat{\mu_q}\brangle{2}+\gamma_x|)\hat{d_q}\varepsilon}x_q\brangle{2}$.

Additionally, create the lifting $z\brangle{1} (=)^{\#(|-\texttt{in}\brangle{1}+\texttt{in}\brangle{2}-\gamma_q|)d_q\varepsilon}z\brangle{2} - \texttt{in}\brangle{1}+\texttt{in}\brangle{2}-\gamma_q$. 

This is equivalent to creating the lifting $\texttt{insample}\brangle{1} +\gamma_q{(=)}^{\#(|-\texttt{in}\brangle{1}+\texttt{in}\brangle{2}-\gamma_q|)d_q\varepsilon}\texttt{insample}\brangle{2}$.

Finally, create the lifting $z'\brangle{1} (=)^{\#(|-\texttt{in}\brangle{1}+\texttt{in}\brangle{2}-\gamma_q'|)d_q'\varepsilon}z'\brangle{2} - \texttt{in}\brangle{1}+\texttt{in}\brangle{2}-\gamma_q'$. As before, this is equivalent to creating the lifting $\texttt{insample}'\brangle{1} +\gamma_q'{(=)}^{\#(|-\texttt{in}\brangle{1}+\texttt{in}\brangle{2}-\gamma_q'|)d_q'\varepsilon}\texttt{insample}'\brangle{2}$.

If $c=\lguard[\texttt{x}]$ and $\gamma_q\leq \gamma_x$, then \begin{align*}
    \texttt{insample}\brangle{1}<x_q\brangle{1}&\implies \texttt{in}\brangle{1}+z\brangle{1}<x_q\brangle{1}\\
    &\implies \texttt{in}\brangle{1}+z\brangle{2}-\texttt{in}\brangle{1}+\texttt{in}\brangle{2}-\gamma_q<x_q\brangle{2}-\gamma_x\\
    &\implies \texttt{insample}\brangle{2}<x_q\brangle{2}
\end{align*}

Similarly, if $c=\gguard[\texttt{x}]$ and $\gamma_q\geq \gamma_x$, then \begin{align*}
    \texttt{insample}\brangle{1}\geq x_q\brangle{1}&\implies \texttt{in}\brangle{1}+z\brangle{1}\geq x_q\brangle{1}\\
    &\implies \texttt{in}\brangle{1}+z\brangle{2}-\texttt{in}\brangle{1}+\texttt{in}\brangle{2}-\gamma_q\geq x_q\brangle{2}-\gamma_x\\
    &\implies \texttt{insample}\brangle{2}\geq x_q\brangle{2}
\end{align*}

With these liftings, we have ensured that if the first run takes transition $t$, then the second run does as well. 

Now, if $t$ outputs $\texttt{insample}$ and $\gamma_q=0$, then clearly we have that $\texttt{insample}\brangle{1}=\texttt{insample}\brangle{2}$, so $\sigma\brangle{1} = (\texttt{insample}, a, b)\implies \sigma\brangle{2}=(\texttt{insample}, a, b)$.

Similarly, if $\gamma_q'=0$, we have that $\sigma\brangle{1} = (\texttt{insample}', a, b)\implies \sigma\brangle{2}=(\texttt{insample}', a, b)$. 

Thus, if $t$ outputs a real number in the interval $(a, b)$ in the first run, it must also output a real number in the same interval in the second run. 

Thus, given the constraints \[
  \begin{cases}
    \gamma_q\leq\gamma_x & c = \lguard[\texttt{x}]\\
    \gamma_q\geq\gamma_x & c = \gguard[\texttt{x}]\\
    \gamma_q=0 & \sigma = \texttt{insample}\\
    \gamma_q'=0 & \sigma = \texttt{insample}'
  \end{cases},
\]
this is sufficient to create the lifting $\sigma\brangle{1}\{(a, b): a=\sigma\implies b=\sigma\}^{\#d\varepsilon}\sigma\brangle{2}$, where the cost $d = (|\hat{\mu_q}\brangle{1}-\hat{\mu_q}\brangle{2}+\gamma_x|)\hat{d_q}+(|-\texttt{in}\brangle{1}+\texttt{in}\brangle{2}-\gamma_q|)d_q+(|-\texttt{in}\brangle{1}+\texttt{in}\brangle{2}-\gamma_q'|)d_q'$. 

By an application of theorem \ref{implicationcouplingthm}, $\PP[x_q\brangle{1}, t, \texttt{in}\brangle{1}, \sigma]\leq e^{d\varepsilon}\PP[x_q\brangle{2}, t, \texttt{in}\brangle{2}, \sigma]$. Because $\texttt{in}\brangle{1}\sim\texttt{in}\brangle{2}$ are arbitrary adjacent inputs and $\sigma$ is an arbitrary possible output of $t$, this implies that $t$ is $d\varepsilon$-differentially private. 
\end{proof}

We can thus think of couplings for a transition as being parameterized by $\gamma_x$, $\gamma_q$, and $\gamma_q$. 

\begin{defn}[Coupling strategies for a transition]
    A \textbf{coupling strategy} for a transition $t_i = (q_i, q_{i+1}, c_i, \sigma_i, \tau_i)$ is a tuple $C_i = (\gamma_x^{(i)}, \gamma_i, \gamma_i')\in [-1, 1]^3$. 
\end{defn}

\begin{defn}[Validity of a coupling strategy]
    A coupling strategy $C_i =(\gamma_x^{(i)}, \gamma_i, \gamma_i')$ for a transition $t_i$ is \textbf{valid} if the constraints \[
        \begin{cases}
          \gamma_i\leq\gamma_x^{(i)} & c_i = \lguard[\texttt{x}]\\
          \gamma_i\geq\gamma_x^{(i)} & c_i = \gguard[\texttt{x}]\\
          \gamma_i=0 & \sigma_i = \texttt{insample}\\
          \gamma_i'=0 & \sigma_i = \texttt{insample}'
        \end{cases},
      \]
      are all satisfied. 
\end{defn}

In particular, a valid coupling proof gives an upper bound on the privacy cost of any individual transition. 
\begin{prop}\label{indivTransitionCouplingProp}
    For a transition $t_i$, if there exists a valid coupling strategy $C_i=(\gamma_x^{(i)}, \gamma_i, \gamma_i')$ given initial $\texttt{x}$ values centred at $\hat{\mu_q}\brangle{1}$ and $\hat{\mu_q}\brangle{2}$, then $t_i$ is $d\varepsilon$-differentially private for some 
    \[d\leq \max_{\texttt{in}\brangle{1}\sim\texttt{in}\brangle{2}} (|\hat{\mu_q}\brangle{1}-\hat{\mu_q}\brangle{2}+\gamma_x^{(i)}|)\hat{d_q}+(|-\texttt{in}\brangle{1}+\texttt{in}\brangle{2}-\gamma_i|)d_q+(|-\texttt{in}\brangle{1}+\texttt{in}\brangle{2}-\gamma_i'|)d_q'.\]
\end{prop}
\begin{proof}
    Follows immediately from lemma \ref{indTransitionCoupling}.
\end{proof}

\subsection{Multiple Transitions}

Of course, in practice we would like to analyze the behaviour of programs with more than two program states.

We start with \textit{executions}, comprised of a sequence of transitions. 

\begin{defn}[Program executions]
    Consider some set of program states $Q$. A program \textbf{execution} is a sequence of transitions $t_0, t_1, \ldots, t_{n-1}$ such that for all $i\in 0\ldots n-1$, $t_i = (q_i, q_{i+1}, c_i, \sigma_i, \tau_i)$ for some $c_i, \sigma_i, \tau_i$. We will often notate an execution $\rho$ as $\rho = q_0\to q_1\to \ldots \to q_n$. 
    
    Additionally, if $\tau_0 = \texttt{true}$ and $c_0 = \texttt{true}$ (i.e.\ the first transition in any execution always assigns its noised input value into $\texttt{x}$), then $\rho$ is a \textbf{complete execution}. We call this condition the \textbf{initialization} condition.
\end{defn}
\begin{defn}[Taking a execution]
    Consider some complete execution $\rho = q_0\to \ldots \to q_n$ and let $\texttt{x}_i$ for all $i\in 1\ldots n$ be the value of $\texttt{x}$ at each program state $q_i$. Note that we can safely ignore $\texttt{x}_0$ because of the initialization condition. As before, for a program state $q_i\in Q$ with noise parameters $P({q_i}) = (d_{q_i}, d_{q_i}')$, let $z_i\sim \Lap(0, \frac{1}{d_{q_i}\varepsilon})$ and $z_i'\sim\Lap(0, \frac{1}{d_{q_i}'\varepsilon})$. 
    Further, given an input $\texttt{in}\in \RR^n$ and possible output $\sigma \in (\Gamma\cup\{(\texttt{insample}, a, b), (\texttt{insample}', a, b)\})^n$, let $\texttt{insample}_i = \texttt{in}_i+z_i$ and $\texttt{insample}_i' = \texttt{in}_i+z_i'$. $\texttt{x}$ will be updated with $\texttt{insample}$ at a transition $t_i$ if and only if $\tau_i = \texttt{true}$. In other words, $\texttt{x}_i = \begin{cases}
        \texttt{x}_{i-1} & \tau_{i-1} =\texttt{false}\\
        \texttt{insample}_{i-1} &\tau_{i-1}=\texttt{true}
    \end{cases}$. 

    Then $\rho$ is \textbf{taken} if, $\forall i\in 0\ldots n-1$, $c_i$ is satisfied for $\texttt{insample}_i$ and $\texttt{x}_i$ and, if $t_i$ outputs a real value, it is of the form $(\texttt{insample}_i, a, b)$ or $(\texttt{insample}_i', a', b')$, as appropriate. 
\end{defn}

\subsubsection{Privacy}

We can naturally  extend the definition of probability on a single transition to an entire execution recursively.

\begin{defn}
    Given a execution $\rho = q_0\to q_1\to \ldots \to q_n$, the \textbf{tail} of $\rho$ is defined as $tail(\rho) = q_1\to q_2 \to \ldots\to q_n$. 

    We may additionally use the notation $\rho_{i:j}$ to represent the subexecution $q_i\to q_{i+1}\to \ldots \to q_j$ of $\rho$. Using this notation, $tail(\rho) = \rho_{i:} = \rho_{i:n}$.
\end{defn}

\begin{defn}[execution probabilities]
    Consider a execution $\rho = q_0\to q_1\to \ldots \to q_n$ of length $n$. Let $t_0=(q_0, q_1, c_0, \sigma_0, \tau_0)$ between states $q$ and $q'$. Additionally, let $\texttt{x}_0$ be the initial value of $\texttt{x}$ at $q_0$. 
    
    If $\sigma_0 \in \{\texttt{insample}, \texttt{insample}'\}$, then let $\sigma_0 = (\texttt{insample}, a, b)$ or $\sigma_0 = (\texttt{insample}', a', b')$ as appropriate. 

    Additionally, let $(u, v), (u', v')\in \RR_{\infty}$ be defined as follows:
    \begin{align*}
        (u, v) &= \begin{cases}
        (-\infty, \infty) & c_0=\texttt{true}\land \sigma_0 \neq (\texttt{insample}, a, b)\\
        (a, b) &c_0=\texttt{true}\land \sigma_0 = (\texttt{insample}, a, b)\\
        (-\infty, \texttt{x}_0) & c_0=\lguard\land \sigma_0 \neq (\texttt{insample}, a, b)\\
        (c, \min(\texttt{x}_0, d)) &c_0=\lguard\land \sigma_0 = (\texttt{insample}, a, b)\\
        (\texttt{x}_0, \infty) & c_0=\gguard\land \sigma_0 \neq (\texttt{insample}, a, b)\\
        (\max(\texttt{x}_0, c), d) &c_0=\gguard\land \sigma_0 = (\texttt{insample}, a, b)\\
    \end{cases}\\
    (u', v')& = (a', b')\end{align*}

    Then, given an initial $\texttt{x}$-value $\texttt{x}_0$, an input sequence $\texttt{in}\in \RR^n$, and an output sequence $\sigma\in (\Gamma\cup\RR)^n$, the probability of $\rho$ is defined as \[
        \PP[\texttt{x}_0, \rho, \texttt{in}, \sigma] = \begin{cases}
            1 & n = 0\\
            \int_u^v \Lap_{\texttt{in}_0, \frac{1}{d_0\varepsilon}}(z)dz\PP[\texttt{x}_0, \rho_{1:}, \texttt{in}_{1:}, \sigma_{1:}] & \sigma_0 \neq \texttt{insample}' \land \tau_0 = \texttt{false}\\
            \int_u^v \Lap_{\texttt{in}_0, \frac{1}{d_0\varepsilon}}(z)\PP[z, \rho_{1:}, \texttt{in}_{1:}, \sigma_{1:}]dz  & \sigma_0 \neq \texttt{insample}'\land \tau_0=\texttt{true} \\
            \int_{u'}^{v'}\Lap_{\texttt{in}_0, \frac{1}{d'_0\varepsilon}}(z')dz'\int_u^v \Lap_{\texttt{in}_0, \frac{1}{d_0\varepsilon}}(z)dz\PP[\texttt{x}_0, \rho_{1:}, \texttt{in}_{1:}, \sigma_{1:}]& \sigma_0 = \texttt{insample}'\land \tau_0 = \texttt{false}\\
            \int_{u'}^{v'}\Lap_{\texttt{in}_0, \frac{1}{d'_0\varepsilon}}(z')dz'\int_u^v \Lap_{\texttt{in}_0, \frac{1}{d_0\varepsilon}}(z)\PP[z, \rho_{1:}, \texttt{in}_{1:}, \sigma_{1:}]dz& \sigma_0 = \texttt{insample}'\land \tau_0 = \texttt{true}
        \end{cases}
    \]
    where $\Lap_{\mu, s}(x)$ is the PDF of a Laplace distribution with mean $\mu$ and spread parameter $s$.
\end{defn}

For a complete execution $\rho$, note that the initial value of $\texttt{x}$ is irrelevant, so we will shorthand $\PP[\texttt{x}_0, \rho, \texttt{in}, \sigma]$ to $\PP[\rho, \texttt{in}, \sigma]$.

Additionally, because we now read in a \textit{sequence} of real-valued inputs, we need to slightly modify our definition of adjacency.

\begin{defn}[Adjacency for a sequence of inputs]
    Two input sequences $\{\alpha_i\}_{i=1}^n, \{\beta_i\}_{i=1}^n$ of length $n$ are $\Delta$-adjacent (notated $\alpha \sim_{\Delta}\beta$) if, for all $i\in [1\ldots n]$, $|\alpha_i-\beta_i|\leq \Delta$. 

    If $\Delta$ is not specified, we assume that $\Delta = 1$. 
\end{defn}

Thus, we get the following definition of privacy:

\begin{defn}[$d\varepsilon$-differential privacy for a execution]
    A complete execution $\rho$ of length $n$ is $d\varepsilon$-differentially private for some $d>0$ if $\forall \varepsilon>0$, for all adjacent input sequences $\alpha\sim \beta$ of length $n$ and all possible output sequences $\sigma$ of length $n$, $\PP[\rho, \alpha, \sigma]\leq e^{d\varepsilon}\PP[\rho, \beta, \sigma]$.
\end{defn}

\subsubsection{Concatenating couplings}

Let $\rho[\texttt{in}]$ be a random variable representing the output of $\rho$ given input sequence $\texttt{in}$. 

In order to show that a program execution $\rho$ is differentially private, for all adjacent inputs $\alpha\sim\beta$ and all possible outputs $\sigma$, we want to create the coupling $\rho[\alpha]\{(a, b): a=\sigma\implies b=\sigma\}^{\#d\varepsilon}\rho[\beta]$ for some $d>0$. 

Ideally, we would like to simply create couplings for each individual transition in $\rho$ as before and compose them together to create this overall coupling. Indeed, this approach is almost sufficient; the constraints imposed upon shifts for a coupling for transition $t_i$ depend solely on the shift at the most recent \textbf{assignment transition} in $\rho$ (i.e. the most recent transition $t_j$ such that $\tau_j = \texttt{true}$). 
The coupling shifts for \textit{non-assignment transitions} can thus never impact each other. 

\begin{defn}[Assignment transitions]
    Let $A_\rho = \{t_i=(q_i, q_{i+1}, c_i, \sigma_i, \tau_i): \tau_i = \texttt{true}\}$ be the set of \textbf{assignment transitions} in a execution $\rho$. 

    For every transition $t_i$ in $\rho$, let $t_{at(i)}$ be the most recent assignment transition in $\rho$; i.e., $at(i) = \max\{j<i: t_j\in A_\rho\}$. If such a $j$ does not exist, we set $at(i)=-1$. 
\end{defn}

In particular, note that for transition $t_i$, $\gamma_x = \gamma_{at(i)}$, where $\gamma_{-1}$ is the shift applied to the initial $\texttt{x}$-values $\texttt{x}_0\brangle{1}$ and $\texttt{x}_0\brangle{2}$.

Thus, for an individual transition $t_i$ of $\rho$. From proposition \ref{indivTransitionCouplingProp}, we have a family of valid coupling strategies $C_i(\gamma_{at(i)}, \gamma_i, \gamma_i')$. 

We can merge these coupling strategies together to create a proof of privacy for the entire execution: 

\begin{lemma}\label{multTransitionsCouplingProof}
    Let $\rho = q_0\to \ldots \to q_n$ be a complete execution of length $n$. 
    Let $\texttt{in}\brangle{1}\sim \texttt{in}\brangle{2}$ be arbitrary adjacent input sequences of length $n$. Additionally, fix some potential output $\sigma$ of $\rho$ of length $n$ and let $\sigma\brangle{1}$, $\sigma\brangle{2}$ be random variables representing possible outputs of $\rho$ given inputs $\texttt{in}\brangle{1}$ and $\texttt{in}\brangle{2}$, respectively. Additionally, for all $q_i$, let $P(q_i) = (d_i, d_i')$.

    Then $\forall \varepsilon>0$ and for all $\{\gamma_i, \gamma_i'\}_{i=0}^{n-1}$ that, for all $i$, satisfy the constraints \[
        \begin{cases}
          \gamma_i\leq\gamma_{at(i)} & c_i = \lguard[\texttt{x}]\\
          \gamma_i\geq\gamma_{at(i)} & c_i = \gguard[\texttt{x}]\\
          \gamma_i=0 & \sigma_i = \texttt{insample}\\
          \gamma_i'=0 & \sigma_i = \texttt{insample}'
        \end{cases},
      \]
      the lifting $\sigma\brangle{1}\{(a, b): a=\sigma\implies b=\sigma\}^{\#d\varepsilon}\sigma\brangle{2}$ is valid for $d = \sum_{i=0}^{n-1}(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i|)d_i+(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i'|)d_i'$, and therefore $t$ is $d\varepsilon$-differentially private. 
\end{lemma}
\begin{proof}
    From the proof of lemma \ref{indTransitionCoupling}, we know that we can create the couplings $\texttt{insample}_i\brangle{1} +\gamma_i{(=)}^{\#(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i|)d_i\varepsilon}\texttt{insample}_i\brangle{2}$ and $\texttt{insample}_i'\brangle{1} +\gamma_i'{(=)}^{\#(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i'|)d_i'\varepsilon}\texttt{insample}_i'\brangle{2}$ for all $q_i$ in $\rho$. 

    Additionally, for some fixed $q_i$ in $\rho$, if we have the coupling $\texttt{x}_i\brangle{1}+\gamma_x (=)^{\#(|\hat{\mu_i}\brangle{1}-\hat{\mu_i}\brangle{2}+\gamma_x|)\hat{d_i}\varepsilon}x_i\brangle{2}$, where $\texttt{x}_i\brangle{1}\sim \Lap(\hat{\mu_i}\brangle{1}, \frac{1}{\hat{d_i}\varepsilon})$ and $\texttt{x}_i\brangle{2}\sim \Lap(\hat{\mu_i}\brangle{2}, \frac{1}{\hat{d_i}\varepsilon})$, then subject to the constraints \[
        \begin{cases}
          \gamma_i\leq\gamma_x & c_i = \lguard[\texttt{x}]\\
          \gamma_i\geq\gamma_x & c_i = \gguard[\texttt{x}]\\
          \gamma_i=0 & \sigma_i = \texttt{insample}_i\\
          \gamma_i'=0 & \sigma_i = \texttt{insample}_i'
        \end{cases},
      \]
    the coupling $\sigma_i\brangle{1}\{(a, b): a=\sigma_i\implies b=\sigma_i\}^{\#d\varepsilon}\sigma_i\brangle{2}$ is valid for some $d$. 

    Indeed, note that for all $i$, $\texttt{x}_i = \texttt{insample}_{at(i)}$ by definition. Thus, we have that $\texttt{x}_i\brangle{1}+\gamma_x (=)^{\#(|-\texttt{in}_{at(i)}\brangle{1}+\texttt{in}_{at(i)}\brangle{2}+\gamma_{at(i)}|)d_{at(i)}\varepsilon}x_i\brangle{2}$, and we must satisfy the constraints \[
        \begin{cases}
          \gamma_i\leq\gamma_{at(i)} & c_i = \lguard[\texttt{x}]\\
          \gamma_i\geq\gamma_{at(i)} & c_i = \gguard[\texttt{x}]\\
          \gamma_i=0 & \sigma_i = \texttt{insample}_i\\
          \gamma_i'=0 & \sigma_i = \texttt{insample}_i'
        \end{cases}
      \]
      for all $i$.

    Thus, we can put all of these couplings together to show that the coupling $\sigma_i\brangle{1}\{(a, b): a=\sigma_i\implies b=\sigma_i\}^{\#d\varepsilon}\sigma_i\brangle{2}$ is valid for some $d>0$.

    In particular, note that we have created at most one pair of couplings (for $\texttt{insample}$ and $\texttt{insample}$) for each $q_i$. Thus, the total coupling cost associated with each $q_i$ is at most $(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i|)d_i+(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i'|)d_i'$, 
    which gives us an overall coupling cost of $d = \sum_{i=0}^{n-1}(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i|)d_i+(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i'|)d_i'$.
\end{proof}
\begin{defn}
    For a complete execution $\rho$ of length $n$ and adjacent input sequences $\texttt{in}\brangle{1}\sim \texttt{in}\brangle{2}$, a \textbf{coupling strategy} is two functions $\bm{\gamma}(\texttt{in}\brangle{1}, \texttt{in}\brangle{2}):\RR^n\times \RR^n\to [-1, 1]^n$ and $\bm{\gamma}'(\texttt{in}\brangle{1}, \texttt{in}\brangle{2}):\RR^n\times \RR^n\to [-1, 1]^n$ that produce shifts for each transition of $\rho$ dependent on the input sequences. 

    If $\texttt{in}\brangle{1}$ and $\texttt{in}\brangle{2}$ are clear from context, we will often shorthand notating a coupling strategy as $\bm{\gamma}$ and $\bm{\gamma}'$. 
\end{defn}

\begin{defn}
    For a complete execution $\rho$ of length $n$, a coupling strategy $C_\rho = (\bm{\gamma}, \bm{\gamma}')$ is \textbf{valid} if $\forall \texttt{in}\brangle{1}\sim\texttt{in}\brangle{2}$, $\bm{\gamma}(\texttt{in}\brangle{1}, \texttt{in}\brangle{2})$ and $\bm{\gamma}'(\texttt{in}\brangle{1}, \texttt{in}\brangle{2})$ satisfy the constraints \[
        \begin{cases}
          \gamma_i\leq\gamma_{at(i)} & c_i = \lguard[\texttt{x}]\\
          \gamma_i\geq\gamma_{at(i)} & c_i = \gguard[\texttt{x}]\\
          \gamma_i=0 & \sigma_i = \texttt{insample}\\
          \gamma_i'=0 & \sigma_i = \texttt{insample}'
        \end{cases}.
      \]
\end{defn}

\subsubsection{Optimizing Privacy}

\begin{defn}
    For a complete execution $\rho$ of length $n$, the \textbf{cost} of a coupling strategy $C_\rho=(\bm{\gamma}, \bm{\gamma}')$ is \[cost(C_\rho) = \max_{\texttt{in}\brangle{1}\sim\texttt{in}\brangle{2}}\sum_{i=0}^{n-1}(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i|)d_i+(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i'|)d_i'.\]

    Additionally, let $G$ be the set of all valid coupling strategies $C_\rho=(\bm{\gamma}, \bm{\gamma}')$ for $\rho$. Then the \textbf{coupling cost} of $\rho$ is 
    \[cost(\rho) = \min_{(\bm{\gamma}, \bm{\gamma}')\in G}cost((\bm{\gamma}, \bm{\gamma}')).\]
\end{defn}

As before, the existence of a valid coupling strategy upper bounds the privacy cost of any execution. 

\begin{prop}
    If $C_\rho=(\bm{\gamma}, \bm{\gamma}')$ is valid, then $\rho$ is $cost(C_\rho)\varepsilon$-differentially private.
\end{prop}

\begin{proof}
    Follows immediately from lemma \ref{multTransitionsCouplingProof}.
\end{proof}

\begin{cor}
    Any complete execution $\rho$ is $cost(\rho)\varepsilon$-differentially private. Further, for all complete executions $\rho$, $cost(\rho)<\infty$. 
\end{cor}

\begin{proof}
    The first claim follows immediately from definitions. 
    
    The second claim follows by considering a coupling strategy $(\bm{\gamma}, \bm{\gamma}')$ where $\forall \texttt{in}\brangle{1}\sim\texttt{in}\brangle{2}, \bm{\gamma} = \bm{\gamma}' = \bm{0}$. Note that $(\bm{\gamma}, \bm{\gamma}')$ is trivially valid. Since $\texttt{in}\brangle{1}\sim\texttt{in}\brangle{2}$, $cost(\rho)\leq cost(C_\rho(\bm{0}))\leq \sum_{i=0}^{n-1}(d_i+d_i')$, which is finite for all fixed $\rho$. 
\end{proof}


\begin{prop}
    The cost of a coupling strategy over a fixed execution $\rho$ is maximized when, for every transition, the difference between the input values is $1$. In other words,
    \begin{align*}
        &\max_{\texttt{in}\brangle{1}\sim \texttt{in}\brangle{2}} \sum_{i=0}^{n-1}(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i|)d_i+(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i'|)d_i' \\
        = &\max_{\Delta\in \{-1, 1\}} \sum_{i=0}^{n-1}(|\Delta-\gamma_i|)d_i+(|\Delta-\gamma_i'|)d_i'
    \end{align*}
\end{prop}
\begin{proof}
    (Vishnu)
\end{proof}

Note then, that the process of finding the optimal coupling cost of a execution $\rho$ can be formulated as a linear program.
 

\subsection{Branching}


\begin{defn}[Branching program]
    Given a set of program states $Q$, a branching program $B$ is a finite set of complete executions over $Q$ such that for all $\rho=q_0\to\ldots\to q_n, \rho'=q'_0\to\ldots\to q'_m\in B$, $q_0=q'_0$. $B$ must also satisfy the following properties: \begin{enumerate}
        \item If any transition $t$ in any execution $\rho\in B$ is of the form $(q, q', c, \sigma, \tau)$, then no other transitions of the form $(q, q^*, c, \sigma', \tau')$ for $q, q', q^*\in Q$ exist in any execution of $B$. 
        Additionally, if any transition $t$ in any execution $\rho\in B$ is of the form $(q, q', \texttt{true}, \sigma, \tau)$, then transitions of the form $(q, q^*, \lguard[\texttt{x}], \sigma', \tau')$ or $(q, q^*, \lguard[\texttt{x}], \sigma', \tau')$ do not exist in any execution of $B$.
        \item If a transition of the form $(q, q', \lguard[\texttt{x}], \sigma, \tau)$ exists in any execution in $B$ and a transition of the form $(q, q^*, \gguard[\texttt{x}], \sigma', \tau')$ exists in any (potentially different) execution in $B$, then $\sigma \neq \sigma'$. Additionally, at least one of $\sigma\in \Gamma$, $\sigma'\in \Gamma$ is true.
    \end{enumerate} 
    We will refer to the first condition as \textbf{determinism} and the second condition as \textbf{output distinction}.
\end{defn}

\subsubsection{Privacy}

\begin{defn}[DP for branching programs]
    A branching program is DP if [standard def]
\end{defn}

\begin{prop}
    A branching program $B$ is $d\varepsilon$-differentially private for $d>0$ if and only if for every complete execution $\rho$ in $B$, $\rho$ is $d\varepsilon$-differentially private.
\end{prop}
\begin{proof}
    From the conditions of output distinction and determinism, note that for every single possible output $\sigma$ of $B$, there is exactly one possible execution $\rho$ that could have output $\sigma$. Thus, the probability that $B$ outputs $\sigma$ is exactly the probability that $\rho$ outputs $\sigma$; the result follows immediately.
\end{proof}


We can do no better than assigning coupling strategies for each execution independently. 
\begin{defn}[Coupling strategies]
    A (branched program) coupling strategy $C$ for a branching program $B$ is a collection of (execution) coupling strategies where each complete execution $\rho\in B$ is assigned a coupling strategy $C_\rho$. 
\end{defn}

\begin{defn}
    A coupling strategy $C$ for a branching program $B$ is valid if, for every constituent execution coupling strategy $C_\rho$, $C_\rho$ is valid. 
\end{defn}

\begin{defn}
    The cost of a coupling strategy $C$ for a branched program $B$ is \[
        \max_{\rho\in B}cost(\rho)
    \]
\end{defn}

\begin{prop}\label{costDependsExecutionProp}
    Optimal cost is dependent on execution (Vishnu)
\end{prop}

As previously noted, we use a finite union of complete executions to model an underlying program with branching, in part due to proposition \ref{costDependsExecutionProp}. We now formally define that underlying model:

\begin{defn}
    The underlying graph [NAME VERY TENTATIVE] of a branching program $B$ is the directed acyclic graph $G = (V, E)$ such that $V = Q$ and $(q, q')\in E$ if, for some execution $\rho\in B$, there exists a transition $t\in \rho$ such that $t = (q, q', c, \sigma, \tau)$ for some $c, \sigma, \tau$.  

    {\color{red} need also to force this to be acyclic}
\end{defn}


\subsection{Loops}

We will illustrate applying coupling strategies to loops through a simple \textbf{lasso} model. 

\begin{defn}[Lassos]
    Consider a complete execution $\rho = q_0\to\ldots \to q_n$ such that for some $i<n$, $q_i = q_n$. Suppose also that $\forall j\neq i$, $q_j \neq q_n$. A lasso $L_\rho$ is the infinite set of executions $\{q_0\to\ldots\to q_{i-1}\to (q_i\to\ldots\to q_{n-1})^k\to q_n| k\in \NN\}$, where $(q_i\to\ldots\to q_{n-1})^k$ means that the subexecution $(q_i\to\ldots\to q_{n-1})^k$ is iterated $k$ times. 
    Additionally, $L_\rho$ must satisfy the properties of \textbf{determinism} and \textbf{output distinction} as with branching programs.
\end{defn}

\begin{defn}[Lasso privacy]
    A lasso $L_\rho$ is $d\varepsilon$-differentially private for $d>0$ if for all complete executions $\rho'$ in $L_\rho$, for all possible outputs $\sigma_{\rho'}$ of $\rho'$ and input sequences $\texttt{in}\brangle{1}\sim \texttt{in}\brangle{2}$, $\forall \varepsilon>0, \PP[\rho', \sigma_{\rho'}, \texttt{in}\brangle{1}]\leq e^{d\varepsilon}\PP[\rho', \sigma_{\rho'}, \texttt{in}\brangle{2}]$.
\end{defn}

\begin{prop}
    A lasso $L_\rho$ is $d\varepsilon$-differentially private for $d>0$ if and only if for all complete executions $\rho'$ in $L_\rho$, $\rho'$ is $d\varepsilon$-differentially private. 
\end{prop}

\begin{defn}[Coupling strategies]
    A \textbf{coupling strategy} for a lasso $L_\rho$, where $\rho=q_0\to\ldots \to q_n$ is an assignment of shifts $\gamma_i, \gamma_i'$ for each transition in $\rho$ as a function of the input differences. 
\end{defn}

\begin{defn}[Validity]
    A coupling strategy $C_{L_\rho}=(\bm{\gamma}, \bm{\gamma}')$ for a lasso $L_\rho$ is \textbf{valid} if, for all executions $\rho'$ of $A$, the following constraints hold for all adjacent input sequences $\alpha\sim\beta$ and for all $i$:
    \begin{itemize}
        \item If $c_i = \lguard[\texttt{x}]$, then $\gamma_i\leq\gamma_{at(i)}$
        \item If $c_i = \gguard[\texttt{x}]$, then $\gamma_i\geq\gamma_{at(i)}$
        \item If $\sigma_i = \texttt{insample}$, then $\gamma_i=0$
        \item If $\sigma_i = \texttt{insample}'$, then $\gamma_i'=0$
    \end{itemize}
\end{defn}

Note that given a complete execution $\rho'$ in a lasso $L_\rho$, a coupling strategy $C_A$ induces a coupling strategy $C_{\rho'}$ for $\rho'$.

\begin{defn}
    The \textbf{cost} of a coupling strategy $C_{L_\rho} = (\bm{\gamma}, \bm{\gamma}')$ for a lasso $L_\rho$ is \begin{align*}
    cost(C_{L_\rho}) &= \sup_{\rho'\in L_{\rho}}\max_{\texttt{in}\brangle{1}\sim \texttt{in}\brangle{2}} \sum_{i=0}^{|\rho'|-1}(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i|)d_i+(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i'|)d_i'\\
    &=\sup_{\rho'\in L_\rho}cost(C_{\rho'})
\end{align*}
    Further, let $G_{L_\rho}$ be the set of all valid coupling strategies for $L_\rho$. Then the \textbf{coupling cost} of $L_\rho$ is \[
        cost(L_\rho) = \min_{C_{L_\rho}\in G_{L_\rho}}cost(C_{L_\rho})
    \]
\end{defn}

\begin{prop}
    Given a valid coupling strategy $C_{L_\rho}$ for a lasso $L_\rho$, $L_\rho$ is $cost(C_{L_\rho})\varepsilon$-differentially private. 
\end{prop}
\begin{proof}
    Let $\rho'$ be a complete execution in $L_\rho$ and let $C_{\rho'}$ be the coupling strategy for $\rho'$ derived from $C_A$. We know from lemma \ref{multTransitionsCouplingProof} that, if $C_A$ is valid, then the lifting $\sigma\brangle{1}\{(a, b): a=\sigma\implies b=\sigma\}^{\#cost(C_{\rho'})\varepsilon}\sigma\brangle{2}$ is valid, 
    and therefore for all possible outputs $\sigma$ of $\rho'$ and adjacent inputs $\texttt{in}\brangle{1}\sim\texttt{in}\brangle{2}$, $\forall \varepsilon>0, \PP[\rho', \sigma, \texttt{in}\brangle{1}]\leq e^{cost(C_{\rho'})\varepsilon}\PP[\rho', \sigma, \texttt{in}\brangle{2}]\leq e^{cost(C_{L_\rho})\varepsilon}\PP[\rho', \sigma, \texttt{in}\brangle{2}]$.
\end{proof}
\begin{cor}
    A lasso $L_\rho$ is $cost(L_\rho)\varepsilon$-differentially private. 
\end{cor}



\begin{lemma}\label{finiteCostConstraintLemma}
    For a lasso $L_\rho$, given adjacent input sequences $\texttt{in}\brangle{1}\sim \texttt{in}\brangle{2}$, a valid coupling strategy $C_{L_\rho} = (\mathbf{\gamma}, \mathbf{\gamma}')$ has finite cost $cost(C_{L_\rho})<\infty$ if and only if the following constraint applies for all $i$:
    \begin{itemize}
        \item If $t_i$ is in a cycle and $c_i\neq\texttt{true}$, then $\gamma_i = -\texttt{in}\brangle{1}_i+\texttt{in}\brangle{2}_i$ and $\gamma_i' = -\texttt{in}\brangle{1}_i+\texttt{in}\brangle{2}_i$.
    \end{itemize}
\end{lemma}

\begin{proof}
    {\color{red} TODO: check the $c_i\neq \texttt{true}$ condition}

    ($\impliedby$)

    Let $T$ be the set of transitions $t_i$ in $L_\rho$ such that $t_i$ is \textbf{not} in a cycle. Note that $T$ is independent of any choice of execution(s) through $L_\rho$. 

    Fix a complete execution $\rho'$ in $L_\rho$ and let $C_\rho'$ be the coupling strategy for $\rho'$ induced by $C_{L_\rho}$. 

    Let $D_\rho$ be the set of transitions $t_i$ in $\rho$ such that $t_i$ is in a cycle in $L_\rho$, i.e., $t_i\notin T$.  

    If the given constraint holds, then we know that $\max_{\texttt{in}\brangle{1}\sim\texttt{in}\brangle{2}}\sum_{i: t_i\in D_\rho}(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i|)d_i+(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i'|)d_i' = 0$

    So \begin{align*}
        cost(C_\rho) = \max_{\texttt{in}\brangle{1}\sim\texttt{in}\brangle{2}}&\sum_{i: t_i\in D_\rho}(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i|)d_i+(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i'|)d_i'\\
        &+\sum_{i: t_i\notin D_\rho}(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i|)d_i+(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i'|)d_i'\\
        = \max_{\texttt{in}\brangle{1}\sim\texttt{in}\brangle{2}}&\sum_{i: t_i\in T}(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i|)d_i+(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i'|)d_i'\\
        \leq \sum_{i:t_i\in T}(2d_i& + 2d_i')\\
        \leq |T|\max_{i:t_i\in T}&(2d_i + 2d_i')
    \end{align*}

    ($\implies$)

    Suppose that some transition $t_i$ is in a cycle $C$ in $A$ and $\gamma_i\neq -\texttt{in}\brangle{1}_i+\texttt{in}\brangle{2}_i$ or $\gamma_i'\neq  -\texttt{in}\brangle{1}_i+\texttt{in}\brangle{2}_i$. Then $\exists \texttt{in}\brangle{1}\sim \texttt{in}\brangle{2}$ such that $(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i|)d_i+(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i'|)d_i'>0$.

    Fix such a $\texttt{in}\brangle{1}\sim \texttt{in}\brangle{2}$. 

    Let $\rho_k$ be a complete execution in $A$ with $C$ iterated $k$ times. Then for all $k\in \NN$, \begin{align*}
        cost(\rho_k) \geq k((|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i|)d_i+(|-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}-\gamma_i'|)d_i'),
    \end{align*}
    so for all $M\in \RR$, $\exists \rho_k$ such that $cost(\rho_k) > M$.
\end{proof}

{\color{red} move these two lemmas away from this section (appendix or closer to usage in main theorem)}

\begin{lemma}\label{cycleGammaConstraints}
    If a coupling strategy $C=(\mathbf{\gamma}, \mathbf{\gamma}')$ for a lasso $L_\rho$ is valid and has finite cost, then the following must hold for all $i$:
    \begin{enumerate}
        \item If $t_i$ is in a cycle and $c_i = \lguard[\texttt{x}]$, then $\gamma_i = -\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}$ and $\gamma_{at(i)} = 1$.
        \item If $t_i$ is in a cycle and $c_i = \gguard[\texttt{x}]$, then $\gamma_i = -\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}$ and $\gamma_{at(i)} = -1$.
    \end{enumerate}
\end{lemma}
\begin{proof}
    We will show (1). (2) follows symmetrically.

    Consider some $t_i$ in a cycle where $c_i = \lguard[\texttt{x}]$. Because $C$ is has finite cost, we know from lemma \ref{finiteCostConstraintLemma} that $\gamma_i = -\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}$ for all  $\texttt{in}_i\brangle{1}\sim\texttt{in}_i\brangle{2}$. In particular, when $-\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}=1$, then $\gamma_i=1$. 
    
    Further, because $\gamma_{at(i)}$ must be greater than $\gamma_i$ for all $\texttt{in}_i\brangle{1}\sim\texttt{in}_i\brangle{2}$ for $C$ to be valid, we must have that $\gamma_{at(i)}=1$.
\end{proof}
\begin{lemma}
    If a valid finite cost coupling strategy $C = (\gamma, \gamma')$ exists for a lasso $L_\rho$, then there exists a valid finite cost coupling strategy $C^*= (\gamma^*, \gamma^{*\prime})$ such that for all $i\in AT(L_\rho)$, $\gamma_i^*\in \{-1, 0, 1\}$. 
\end{lemma}
\begin{proof}
    TBD
\end{proof}

\subsection{Programs}



\begin{defn}
    Given a finite state space $Q$, a program $A$ is a set of complete executions $\rho$ such that for all $\rho=q_0\to\ldots\to q_n, \rho'=q'_0\to\ldots\to q'_m\in B$, $q_0=q'_0$ and $A$ satisfies the following closure property:\begin{itemize}
        \item If a complete execution $\rho\in A$ such that $\rho = q_0\to \ldots \to q_i \to \ldots \to q_j \to q_i\to \ldots \to q_n$, then, for all $k\in \NN$, the execution $\rho_k\in A$, where $\rho_k = q_0\to \ldots \to (q_i \to \ldots \to q_j)^k \to q_i\to \ldots \to q_n$.
    \end{itemize}
    Additionally, $A$ must satisfy the properties of \textbf{determinism} and \textbf{output distinction}, as with branching programs. 
\end{defn}

Intuitively, this closure condition means that if a execution $\rho$ with the cycle $q_i\to \ldots \to q_j\to q_i$ is in $A$, then every execution that is identical to $\rho$ except with the cycle iterated a different number of times must be in $A$ as well. 

\begin{defn}[DP]
    A program $A$ is $d\varepsilon$-differentially private for some $d>0$ if for all adjacent input sequences $\texttt{in}\brangle{1}\sim \texttt{in}\brangle{2}$ and for all possible outputs $\sigma$ of $A$, $\PP[\sigma, \texttt{in}\brangle{1}]\leq e^{d\varepsilon}\PP[\sigma, \texttt{in}\brangle{2}]$.
\end{defn}

As with branching programs, the conditions of determinism and output distinction mean that knowing the output of a program means that we know what execution the program must have taken. 

\begin{prop}
    For every complete execution $\rho$ of a program $A$, $\rho$ is $d\varepsilon$-differentially private if and only if $A$ is differentially private. 
\end{prop}

As expected, then, we can use coupling strategies for executions to prove privacy.

\begin{prop}
    If, for every complete execution $\rho$ of a program $A$, there is a coupling strategy $C_\rho$ such that $cost(C_\rho)<d$, then $A$ is $d\varepsilon$-differentially private.
\end{prop}

However, this naive approach is not actually tractable, since there are possibly an unbounded number of executions in a single program $A$. 

What we will show instead is that, inspired by our work with lassos, we can choose a coupling strategy for each of a finite number of execution classes of $A$, which will induce coupling strategies for every execution of $A$. 

\hrulefill
{\color{red} ALTERNATIVE DEFINITION FROM SUBGRAPHS}
\begin{defn}
    For an execution $\rho$ of a program $A$, let $graph(\rho)$ be the subgraph of the underlying graph of $A$ that is traversed by $\rho$. That is, if the underlying graph of $A$ is $G=(V, E)$, then $graph(\rho) = (V', E')$, where $V'\subseteq V$, $E'\subseteq E$, and for all transitions $t_i = (q_i, q_{i+1}, c_i, \sigma_i, \tau_i)$, $q_i, q_{i+1}\in V$ and $(q_i, q_{i+1}) \in E$. 
\end{defn}

Note that the relation between complete executions $\sim_G$ where $\rho \sim_G\rho'$ if and only if $graph(\rho) = graph(\rho')$ is clearly an equivalence relationship; let $[\rho]_G$ be the equivalence class of $\rho$ defined by this relationship for any complete execution $\rho$ of a program $A$. 

\begin{defn}[Class Coupling Strategies]
    Consider an execution class $[\rho]_G$ of a program $A$ and let $G=(V, E) = graph(\rho)$ be the underlying subgraph of $[\rho]_G$. A [name tentative] class coupling strategy $C_{[\rho]_G}$ for $[\rho]_G$ is a function $C_{[\rho]_G}: E\to (\RR\times\RR\to[-1, 1])\times (\RR\times\RR\to[-1, 1])$ mapping edges of $G$ to shift functions $(\gamma, \gamma')$.
\end{defn}

Observe that there are a finite possible number of execution classes of a program $A$ since $A$ must have a finite number of states; additionally, a class coupling strategy for an execution class $[\rho]_G$ directly induces execution coupling strategies for every complete execution in the class. 


\hrulefill

\begin{defn}[Execution Descriptions]
    Given a complete execution $\rho = q_0\to \ldots \to q_n$ of a program $A$, let the description $desc(\rho)$ of $\rho$ be the cycle-free substring of $\rho$. {\color{red} still don't like this definition}
\end{defn}

Note that the relation between complete executions $\sim$ where $\rho \sim\rho'$ if and only if $desc(\rho) = desc(\rho')$ is clearly an equivalence relationship; let $[\rho]$ be the equivalence class of $\rho$ defined by this relationship for any complete execution $\rho$ of a program $A$. 

\begin{defn}[Execution Class]
    An execution class $[\rho]$ of a program $A$ is the equivalence class of an execution $\rho$ of $A$ under the aforementioned equivalence relation. 
\end{defn}

\begin{obs}
    There are a finite number of execution classes of a program $A$ because there are a finite number of simple paths through any finite graph.
\end{obs}

\begin{defn}[Class Coupling Strategies]
    Given an execution class $[\rho]$ of a program $A$, let $T$ be the set of all transitions of any path in $[\rho]$. Note that $T$ is finite. Then a (class) coupling strategy for $[\rho]$ is a pair of functions $C = (\gamma, \gamma')$ such that $\gamma:T\to (\RR\times\RR\to[-1, 1])$ and $\gamma':(\RR\times\RR\to[-1, 1])$ are two shift functions that map each transition in $[\rho]$ to a shift in $[-1, 1]$. 
\end{defn}


\begin{defn}[Induced Coupling Strategy]
    {\color{red}not sure how necessary this is}
    Given a class coupling strategy $C = (\gamma, \gamma')$ for an execution class $[\rho]$ and a specific execution $\rho\in [\rho]$, the coupling strategy for $\rho=q_0\to \ldots \to q_n$ induced by $C$ is the pair of functions $\gamma_\rho, \gamma'_\rho$ such that 
    \begin{align*}
        \gamma_\rho(\texttt{in}\brangle{1}, \texttt{in}\brangle{2}) &= (\gamma(q_0\to q_1)(\texttt{in}\brangle{1}, \texttt{in}\brangle{2}), \gamma(q_1\to q_2)(\texttt{in}\brangle{1}, \texttt{in}\brangle{2}), \ldots,\gamma(q_{n-1}\to q_n)(\texttt{in}\brangle{1}, \texttt{in}\brangle{2}) )\\
        \gamma'_\rho(\texttt{in}\brangle{1}, \texttt{in}\brangle{2}) &= (\gamma'(q_0\to q_1)(\texttt{in}\brangle{1}, \texttt{in}\brangle{2}), \gamma'(q_1\to q_2)(\texttt{in}\brangle{1}, \texttt{in}\brangle{2}), \ldots,\gamma'(q_{n-1}\to q_n)(\texttt{in}\brangle{1}, \texttt{in}\brangle{2}) )
    \end{align*}
\end{defn}

\begin{defn}
    The cost of a class coupling strategy $C$ for an execution class $[\rho]$ is $cost(C) = \sup_{\rho\in [\rho]}cost(C_{\rho})$, where $C_{\rho}$ is the execution coupling strategy for $\rho'$ induced by $C$.
\end{defn}

\begin{prop}
    If, for every complete execution class $[\rho]$ of a program $A$, there is a coupling strategy $C_{[\rho]}$ such that $cost(C_{[\rho]})<d$, then $A$ is $d\varepsilon$-differentially private.
\end{prop}

As with lassos, we primarily care about making sure that cycle transitions are costless. 

\begin{prop}
    A valid class coupling strategy $C=(\gamma, \gamma')$ for an execution class $[\rho]$ has finite coupling cost if and only if the following constraint holds for all $i$: 
    \begin{itemize}
        \item If $t_i$ is in a cycle in $[\rho]$ and $c_i\neq\texttt{true}$, then $\gamma_i = -\texttt{in}\brangle{1}_i+\texttt{in}\brangle{2}_i$ and $\gamma_i' = -\texttt{in}\brangle{1}_i+\texttt{in}\brangle{2}_i$.
    \end{itemize}
\end{prop}


Indeed, collapsing the infinite collection of executions in a program to the finite set of execution classes does not cost us anything. 

\begin{prop}
    If there exists a valid coupling strategy $C_\rho$ with cost $cost(C_\rho)$ for every execution $\rho$ of an execution class $[\rho]$ in a program $A$ and $\sup_{\rho\in [\rho]}cost(C_\rho)< \infty$, then there exists a class coupling strategy $C'$ for $[\rho]$ of $A$ that is valid such that $cost(C') \leq \sup_{\rho\in [\rho]}cost(C_\rho)$. 
\end{prop}

\begin{proof}{\color{red} Make sure to put this proof after the DiPA counterexample proof}

    Because $\sup_{\rho\in [\rho]}cost(C_\rho)< \infty$, we can assume that there are no leaking cycles, disclosing cycles, leaking pairs, or privacy violating paths in $[\rho]$.


    For a given execution $\rho$ and a coupling strategy $C_\rho$, recall that we effectively assign each transition $t_i$ in $\rho$ the cost $\max_{\Delta \in \{-1, 0, 1\}}|\Delta - \gamma_i(\Delta)| + |\Delta' - \gamma'_i(\Delta)|$. For convenience, we will shorthand this quantity as $\delta(\rho, t_i) + \delta'(\rho, t_i)$.


    For all $n\in \NN$, let $\rho_n$ be the path in $[\rho]$ with every cycle in $\rho_n$ repeated $n$ times. 

   Let $cycle([\rho])$ be the set of all transitions in $[\rho]$ that are contained within a cycle in $[\rho]$. Observe that for all $t\in cycle([\rho])$, \[
        \lim_{n\to\infty}\inf_{t_i\in\rho_n: t_i=t} \delta(\rho_n, t_i) = 0
    \]
    Informally, for every cycle transition $t$ in $[\rho]$, if the cycle it is contained in is iterated enough times, there must be some iteration $t_i$ of $t$ that is assigned costs approaching 0. 

    This can be shown by considering a transition $t$ in a cycle in $[\rho]$ whose minimum coupling cost is non-zero (i.e. $\inf_{\rho\in[\rho]; t_i=t} \delta(t_i) > 0$). Then for any finite $d>0$, there exists an execution $\rho_n$ where $n>\lceil\frac{d}{\inf\delta(t_i)}\rceil+1$. Then $cost(C_{\rho^*})>d$, which implies that $\sup_{\rho\in [\rho]}cost(C_\rho) = \infty$, so the observation must hold. 

    Let $t_i$ be a transition in a cycle in $[\rho]$ and let $\mathcal{C}_i$ be the cycle containing $t_i$. 

    Then in particular, if $\mathcal{C}_i$ contains a transition with guard $\lguard[\texttt{x}]$, then for all $\psi>0$, there exists $n\in \NN$ such that for $\rho_n\in [\rho]$, $\gamma_{at(i)}> 1-\psi$ and if $\mathcal{C}_i$ contains a transition with guard $\lguard[\texttt{x}]$, then for all $\psi>0$, $\gamma_{at(i)}> -1+\psi$. 
    Informally, assignment transitions before an \lcycle\ have shifts that approach 1 and assignment transitions before a \gcycle\ have shifts that approach -1 in $\rho_n$ as $n\to\infty$. 

    Because we know that all coupling strategies $C_{\rho}$ are valid, this may also imply that other assignment transitions also have shifts that approach 1 or -1. 

    Further, if the shifts for an assignment transition $t_i$ approach 1, then the shifts for a transition $t_j$ such that $at(j) = i$ and $c_j = \gguard[\texttt{x}]$ must also approach 1; symmetrically, if the shifts for an assignment transition $t_i$ approach -1, then the shifts for a transition $t_j$ such that $at(j) = i$ and $c_j = \lguard[\texttt{x}]$ must also approach -1. 

    Let $T_1$ and $T_{-1}$ be the sets of assignment transitions in $[\rho]$ that approach 1 and -1, respectively. 

    Note that every other transition in $[\rho]$ is a non-cycle transition. Consider such a transition $t$ in $[\rho]$. Then for every execution $\rho\in [\rho]$ and its corresponding coupling strategy $C_\rho$, there is exactly one shift assignment for $t$ because $t$ is not in a cycle. 

    Let the class coupling strategy $C' = (\gamma, \gamma')$ be partially defined as follows: \begin{align*}
        \gamma(t_i)(\texttt{in}\brangle{1}, \texttt{in}\brangle{2}) &= \begin{cases}
            1 & t_i \in T_1\\
            -1 & t_i \in T_{-1}\\
            \texttt{in}\brangle{1}-\texttt{in}\brangle{2} & c_i = \lguard[\texttt{x}]\land t_{at(i)}\in T_1\\
            \texttt{in}\brangle{1}-\texttt{in}\brangle{2} & c_i = \gguard[\texttt{x}]\land t_{at(i)}\in T_{-1}\\
            1 & c_i = \gguard[\texttt{x}]\land t_{at(i)}\in T_1\\
            -1 & c_i = \lguard[\texttt{x}]\land t_{at(i)}\in T_{-1}
        \end{cases}\\
        \gamma'(t_i)(\texttt{in}\brangle{1}, \texttt{in}\brangle{2}) &=\begin{cases}
            0 & t_i\text{ outputs }\texttt{insample}'\\
            \texttt{in}\brangle{1}-\texttt{in}\brangle{2} & \text{otherwise}
        \end{cases}
    \end{align*}

    Let $T_{un}$ be the set of transitions in $[\rho]$ that are not assigned by $\gamma$ so far. Note that all transitions in $T_{un}$ are not in cycles. 

    Let $C^* = (\gamma^*, \gamma^{*\prime})$ be the minimal-cost valid class coupling strategy such that for all $t\notin T_{un}$, $\gamma^*(t) = \gamma(t)$. 

    In other words, $cost(C^*) = \inf_{\text{all such possible valid class coupling strategies } C} cost(C)$. Note that $C^*$ is valid. 

    We additionally claim that $cost(C^*)\leq \sup_{\rho\in [\rho]}cost(C_\rho)$. The cost of $C^*$ can be separated into costs attributed to $\gamma^{*\prime}$, costs attributed to all transitions not in $T_{un}$ by $\gamma^*$, and costs attributed to all transitions in $T_{un}$ by $\gamma^*$. 
    
    First, note that the coupling cost attributed to $\gamma^{*\prime}$ in $C^*$ must be at most the maximimum coupling cost attributed to $\gamma'$ over all execution-specific coupling strategies. From before, we additionally know that the cost attributed to all transitions $t\notin T_{un}$ by $\gamma^*$ is at most the supremum of the costs attributed to $t$ over all executions in $[\rho]$, since we take the limit of all such shifts for $\rho_n$ as $n\to\infty$.

    Finally, since all execution-specific coupling strategies are valid, taking the remaining transition shifts to minimize the overall cost while retaining a valid coupling strategy sufficies. 

    {\color{red} If i have time, come back to this argument - expressed poorly right now}
\end{proof}

Perhaps surprisingly, we prove that coupling proofs are \textbf{complete} for programs of this form; while producing a valid and finite cost coupling proof is clearly sufficient for a program to be private, it is also necessary for such a coupling proof to exist for privacy. 

\begin{thm}
    There exists a valid and finite cost coupling strategy for a program $P$ if and only if $P$ is $d\varepsilon$-differentially private for some $d>0$. 
\end{thm}

\begin{lemma}
    If there exists a valid coupling strategy with cost $d>0$ for a program $P$, then $P$ is $d\varepsilon$-differentially private. 
\end{lemma}
\begin{proof}
    [follows from all previous results]
\end{proof}


\subsection{DiPA}

\begin{defn}[DiPA]
    A DiPA $A$ is a tuple (...) [copy this def]
\end{defn}

\begin{defn}
    A DiPA $A$ is differentially private if [copy this def]
\end{defn}

\begin{prop}[informal]
    There is a bijection between the set $S_P$ of all possible programs $P$ and the set of all possible DiPAs $S_D$. [that preserves coupling proofs etc]
\end{prop}


\subsubsection{Deciding Privacy}


\begin{defn}[Leaking Pair, etc from DiPA]
    [...]
\end{defn}

\begin{thm}[from DiPA]\label{DiPACounterexamplesThm}
    If a DiPA $A$ has a leaking cycle, leaking pair, disclosing cycle, or privacy violating path, then $A$ is not $d\varepsilon$-differentially private for any $d>0$. 
\end{thm}

Note that for any path in $A$, we have a list of constraints that a coupling strategy $C=(\mathbf{\gamma}, \mathbf{\gamma}')$ can satisfy\begin{enumerate}
    \item If $c_i = \lguard[\texttt{x}]$, then $\gamma_i\leq\gamma_{at(i)}$
    \item If $c_i = \gguard[\texttt{x}]$, then $\gamma_i\geq\gamma_{at(i)}$
    \item If $\sigma_i = \texttt{insample}$, then $\gamma_i=0$
    \item If $\sigma_i = \texttt{insample}'$, then $\gamma_i'=0$
    \item If $t_i$ is in a cycle and $c_i\neq \texttt{true}$, then $\gamma_i = -\texttt{in}\brangle{1}_i+\texttt{in}\brangle{2}_i$
    \item If $t_i$ is in a cycle and $c_i\neq \texttt{true}$, then $\gamma_i' = -\texttt{in}\brangle{1}_i+\texttt{in}\brangle{2}_i$
\end{enumerate}

If all constraints are statisfied, then $A$ is private. 

\begin{lemma}
    If there does not exist a valid coupling strategy for a DiPA $A$ with finite cost, then $A$ is not differentially private. 
\end{lemma}
\begin{proof}
    Consider a ``maximially'' satisfied coupling strategy $C=(\mathbf{\gamma}, \mathbf{\gamma}')$; i.e. there is no other coupling strategy $C'$ for $A$ such that $C'$ satisfies more constraints than $C$. By lemma [tbd], we are allowed to only consider coupling strategies $C=(\gamma, \gamma')$ such that, for all $i\in AT(A)$, $\gamma_i \in \{-1, 0, 1\}$. 

    Fix some execution class $\rho$ in $A$ such that at least one constraint is not satisfied by $C$ as applied to $\rho$.

    By assumption, at least one constraint is unsatisfied by $C$. We will show that in every case, $A$ must contain at least one of a leaking cycle, leaking pair, disclosing cycle, or privacy violating path. By theorem \ref{DiPACounterexamplesThm}, this is sufficient to show that $A$ is not $d\varepsilon$-differentially private for any $d>0$.

    {\color{red} If I have time (low priority): rewrite this using a few helper lemmas to compress (e.g. $\gamma_{at(i)} =1\implies \lcycle$)}

    \textbf{Case 1: (1) is unsatisfied for $\gamma_i$}
    
    In this case, $c_i = \lguard[\texttt{x}]$ and $\gamma_i > \gamma_{at(i)}$. Note that $\gamma_{at(i)} \neq 1$. 

    We can assume that for all assignment transitions $t_at(k)$ in $\rho$ that $t_{at(k)}$ is not in a cycle, since otherwise there would be a leaking cycle in $A$. 

    \textbf{Case 1.1: $t_i$ is in a cycle}

    In this case, we can suppose that $t_i$ is not an assignment transition and $t_i$ does not output $\texttt{insample}$ or $\texttt{insample}'$, since otherwise either a leaking cycle or a disclosing cycle would clearly exist in $A$. We can thus additionally assume that constraint (5) is satisfied for $\gamma_i$. 
    
    Noe that the cycle containing $t_i$ is also an $\texttt{L}$-cycle by definition.

    Then attempting to resolve (1) for $\gamma_i$ by setting $\gamma_{at(i)} = 1$ must violate another constraint. In particular, either constraint (1) or (3) for $\gamma_{at(i)}$ or constraint (2) for some $\gamma_j$ such that $at(j) = at(i)$ must be newly violated. Note that constraint (5) for $\gamma_{at(i)}$ cannot be violated since we assumed that $t_{at(i)}$ is not in a cycle. 

    \textbf{Case 1.1.1: setting $\gamma_{at(i)} = 1$ violates constraint (1) for $\gamma_{at(i)}$}

    Let $t_{at(k)}$ be the earliest assignment transition before $t_{at(i)}$ such that, for all $at(k)\leq at(l)< at(i)$, $\gamma_{at(l)} <1$ and $c_{at(l)} = \lguard[\texttt{x}]$. Then there must be \textit{some} $\gamma_{at(l)}$ such that setting $\gamma_{at(l)} = 1$ would violate constraint (2) for some $\gamma_{l'}$ such that $at(l') = at(l)$. 

    Observe that $c_{l'} = \gguard[\texttt{x}]$ and there is an $\texttt{AL}$-path from $t_{l'}$ to $t_i$. 

    Then setting $\gamma_{l'}= 1$ must violate either constraint (3) or constraint (5) for $\gamma_{l'}$. If constraint (3) is violated, then $\gamma_{l'}$ is a transition with guard $\gguard[\texttt{x}]$ that outputs $\texttt{insample}$, so there is a privacy violating path from $t_{l'}$ to $t_i$. Otherwise if constraint (5) is violated, then $\gamma_{l'}$ is in a \gcycle, so there is a leaking pair composed of the cycles containing $t_{l'}$ and $t_i$, repectively. 

    \textbf{Case 1.1.2: Setting $\gamma_{at(i)}=1$ would violate (3) for $\gamma_{at(i)}$}

    Then $\gamma_{at(i)}$ is an assignment transition that outputs $\texttt{insample}$. Further, the path from $t_{at(i)}$ to $t_i$ is an $\texttt{AL}$-path, since there are no transitions on it. Thus, there is a privacy violating path from $t_i{at(i)}$ to $t_i$

    \textbf{Case 1.1.3: Setting $\gamma_{at(i)}=1$ would violate (2) for some $\gamma_j$ such that $at(j)= at(i)$}

    Note that, if $i<j$, the path from $t_i$ to $t_j$ (or vice versa, if $j<i$) is both an $\texttt{AL}$ and $\texttt{AG}$-path.

    Setting $\gamma_{j}= 1$ must violate either constraint (3) or constraint (5) for $\gamma_{j}$. 
    
    If constraint (3) is violated, then $\gamma_{j}$ is a transition with guard $\gguard[\texttt{x}]$ that outputs $\texttt{insample}$. Thus if $i<j$, there is a privacy violating path from $t_i$ to $t_j$ and if $j<i$, there is a privacy violating path from $t_j$ to $t_i$. 
    
    Otherwise if constraint (5) is violated, then $\gamma_{j}$ is in a \gcycle, so there is a leaking pair composed of the cycle containing $t_j$ and the cycle containing $t_i$ if $j<i$ or vice versa if $j>i$. 

    \textbf{Case 1.2: $t_i$ is not in a cycle}

    Note that $t_i$ must either be an assignment transition or output $\texttt{insample}$ or both, since otherwise, setting $\gamma_i = \gamma_{at(i)}$ would resolve constraint (1) for $\gamma_i$ without violating any other constraint. 

    \textbf{Case 1.2.1: $t_i$ outputs $\texttt{insample}$ and $t_i$ is an assignment transition}

    In this case, attempting to resolve constraint (1) without violating constraint (3) for $\gamma_i$ by setting $\gamma_i = \gamma_{at(i)} = 0$ must violate some other constraint. In particular, setting $\gamma_{at(i)} = 0$ can newly violate constraint (1) for $\gamma_{at(i)}$ or constraint (2) for some $\gamma_j$ such that $at(j) = at(i)$; note that setting $\gamma_{at(i)}=0$ cannot \textit{newly} violate constraint (1) for some $\gamma_j$ such that $at(j) = at(i)$. 
    Alternatively, setting $\gamma_i = 0$ could potentially newly violate either constraint (1) or constraint (2) for some $\gamma_j$ such that $at(j) = i$. 

    \textbf{Case 1.2.2.1: Setting $\gamma_{at(i)} =0$ violates constraint (1) for $\gamma_{at(i)}$}

    Let $t_{at(k)}$ be the earliest assignment transition before $t_{at(i)}$ such that, for all $at(k)\leq at(l)< at(i)$, $\gamma_{at(l)} = -1$ and $c_{at(l)} = \lguard[\texttt{x}]$. Then there must be \textit{some} $\gamma_{at(l)}$ such that setting $\gamma_{at(l)} = 0$ would violate constraint (2) for some $\gamma_{l'}$ such that $at(l') = at(l)$.  
    Additionally, note that setting $\gamma_{l'} = \gamma_{at(l)} = 0$ can only violate constraint (5) for $\gamma_{l'}$, since $\gamma_{l'}$ cannot be an assignment transition. 
    
    Thus, $t_{l'}$ is in a cycle, so the cycle containing $t_{l'}$ is a \gcycle. Note that the path from $t_{l'}$ to $t_i$ is an $\texttt{AL}$-path. Therefore, there is a privacy violating path from $t_{l'}$ to $t_i$.

    \textbf{Case 1.2.2.2: Setting $\gamma_{at(i)} =0$ violates constraint (2) for some $\gamma_j$ such that $at(j) = at(i)$}

    Note that $j\neq i$, meaning that $t_j$ is not an assignment transition. Then setting $\gamma_j = \gamma_{at(i)} = 0$ must violate constraint (5) for $\gamma_j$; this means that $t_j$ is in a \gcycle. 

    If $i<j$, then the path from $t_i$ to $t_j$ is an $\texttt{AL}$-path, so it is also a privacy violating path.

    Otherwise illustratef $j<i$, then the path from $t_j$ to $t_i$ is an $\texttt{AG}$ path, so it is also a privacy violating path.

    \textbf{Case 1.2.2.3: Setting $\gamma_i =0$ violates constraint (1) for some $\gamma_j$ such that $at(j) = i$}

    If $\gamma_j$ is not an assignment transition, then setting $\gamma_j = \gamma_i = 0$ must violate constraint (5) for $\gamma_j$, so $t_j$ is in an \lcycle. Then there is a privacy violating path from $t_i$ to $t_j$, since the path from $t_{i+1}$ to $t_j$ is an $\texttt{AL}$-path by virtue of not containing any assignment transitions. 

    Otherwise if $t_j$ is an assignment transition, then $\gamma_j$ must originally be set to 1. Let $t_{at(k)}$ be the latest assignment after $t_{i}$ such that, for all $i\leq at(l)< at(k)$, $\gamma_{at(l)} = 1$ and $c_{at(l)} = \lguard[\texttt{x}]$. Then there must be \textit{some} $\gamma_{at(l)}$ such that setting $\gamma_{at(l)} = 0$ would violate constraint (1) for some $\gamma_{l'}$ such that $at(l') = at(l)$.  
    Additionally, note that setting $\gamma_{l'} = \gamma_{at(l)} = 0$ can only violate constraint (5) for $\gamma_{l'}$, since $\gamma_{l'}$ cannot be an assignment transition. 

    Then $\gamma_{l'}$ must be in an \lcycle. Since the path from $t_i$ to $t_{l'}$ is an $\texttt{AL}$-path, there is a privacy violating path from $t_i$ to $t_{l'}$.

    \textbf{Case 1.2.2.4: Setting $\gamma_i =0$ violates constraint (2) for some $\gamma_j$ such that $at(j) = i$}

    This case is exactly symmetric to case 1.2.2.3.

    \textbf{Case 1.2.2: $t_i$ outputs $\texttt{insample}$ and $t_i$ is not an assignment transition}

    We can assume that $\gamma_{at(i)} = -1$ originally, since otherwise, setting $\gamma_i = 0$ would resolve constraint (1) without violating any additional ones.

    Thus attempting to resolve constraint (1) while preserving constraint (3) for $\gamma_i$ by setting $\gamma_{at(i)}=\gamma_i =0$ must violate constraint (1) for $\gamma_{at(i)}$. 
   
    Let $t_{at(k)}$ be the earliest assignment transition before $t_{at(i)}$ such that, for all $at(k)\leq at(l)< at(i)$, $\gamma_{at(l)} = -1$ and $c_{at(l)} = \lguard[\texttt{x}]$. Then there must be some $\gamma_{at(l)}$ such that setting $\gamma_{at(l)} = 0$ would violate constraint (2) for some $\gamma_{l'}$ such that $at(l') = at(l)$.  
    Additionally, note that setting $\gamma_{l'} = \gamma_{at(l)} = 0$ can only violate constraint (5) for $\gamma_{l'}$, since $\gamma_{l'}$ cannot be an assignment transition. 
    
    Thus, $t_{l'}$ is in a cycle, so the cycle containing $t_{l'}$ is a \gcycle. Note that the path from $t_{l'}$ to $t_i$ is an $\texttt{AL}$-path. Therefore, there is a privacy violating path from $t_{l'}$ to $t_i$.

    \textbf{Case 1.2.3: $t_i$ does not output $\texttt{insample}$ and $t_i$ is an assignment transition}

    In this case, attempting to resolve (1) by setting $\gamma_{at(i)} = 1$ must violate either constraint (1) or (3) for $\gamma_{at(i)}$, or constraint (2) for some $\gamma_j$ such that $at(j) = at(i)$. 

    Additionally, note that $\gamma_{at(i)} \in \{0, -1\}$. 

    \textbf{Case 1.2.3.1: $\gamma_{at(i)} =0$}

    Since originally, $\gamma_i > \gamma_{at(i)} \implies \gamma_i = 1$, we know that setting $\gamma_i = \gamma_{at(i)} = 0$ must violate constraint (1) for some $\gamma_j$ such that $at(j) = i$. If $t_{j}$ is not an assignment transition, then setting $\gamma_{j} = 0$ can only violate constraint (5) for $\gamma_{j}$, meaning that $t_j$ is in an \lcycle.

    Otherwise, if $t_j$ is an assignment transition, let $t_{at(k)}$ be the latest assignment transition after $t_{i}$ such that for all $j\leq at(l)< at(k)$, $\gamma_{at(l)} =1$ and $c_{at(k)} = \lguard[\texttt{x}]$. Then there must exist some $at(l), j\leq at(l)< at(k)$ such that setting $\gamma_{at(l)}=0$ would violate constraint (1) for some non-assignment $\gamma_{l'}$ where $at(l') = at(l)$. 

    Further, setting $\gamma_{l'} = 0$ must then violate constraint (5) for $\gamma_{l'}$, so $t_{l'}$ is in an \lcycle. 

    Therefore, there exists a $\texttt{AL}$-path from $t_i$ to some transition $t$ in an \lcycle. 

    \textbf{Case 1.2.3.1.1: Setting $\gamma_{at(i)} = 1$ would violate constraint (1) for $\gamma_{at(i)}$}

    Let $t_{at(j)}$ be the earliest assignment transition before $t_{at(i)}$ such that for all $at(j)\leq at(k)< at(i)$, $\gamma_{at(k)} =0$ and $c_{at(k)} = \lguard[\texttt{x}]$. Then there must exist some $at(k), at(j)\leq at(k)< at(i)$ such that setting $\gamma_{at(k)}=1$ would violate constraint (2) for some non-assignment $\gamma_l$ where $at(l) = at(k)$, so $c_l = \gguard[\texttt{x}]$

    Note that there is an $\texttt{AL}$-path from $t_l$ to $t_i$, and therefore an $\texttt{AL}$-path from $t_l$ to some transition $t_{o}$ in an \lcycle. 

    Further, setting $\gamma_l = \gamma_{at(k)} = 1$ must then violate either constraint (3) or (5) for $\gamma_l$. 

    If constraint (3) is violated, then $t_l$ outputs $\texttt{insample}$, so there is a privacy violating from $t_l$ to $t_o$.

    If constraint (5) is violated, then $t_l$ is in a \gcycle, so there is a leaking pair consisting of the cycle containing $t_l$ and the cycle containing $t_o$. 

    \textbf{Case 1.2.3.1.2: Setting $\gamma_{at(i)}=1$ would violate constraint (3) for $\gamma_{at(i)}$}

    Note that there is an $\texttt{AL}$ path from $t_{at(i)}$ to some transition $t_j$ such that $t_j$ is in an \lcycle.

    Then $t_{at(i)}$ is an assignment transition that outputs $\texttt{insample}$, so there is a privacy violating path from $t_{at(i)}$ to $t_j$. 
    
    \textbf{Case 1.2.3.1.3: Setting $\gamma_{at(i)}=1$ would violate constraint (2) for some $\gamma_j$ such that $at(j) = at(i)$}

    As before, note that there is an $\texttt{AL}$ path from $t_{j}$ to some transition $t_k$ such that $t_k$ is in an \lcycle.

    Then trying to set $\gamma_j = \gamma_{at(i)} = 1$ must violate either constraint (3) or constraint (5) for $\gamma_j$. If constraint (3) is violated, then $t_j$ outputs $\texttt{insample}$, so there is a privacy violating from $t_j$ to $t_k$. If constraint (5) is violated, then $t_j$ is in a \gcycle, so there is a leaking pair consisting of the cycle containing $t_j$ and the cycle containing $t_k$.  

    \textbf{Case 1.2.3.2: $\gamma_{at(i)} = -1$}

    Note that $\gamma_i \in \{0, 1\}$.

    First, if $\gamma_i = 0$, then setting $\gamma_i = -1$ must newly violate constraint (1) for some $\gamma_j$ where $at(j) = i$. If $t_{j}$ is not an assignment transition, then setting $\gamma_{j} = -1$ can only newly violate constraint (3) for $\gamma_{j}$, meaning that $t_j$ outputs $\texttt{insample}$.

    Otherwise, if $t_j$ is an assignment transition, let $t_{at(k)}$ be the latest assignment transition after $t_{i}$ such that for all $j\leq at(l)< at(k)$, $\gamma_{at(l)} =0$ and $c_{at(k)} = \lguard[\texttt{x}]$. Then there must exist some $at(l), j\leq at(l)< at(k)$ such that setting $\gamma_{at(l)}=-1$ would newly violate constraint (1) for some non-assignment $\gamma_{l'}$ where $at(l') = at(l)$; as before, this means that $t_{l'}$ outputs $\texttt{insample}$.  

    Otherwise, if $\gamma_i = 1$, then setting $\gamma_i = -1$ must newly violate constraint (1) for some $\gamma_j$ where $at(j) = i$. If $t_{j}$ is not an assignment transition, then setting $\gamma_{j} = -1$ can only newly violate constraint (5) for $\gamma_{j}$, meaning that $t_j$ is in an \lcycle. 

    Otherwise, if $t_j$ is an assignment transition, let $t_{at(k)}$ be the latest assignment transition after $t_{i}$ such that for all $j\leq at(l)< at(k)$, $\gamma_{at(l)} =0$ and $c_{at(k)} = \lguard[\texttt{x}]$. Then there must exist some $at(l), j\leq at(l)< at(k)$ such that setting $\gamma_{at(l)}=-1$ would newly violate constraint (1) for some non-assignment $\gamma_{l'}$ where $at(l') = at(l)$; as before, this means that $t_{l'}$ is in an \lcycle.  

    Thus, if $\gamma_i =0$, then there is $\texttt{AL}$-path from $t_i$ to some other transition that has guard $\lguard[\texttt{x}]$ and outputs $\texttt{insample}$. Otherwise, if $\gamma_i = 1$, there is an $\texttt{AL}$-path from $t_i$ to some other transition that is in an \lcycle. 

    \textbf{Case 1.2.3.2.1: Setting $\gamma_{at(i)} = \gamma_i$ would violate constraint (1) for $\gamma_{at(i)}$}

    Let $t_{at(j)}$ be the earliest assignment transition before $t_{at(i)}$ such that for all $at(j)\leq at(k)< at(i)$, $\gamma_{at(k)} =-1$ and $c_{at(k)} = \lguard[\texttt{x}]$. Then there must exist some $at(k), at(j)\leq at(k)< at(i)$ such that setting $\gamma_{at(k)}=\gamma_i$ would newly violate constraint (2) for some non-assignment $\gamma_l$ where $at(l) = at(k)$.

    First note that $c_l = \gguard[\texttt{x}]$ and there is an $\texttt{AL}$-path from $t_l$ to $t_i$. 
    
    If $\gamma_i = 0$, then setting $\gamma_l = \gamma_{at(k)} = \gamma_i = 0$ can only newly violate constraint (5) for $\gamma_l$. Thus, $\gamma_l$ is in a \gcycle. Since $\gamma_i = 0$, there exists some $t_{l'}$ such that there is an $\texttt{AL}$-path from $t_i$ to $t_{l'}$ and $t_{l'}$ has guard $\lguard[\texttt{x}]$ and outputs $\texttt{insample}$. Thus, there is an $\texttt{AL}$ path from $t_l$ to $t_{l'}$, and so there is a privacy violating path from $t_l$ to $t_{l'}$. 
    
    If $\gamma_i = 1$, then setting $\gamma_l = \gamma_{at(k)} = \gamma_i = 1$ can newly violate constraints (3) or (5) for $\gamma_l$. Further, since $\gamma_i =1$, there exists some $t_{l'}$ such that there is an $\texttt{AL}$-path from $t_i$ to $t_{l'}$ and $t_{l'}$ is in an \lcycle. Thus, there is an $\texttt{AL}$ path from $t_l$ to $t_{l'}$.
    
    If constraint (3) is newly violated, then $t_l$ is a transition with guard $\gguard[\texttt{x}]$ that outputs $\texttt{insample}$. Thus, there is a privacy violating path from $t_l$ to $t_{l'}$. 

    If constraint (5) is newly violated, then $t_l$ is in a \gcycle. Thus, there is a leaking pair composed of the cycles containing $t_l$ and $t_{l'}$, respectively.

    \textbf{Case 1.2.3.2.2: Setting $\gamma_{at(i)}=\gamma_i$ would violate constraint (3) for $\gamma_{at(i)}$}

    First, $t_{at(i)}$ is an assignment transition that outputs $\texttt{insample}$. Since $\gamma_i = 1$, there exists some $t_j$ such that there is an $\texttt{AL}$-path from $t_{at(i)}$ to $t_j$ and $t_j$ is in an \lcycle. Then there is a privacy violating path from $t_{at(i)}$ to $t_j$.

    \textbf{Case 1.2.3.2.3: Setting $\gamma_{at(i)}=\gamma_i$ would violate constraint (2) for some $\gamma_j$ such that $at(j) = at(i)$}

    Observe that $t_j$ is not an assignment transition and has guard $\gguard[\texttt{x}]$. Additionally, there is an $\texttt{AL}$-path from $t_j$ to $t_i$ since there are no assignments between $t_j$ and $t_i$. 

    If $\gamma_i =0$, then setting $\gamma_j = \gamma_{at(i)} = 0$ can only newly violate constraint (5) for $\gamma_j$. Thus, $\gamma_j$ is in a \gcycle. Since $\gamma_i = 0$, there exists some $t_{k}$ such that there is an $\texttt{AL}$-path from $t_i$ to $t_{k}$. Thus, there is an $\texttt{AL}$ path from $t_j$ to $t_{k}$, and so there is a leaking pair composed of the cycles containing $t_j$ and $t_{k}$, respectively. 

    If $\gamma_i = 1$, then setting $\gamma_j = \gamma_{at(i)}=1$ can newly violate constraints (3) or (5) for $\gamma_l$. Further, since $\gamma_i =1$, there exists some $t_{k}$ such that there is an $\texttt{AL}$-path from $t_i$ to $t_{k}$ and $t_{k}$ is in an \lcycle. Thus, there is an $\texttt{AL}$ path from $t_j$ to $t_{k}$.
    
    If constraint (3) is newly violated, then $t_j$ is a transition with guard $\gguard[\texttt{x}]$ that outputs $\texttt{insample}$. Thus, there is a privacy violating path from $t_j$ to $t_{k}$. 

    If constraint (5) is newly violated, then $t_j$ is in a \gcycle. Thus, there is a leaking pair composed of the cycles containing $t_j$ and $t_{k}$, respectively.

    \textbf{Case 2: (2) is unsatisfied for $\gamma_i$}

    This case is exactly symmetric to case (1).

    \textbf{Case 3: (3) is unsatisfied for $\gamma_i$}

    First note that if $t_i$ is in a cycle, then that cycle will be a disclosing cycle because $t_i$ outputs $\texttt{insample}$. Thus, we will assume that $t_i$ is not in a cycle.

    Because $C$ is maximal, setting $\gamma_i=0$ must violate at least one of constraints (1) or (2) for $\gamma_i$ or (1) for some $\gamma_l$ such that $at(l) = i$.

    \textbf{Case 3.1: Satisfying (3) for $\gamma_i$ would violate (1) for $\gamma_i$}

    This means that $\gamma_{at(i)}<0\implies \gamma_{at(i)} = -1$. Further, $c_i = \lguard[\texttt{x}]$. Then changing $\gamma_{at(i)}=0$ can newly violate constraints (1) or (5) for $\gamma_{at(i)}$ or constraint (2) for some $\gamma_j$ such that $at(j) = at(i)$.

    If constraint (5) is newly violated, then $t_{at(i)}$ is in a cycle. In particular, the cycle must be a leaking cycle; if $t_i$ and $t_{at(i)}$ are both contained in a cycle, then it must be leaking because $c_i = \lguard[\texttt{x}]$. Otherwise, there still must be some transition in the cycle containing $t_{at(i)}$ that has a non-$\texttt{true}$ guard since otherwise a path from $t_{at(i)}$ to $t_i$ could not exist. 

    By similar reasoning, we can assume that for every assignment transition $t_{at(j)}$before $t_{at(i)}$ on a complete path to $t_i$, $t_{at(j)}$ is not in a cycle. 

    If constraint (1) is newly violated for $\gamma_{at(i)}$, then $c_{at(i)} = \lguard[\texttt{x}]$. Let $t_{at(j)}$ be the earliest assignment transition before $t_{at(i)}$ such that $\gamma_{at(l)} = -1$ and for all assignment transitions $t_{at(k)}$ between $t_{at(j)}$ and $t_{at(i)}$, $c_{at(k)} = \lguard[\texttt{x}]$ and $\gamma_{at(k)} = -1$. 
    
    Then there must exist some assignment transition $t_{at(k)}$, $at(j)\leq at(k)\leq at(i)$ between $t_{at(j)}$ and $t_{at(i)}$ such that setting $\gamma_{at(k)} = 0$ would newly violate constraint (2) for some $l$ where $at(l) = at(k)$. In particular, this must be because $t_l$ is in a cycle and setting $\gamma_l = 0$ would violate constraint (5). Thus, $t_l$ is in a $\texttt{G}$-cycle. Then there is an $\texttt{AL}$-path from $t_l$ to $t_i$, creating a privacy violating path from $t_l$ to $t_i$. 

    If changing $\gamma_{at(i)}$ from $-1$ to $0$ means that constraint (2) would be newly violated for some $\gamma_j$ such that $at(j) = at(i)$, note that $\gamma_j < 0$ and $c_j = \gguard[\texttt{x}]$. 
    
    So setting $\gamma_j = 0$ can violate either (2) for some $\gamma_l$ where $at(l) = j$ or (5) for $\gamma_j$. 

    If setting $\gamma_j = 0$ would violate constraint (2) for some $\gamma_l$ where $at(l) = j$, then let let $t_{at(m)}$ be the latest assignment transition after $t_{at(j)}$ such that $\gamma_{at(m)} = -1$ and for all assignment transitions $t_{at(k)}$ between $t_{at(j)}$ and $t_{at(m)}$, $c_{at(k)} = \gguard[\texttt{x}]$ and $\gamma_{at(k)} = -1$. 
    
    Then there must exist some assignment transition $t_{at(k)}$, $at(j)\leq at(k)\leq at(m)$ between $t_{at(j)}$ and $t_{at(m)}$ such that setting $\gamma_{at(k)} = 0$ would newly violate constraint (2) for some $l'$ where $at(l') = at(k)$. 
    In particular, this must be because $t_{l'}$ is in a cycle and setting $\gamma_l = 0$ would violate constraint (5). Thus, $t_l$ is in a $\texttt{G}$-cycle. Then there is an $\texttt{AG}$-path from $t_i$ to $t_l$, creating a privacy violating path from $t_i$ to $t_l$. 

    Otherwise, if setting $\gamma_j = 0$ would violate constraint (5) for $\gamma_j$, then $t_j$ is in a $\texttt{G}$-cycle. We can assume that $j\neq i$ because otherwise, the cycle containing $t_j$ would be a disclosing cycle. Additionally, note that there are no assignment transitions between $t_i$ and $t_j$ or vice versa, since $at(j) = at(i)$.
    Thus, if $j<i$, then there is an $\texttt{AL}$-path from $t_j$ to $t_i$, which forms a privacy violating path. Symmetrically, if $i<j$, then there is an $\texttt{AG}-$path from $t_i$ to $t_j$, which again forms a privacy violating path. 

    \textbf{Case 3.2: Satisfying (3) for $\gamma_i$ would violate (2) for $\gamma_i$}

    This case is exactly symmetric to case (3a).

    \textbf{Case 3.3: Satisfying (3) for $\gamma_i$ would violate (1) for some $\gamma_l$ where $at(l) = i$}

    Note that $t_i$ must be an assignment transition. Further, we know that $\gamma_l>0$ and $c_l = \lguard[\texttt{x}]$. 
    
    Because $C$ is maximal, setting $\gamma_l=0$ would now violate either constraint (1) for some $\gamma_{l'}$ where $at(l') = l$ or constraint (5) for $\gamma_l$. Note that because $\gamma_l>0$, constraint (2) cannot be newly violated for some $\gamma_{l'}$ where $at(l') = l$.

    If constraint (5) would be newly violated for $\gamma_l$, then $\gamma_l$ is in an $\texttt{L}$-cycle. Additionally, note that the path from $t_{i+1}$ to $t_l$ is an $\texttt{AL}$-path, so there is a privacy violating path from $t_i$ to $t_l$. 

    Otherwise, if setting $\gamma_l = 0$ would violate constraint (1) for some $\gamma_{l'}$ where $at(l')=l$, let $t_{at(j)}$ be the latest assignment transition such that $c_{at(j)} = \lguard[\texttt{x}]$ and $\gamma_{at(j)}<1$ and, for all assignment transitions $t_{at(k)}$ between $t_l$ and $t_{at(j)}$, $c_{at(k)} = \lguard[\texttt{x}]$ and $\gamma_{at(k)}<1$. 

    If $at(j) = l$, then $l'$ is not an assignment transition. Then, setting $\gamma_{l'} = 0$ could only violate constraint (5). In this case, as before, there is a privacy violating path from $t_i$ to $t_l$. 

    Otherwise, since $C$ is maximal, we cannot set $\gamma_{at(k)}=0$ for any $l<at(k)\leq at(j)$ without violating another constraint. In particular, there must be some $at(k)$ such that setting $\gamma_{at(k)} = 0$ would violate constraint (1) for some $\gamma_{k'}$ such that $at(k') = at(k)$. Note that there must be an \texttt{AL}-path from $t_i$ to $t_{k'}$. Then, as before, there must be a privacy violating path from $t_i$ to $t_{k'}$. 


    \textbf{Case 3.4: Satisfying (3) for $\gamma_i$ would violate (2) for some $\gamma_l$ where $at(l) = i$} 

    This case is exactly symmetric to case (3c).

    \textbf{Case 4: (4) is unsatisfied for $\gamma_i'$}
    
    Because $C$ is maximal, setting $\gamma_i'=0$ must violate some other constraint. In particular, this must mean that constraint (6) is now violated. However, this would imply that $t_i$ is in a cycle, and so the cycle containing $t_i$ would be a disclosing cycle.

    \textbf{Case 5: (5) is unsatisfied for $t_i$:} Because $C$ is maximal, we know that if $\gamma_i = -\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}$ then another constraint must be violated. In particular, at least one of constraints (1), (2), or (3) must be violated for $\gamma_i$. 
    
    \textbf{Case 5.1: Satisfying (5) for $t_i$ would violate (1)}

    If (1) is now violated, then either $t_i$ is an assignment transition or $c_i = \lguard[\texttt{x}]$ and $\gamma_{at(i)}<1$. If $t_i$ is an assignment transition, then the cycle containing $t_i$ has a transition with a non-$\texttt{true}$ guard ($t_i$) and an assignment transition, so it must be a leaking cycle. 

    Otherwise, if $t_i$ is not an assignment transition, $c_i = \lguard[\texttt{x}]$, and constraint (1) is violated for $\gamma_i$, we must have that $\gamma_{at(i)}<1$ due to other constraints.
    
    Consider all assignment transitions in $\rho$ before $t_i$. Note that if any such assignment transition is in a cycle, then that cycle must be a leaking cycle since either the assignment transition is in the same cycle as $t_i$ or there must be some non-$\texttt{true}$ transition in the cycle because otherwise $t_i$ is unreachable. {\color{red} make sure to add a condition to programs so that this is bad}

    So assume that all assignment transitions in $\rho$ before $t_i$ are not in a cycle. Then if $c_{at(i)} \neq \lguard[\texttt{x}]$, because $C$ is maximal, this must mean that $t_{at(i)}$ outputs $\texttt{insample}$. Note that the path from $t_{at(i)+1}$ to $t_i$ is an $\texttt{AL}$-path (since there are no assignment transitions on it) and $t_i$ is in an $\texttt{L}$-cycle since $t_i$ is in a cycle and $c_i = \lguard[\texttt{x}]$. 
    Then the path from $t_{at(i)}$ (an assignment transition that outputs $\texttt{insample}$) to $t_i$ is a privacy violating path. 

    If $c_{at(i)} = \lguard[\texttt{x}]$, then let $c_{at(j)}$ be the earliest assignment transition such that $c_{at(j)} = \lguard[\texttt{x}]$ and $\gamma_{at(j)} < 1$ and, for all assignment transitions $t_{at(k)}$ between $t_{at(j)}$ and $t_i$, $c_{at(k)} = \lguard[\texttt{x}]$ and $\gamma_{at(k)} < 1$. Note that such an $t_{at(j)}$ must exist. 

    If $t_{at(j)} = t_{at(i)}$, then setting $\gamma_{at(i)} =1$ must violate either constraint (2) for some other $\gamma_l$ such that $at(l)=at(i)$, or constraint (3) for $\gamma_{at(i)}$. Without loss of generality, we will assume that $l\neq i$. If constraint (3) would be violated, then as before, there exists a privacy violating path from $t_{at(j)}$ to $t_i$. 
    If constraint (2) would be violated for some $\gamma_l$ such that $at(l)=at(i)$, then either $t_l$ must output $\texttt{insample}$ or $t_l$ must be in a cycle. 
    
    Suppose that $i<l$; then that the path from $t_i$ to $t_l$ is both an $\texttt{AG}$-path and an $\texttt{AL}$-path (since there are no assignment transitions on it). Thus, if $t_l$ outputs $\texttt{insample}$, there exists a privacy violating path from $t_i$ to $t_l$ and if $t_l$ is in a cycle, then the cycle containing $t_i$ and the cycle containing $t_l$ together make up a leaking pair, since the cycle containing $t_l$ is a $\texttt{G}$-cycle by definition. 
    Symmetrically, if $l>i$, then either the path from $t_l$ to $t_i$ is a privacy violating path or the cycle containing $t_l$ and the cycle containing $t_i$ make up a leaking pair.
    
    Otherwise, note that the path from $t_{at(j)}$ to $t_i$ is an $\texttt{AL}-$path. Since $C$ is maximal, we cannot set $\gamma_{at(k)}=1$ for $\gamma_{at(j)}$ or for any of the other assignment transitions $t_{at(k)}$ between $t_{at(j)}$ and $t_i$ without violating another constraint. 
    In particular, there must be some $t_{at(k)}$ where $at(j)\leq at(k)<i$ such that setting $\gamma_{at(k)} = 1$ would mean that either constraint (2) for some $\gamma_l$ such that $at(l) = at(k)$ or constraint (3) would be violated for $\gamma_{at(k)}$. 
    If constraint (3) would be violated for $\gamma_{at(k)}$ then $t_{at(k)}$ outputs $\texttt{insample}$, so as before, there is a privacy violating path from $t_{at(k)}$ to $t_i$. Otherwise if constraint (2) would be violated for some $\gamma_l$ such that $at(l) = at(k)$, then as before, $\gamma_l$ must either output $\texttt{insample}$ or $t_l$ is in a cycle. 
    Just like before, this means that there must be either a privacy violating path from $t_l$ to $t_i$ or the cycle containing $t_l$ and the cycle containing $t_i$ together make up a leaking pair. 

    \textbf{Case 5.2: Satisfying (5) for $t_i$ would violate (2)}

    This case is exactly symmetric to case (5a).

    \textbf{Case 5.3: Satisfying (5) for $t_i$ would violate (3)}

    If (3) would be violated, then $t_i$ must output $\texttt{insample}$. Then the cycle containing $t_i$ must be a disclosing cycle. 
    
    \textbf{Case 6: (6) is unsatisfied for $t_i$:} Because $C$ is maximal, we know that if $\gamma_i' = -\texttt{in}_i\brangle{1}+\texttt{in}_i\brangle{2}$ then another constraint must be violated for $\gamma_i'$. In particular, constraint (4) must be violated, since no other constraint involves $\gamma_i'$. 
    Then $t_i$ is a transition in a cycle that outputs $\texttt{insample}'$, so $A$ has a disclosing cycle.
\end{proof}


\begin{thm}
    A DiPA $A$ is $d\varepsilon$-differentially private for some $d>0$ if and only if there exists some valid coupling strategy $S$ for $A$ with $cost(S)<\infty$. 
\end{thm}

\subsection{An algorithm for deciding privacy}

Observe that the constraints imposed on valid coupling strategies for a complete path $\rho$ only depend on the shifts associated with \textit{assignment transitions} in $\rho$. 

In particular, this lends itself to conceptualizing complete paths by splitting them up based on assignment transitions. 

\begin{defn}
    A \textbf{segment} of a (complete) path $\rho = q_0\to\ldots\to q_n$ is a subpath $q_i \to q_{i+1}\to \ldots \to q_j$ of $\rho$ such that $t_i \in A_\rho$; for all $i<k<j$, $t_k \notin A_\rho$; and either $j=n$ or $t_j \in A_\rho$.
\end{defn}

In other words, a segment is a subpath of $\rho$ between two consecutive assignment transitions (or between the last assignment transition and the end of the path). Splitting up a path into segments thus allows us to think about a single value of $\texttt{x}$ at a time.

\begin{prop}
    [Vishnu's segment graph overview here]
\end{prop}

\subsection{Minimizing a privacy budget}

If we have a differentially private program, we'd also like to optimize its privacy cost. We can do so via couplings: 

\begin{prop}
    Introduce linear program here - maybe this is a definition?
\end{prop}

\begin{prop}
    Introduce approximate version here
\end{prop}

\begin{prop}
    Optimal linear program always has cost at worst approx version; there is indeed a separation between the optimal + approx
\end{prop}

\begin{prop}
    Approximate version is an approximation of the optimal by a factor linear in the number of segments. 
\end{prop}

\begin{prop}
    Approximate version can be solved in polytime
\end{prop}

\begin{conj}[IF I HAVE TIME LOOK INTO THIS]
    Optimal coupling cost $\leq$ cost given by original DiPA analysis. [Vishnu says he almost certainly has a proof of this]
\end{conj}

\begin{conj}
    Optimal coupling cost = ``true'' optimal privacy cost
\end{conj}


\section{Extensions}

- brief word about counter, maybe the simplified multivariable case

\subsection{Two-Threshold Programs}

\noindent\hrulefill

\section{DiPA}

We now introduce the final extension to our program model. 

\begin{defn}[\cite{chadhaLinearTimeDecidability2021}]
    A DiP\footnote{\textbf{Di}fferentially \textbf{P}rivate} Automaton (DiPA) $A$ is a 7-tuple $(Q, \Sigma, C, \Gamma, q_{init}, X, P, \delta)$ where
    \begin{itemize}
        \item $Q$ is a finite set of states partitioned into input states $Q_{in}$ and non-input states $Q_{non}$. 
        \item $\Sigma = \RR$ is the input alphabet
        \item $C = \{\texttt{true}, \lguard, \gguard\}$ is a set of guard conditions
        \item $\Gamma$ is a finite output alphabet
        \item $q_{init}\in Q$ is the initial state
        \item $X = \{\texttt{x}, \texttt{insample}, \texttt{insample}'\}$ is the set of variables
        \item $P: Q\to \QQ\times \QQ^{\geq 0}\times \QQ\times  \QQ^{\geq 0}$ is a parameter function that assigns sampling parameters for the Laplace distribution for each state
        \item $\delta:(Q\times C)\to (Q\times (\Gamma \cup \{\texttt{insample}, \texttt{insample}'\})\times \{\texttt{true}, \texttt{false}\})$ is a partial transition function. 
    \end{itemize}
    In addition, $\delta$ must satisfy some additional conditions:
    
    \begin{itemize}
        \item \textbf{Determinism:} For any state $q\in Q$, if $\delta(q,\texttt{true})$ is defined, then $\delta(q,\lguard)$ and $\delta(q,\gguard)$ are not defined. 

        \item \textbf{Output Distinction:} For any state $q\in Q$, if $\delta(q, \gguard) = (q_1, o_1, b_1)$ and $\delta(q, \lguard) = (q_2, o_2, b_2)$, then $o_1\neq o_2$ and at least one of $o_1\in \Gamma$ and $o_2\in \Gamma$ is true.

        \item \textbf{Initialization:} The initial state $q_0$ has only one outgoing transition of the form $\delta(q_0, \texttt{true}) = (q, o, \texttt{true})$.

        \item \textbf{Non-input transition:} From any $q\in Q_{non}$, if $\delta(q, c)$ is defined, then $c=\texttt{true}$.
    \end{itemize}

    A DiPA $A$ functions almost identically to the previous automata we have defined, except that instead of only the first transition of $A$ assigning into $\texttt{x}$, now any \textbf{assignment transition} can re-assign the value of $\texttt{x}$ to be $\texttt{insample}$. In addition, DiPAs are no longer dependent on an initial value for $\texttt{x}$, since the first transition must always be a $\texttt{true}$ guard assignment transition.
\end{defn}

Note that we can treat a DiPA $A$ as a (possibly infinite, if an assignment transition is in a cycle) set of segment automata by ``splitting'' at every assignment transition in $A$. 


\begin{defn}
    For a path $\rho$ in a DiPA $A$, let $segments(\rho)$ be the set of subpaths of $\rho$ created by splitting $\rho=r_0\to\ldots\to r_n$ at each assignment transition. 
    
    More precisely, let $I$ be the ordered set of indices such that $\trans(r_{I_i})$ for $i\in [|I|]$ is an assignment transition. Then $segments(\rho) = \{r_0\to\ldots\to r_{I_0}, \ldots, r_0\to\ldots\to r_{I_k}\}$.
\end{defn}

\begin{defn}
    Let $A$ be a DiPA and let $P$ be the set of all paths through $A$. 
    
    Then $branches(A) = \bigcup_{\rho\in P}\bigcup_{\eta\in segments(\rho)} acyclic(\eta)$ be the set of branches in $A$.
\end{defn}

Note that every path in $A$ can be broken up into a sequence of branches, each from its own segment. 

\subsection{Joining Coupling Strategies}

Naively, the fact that we can separate a DiPA $A$ into a set of segment automata would suggest an approach of assigning a coupling strategy to each branch of $A$ as before and simply combining these coupling strategies in sequence. However, it is not always possible to arbitrarily join coupling strategies together. 

This is primarily because we can no longer freely decide the initial value for $\texttt{x}$ at the beginning of each segment, as we could with segment automata. Recall that for a fixed path $\rho = r_0\to\ldots\to r_n$, it was important that the initial transition guard $\guard(r_0)$ is satisfied. 
Notably, whether or not the initial guard is satisfied is dependent on the initialized value of $\texttt{x}$; since we had no additional restrictions on $\texttt{x}$, we were able to (for example) arbitrarily couple $x_0\brangle{1}+1(=)^{\#d_x\varepsilon}x_0\brangle{2}$.

However, now that we have joined multiple segment automata together, the initial value $x_0$ for a segment automata is actually the assigned value $\texttt{x}$ from the \textit{previous} segment automata. 
This means that $x_0\brangle{1}$ and $x_0\brangle{2}$ will already be coupled together, perhaps in a way such that coupling $\texttt{insample}_0\brangle{1}$ and $\texttt{insample}_0\brangle{2}$ will be impossible to both ensure the correct shift of $\texttt{x}$ for the new coupling strategy and so that the initial guard is satisfied.

For example, consider two paths $\rho = r_0\to\ldots\to r_n$ and $\rho' = q_1\to \ldots \to q_m$ with the assignment transition $r_n\to q_1$ connecting them, where $\guard(r_n) = \gguard$. We are aiming to choose one coupling strategy for each of $\rho$ and $\rho'$. 

If $S^L$ is chosen for $\rho$, then at the connecting assignment transition, $x_0$ is coupled such that $x_0\brangle{1}+1 =x_1\brangle{1}$. Further, we would like to couple $\texttt{insample}_0$ such that $\texttt{insample}_0\brangle{1} = \texttt{insample}_0\brangle{2}+1$. However, trying to create this lifting while also ensuring that the implication $\texttt{insample}_0\brangle{1} \geq x_0\brangle{1}\implies \texttt{insample}_0\brangle{2} \geq x_0\brangle{2}$ holds is impossible. 

Thus, we cannot choose $S^G$ for a segment that follows a segment with coupling strategy $S^L$ if the connecting assignment transition has guard $\gguard$. There are a series of similar restrictions on how coupling strategies can be connected for adjacent segments, which along with previous restrictions on coupling strategies (e.g. we cannot choose $S^G$ or $S^L$ if the first transition of a segment outputs $\texttt{insample}$).

\subsection{A Constraint System for Valid Couplings}

Based on the restrictions on joining segments together, we can construct a set of constraints on coupling strategies for a DiPA $A$ that, if solved, will give us a valid proof of $d\varepsilon$-differential privacy.

\begin{const}\label{constraintsystem}
    Consider a DiPA~$A$.
    
    For each branch $s_i\in branches(A)$, we can assign one of three coupling strategies $S_i \in \{S^L, S^G, S^N\}$. We would like to find an assignment of coupling strategies for each segment of each variable, subject to the following constraints: 

    \begin{enumerate}
        \item Constraints for valid couplings\begin{enumerate}
            \item For all $s_i$, if $\trans(s_i)$ outputs $\texttt{insample}$, then $S_i = S^N$.
            \item For all $s_i, s_j$ such that $s_i$ is directly followed by $s_j$, \begin{enumerate}
                \item If $\guard(s_j)=\lguard$ and $S_i = S^G$, then $S_j = S^G$. 
                \item If $\guard(s_j) = \gguard$ and $S_i = S^L$, then $S_j = S^L$.
                \item If $\guard(s_j) = \lguard$ and $S_i = S^N$, then $S_j\neq S^L$.
                \item If $\guard(s_j) = \gguard$ and $S_i = S^N$, then $S_j\neq S^G$.
            \end{enumerate}
           
        \end{enumerate}
        \item Constraints for finite cost\begin{enumerate}
            \item For all $s_i$, no cycle in $s_i$ has a transition that outputs $\texttt{insample}$ or $\texttt{insample}'$. 
            \item For all $s_i$, if $s_i$ has an $\texttt{L}$-cycle, then $S_i = S^L$.
            \item For all $s_i$, if $s_i$ has a $\texttt{G}$-cycle, then $S_i = S^G$. 
            \item For all segments $s_i$, there is no transition $\trans(a_k)$ in $s_i$ that is \textit{faulty}, i.e.:\begin{enumerate}
                \item If $s_i$ contains a $\lguard$ transition that outputs $\texttt{insample}$, then $S_i \neq S^G$.
                \item If $s_i$ contains a $\gguard$ transition that outputs $\texttt{insample}$, then $S_i \neq S^L$.
            \end{enumerate}
        \end{enumerate}
    \end{enumerate}
\end{const}

\begin{thm}\label{constraintsatisfiableprivatethm}
    Let $A$ be a DiPA.\ If $|branches(A)|< \infty$ and for each branch $B\in branches(A)$, there exists an assignment of coupling strategies to each segment that satisfies the constraint system defined in \ref{constraintsystem}, then $A$ is $d\varepsilon$-differentially private for \[d=\sum_{s_i\in branches(A)}d_{s_i},\]
    where $d_{s_i}$ is the cost of the satisfying assignment strategy $S_i$ for a branch $s_i$.  
\end{thm}
\begin{proof}
    Let $\rho$ be a path through $A$ that is composed of branches $s_{x_1}\to \ldots\to s_{x_k}$ and let $S_{x_1}, \ldots, S_{x_k}$ be the associated coupling strategies from the satisfying assignment. 

    Because of constraints (1a-1b), we can actually compose each coupling strategy in sequence to create a valid lifting $A(X)\{(a, b): a=\sigma \implies b=\sigma\}A(X')$ for all adjacent datasets $X\sim X'$ and possible outputs $\sigma$ of $\rho$. 

    In addition, we claim that the cost of the satisfying assignments $d_{s_i}$ is bounded for all $s_i$. There are two ways for a branch cost $d_{s_i}$ to be unbounded: either a cycle transition has non-zero cost, or a transition has to be faulty with respect to the chosen coupling strategy. From constraint (2d), we know that no transitions can be faulty, and we know from constraints (2a-2c) that every cycle transition has to have zero cost. 

    Finally, the fact that $|branches(A)|<\infty$ and every path can go through each branch at most one time gives us the bound on $d$. 
\end{proof}


\subsection{Well-formedness}

Similar to before, \cite{chadhaLinearTimeDecidability2021} define four structures in the graphs of DiPAs that characterize privacy for DiPAs. Within DiPAs, these graph structures can be defined as follows:\begin{itemize}
    \item \textbf{Leaking Cycles}: A cycle $C$ is a leaking cycle if one of the transitions in $C$ is an assignment transition.
    \item \textbf{Leaking Pair}: A pair of cycles $C$, $C'$ are a leaking pair if $C$ is an \lcycle, $C'$ is a \gcycle, and there exists a path from $C$ to $C'$ such that every assignment transition on the path has guard $\gguard$; or, symmetrically, $C$ is an \gcycle, $C'$ is a \lcycle, and there exists a path from $C$ to $C'$ such that every assignment transition on the path has guard $\lguard$.
    \item \textbf{Disclosing Cycle}: A cycle $C$ is a disclosing cycle if a transition in $C$ outputs either $\texttt{insample}$ or $\texttt{insample}'$. 
    \item \textbf{Privacy Violating Path}: A path $\rho = q_0\to\ldots \to q_n$ is a privacy violating path if any of the following conditions hold:\begin{itemize}
        \item $q_1\to\ldots q_n$ is a path whose assignment transitions all have guard $\gguard$ (resp.\ $\lguard$) such that $q_n$ is part of a \gcycle\ (resp.\ \lcycle) and $\trans(q_0)$ is an assignment transition that outputs $\texttt{insample}$. 
        \item $\rho$ is a path whose assignment transitions all have guard $\gguard$ (resp.\ $\lguard$) such that $q_n$ is part of a \gcycle\ (resp.\ \lcycle), $\guard(q_0) = \lguard$ (resp.\ $\gguard$), and $\trans(q_0)$ outputs $\texttt{insample}$.
        \item $\rho$ is a path whose assignment transitions all have guard $\gguard$ (resp.\ $\lguard$) such that $q_0$ is part of a \lcycle\ (resp.\ \gcycle), $\guard(q_{n-1}) = \gguard$ (resp.\ $\lguard$), and $\trans(q_{n-1})$ outputs $\texttt{insample}$.
    \end{itemize}
\end{itemize}



\begin{defn}
    A DiPA $A$ is \textbf{well-formed} if it does not have a leaking cycle, leaking pair, disclosing cycle, or privacy violating path. 
\end{defn}

Importantly, \cite{chadhaLinearTimeDecidability2021} have shown that the existence of these graph structures completely decides whether or not a DiPA is $d\varepsilon$-differentially private. 
\begin{thm}[\cite{chadhaLinearTimeDecidability2021}]
    A DiPA $A$ is $d\varepsilon$-differentially private for some $d > 0$ if and only if $A$ is well-formed. Further, the well-formedness of an automaton $A$ can be decided in linear time in the size of $A$. 
\end{thm}

We will leverage this result to show that the existence of valid coupling strategies is also a complete characterization of DiPAs.

\begin{lemma}\label{leakingcyclesbrancheslemma}
    For a DiPA $A$, $|branches(A)|< \infty$ if and only if $A$ has no leaking cycles. 
\end{lemma}

\begin{lemma}\label{unsatisfiablenoprivacylemma}
    Suppose a DiPA $A$ has a finite number of branches. If constraint system \ref{constraintsystem} is not satisfiable, there must exist a leaking cycle, a leaking pair, a disclosing cycle, or a privacy violating path in the graph of $A$.
\end{lemma}
\begin{proof}
    TBD, want to briefly discuss the best way to do this. 

    high level overview: very similar to the previous, one-segment, version of this, but we can chain constraints across $\texttt{AG}-$ and $\texttt{AL}-$paths.

    The reasoning gets a bit convoluted though, because there are a bunch of cases / you have to keep a bunch of assumptions hanging around.
\end{proof}

\begin{thm}
    A DiPA $A$ is $d\varepsilon$-differentially private if and only if $A$ has a finite number of branches and there exists a valid assignment of coupling strategies over all branches of $A$. 
\end{thm}
\begin{proof}
    Follows from theorem \ref{constraintsatisfiableprivatethm} and lemmas \ref{leakingcyclesbrancheslemma} and \ref{unsatisfiablenoprivacylemma}.
\end{proof}

\section{Bounds on Privacy}

So far, we have focused on the binary question of whether a DiPA is private or not for \textit{any} finite $d>0$. An obvious question remaining thus is how tight of a privacy cost bound can we obtain using couplings?

Recall that $S^G, S^L$, and $S^N$ are primarily characterized by \textbf{shifts}; that is, offseting variables from each other.

Indeed, we can generalize our discrete set of coupling strategies to a continuous family of coupling strategies by treating the offsets of each variable as parameters. By rephrasing in this way, we can derive a linear system:

[insert vishnu's linear program here]

If solvable, this linear system will thus give the best possible privacy cost obtainable using this family of coupling strategies. 

\begin{prop}
    An optimal solution to the linear program provides the minimal cost coupling over all shift coupling strategies. If the linear program is infeasible, then the DiPA is not $d\varepsilon$-differentially private for any $\varepsilon$. 
\end{prop}

\begin{thm}[optimistically]
    If a DiPA $A$ is $\varepsilon$-differentially private, then there exists some valid assignment of coupling strategies over all segments that has a total cost of $\varepsilon$ (i.e.\ coupling cost is tight). 
\end{thm}

\section{Multivariable DiPA}

In this section, we explore a natural extension of the DiPA model to demonstrate the utility of using couplings as proof infrastructure. Specifically, we introduce Generalized DiPAs (GDiPAs), which allow for an arbitrary finite set of variables and an expanded alphabet where multiple variables can be compared to the input simultaneously to determine transitions. 
This would, for example, allow for SVT-style algorithms that check for membership between or outside of two thresholds or indeed, membership within any finite union of intersections of halves\footnote{think there's a term for this I'm forgetting} of $\RR$. 

\subsection{GDiPA}

A GDiPA $A$ is a generalization of DiPA whose primary characteristics are that:
\begin{itemize}
	\item At every state, a (real-valued) input is read. Additionally, Laplace noise (with parameters set by the user) is added to the input. 
	\item The automaton has a stored finite set of (real-valued) variables $\mathcal{X}$. At each transition, the value of each variable can be updated with the noisy input value read in. 
	\item A transition can optionally assign the (noisy) input value read at the previous state into at most one program variable.
	\item The automaton will take transitions based on a boolean combination of comparisons between the noisy input and a subset of the stored variables. Importantly, noise is added independently to the input for each separate variable comparison. Alternatively, there can be exactly one guaranteed (\texttt{true}) transition out of a state. 
	\item At every transition, the automaton will output either \begin{enumerate}
		\item A symbol from a pre-defined finite alphabet ($\Gamma$)
		\item The noisy input value as compared to one of the input variables ($\texttt{insample}$)
		\item The input value with fresh Laplace noise ($\texttt{insample}'$)
	\end{enumerate}
	As with DiPAs, the output sequence of any GDiPA must uniquely determine a path through the automaton.
\end{itemize}

\subsection{Combining Separate Variable Couplings}
Consider a GDiPA $A$ with program variables $\mathcal{X}$. For each program variable $x\in \mathcal{X}$, we can define coupling strategies similar to with single variables. That is, for two runs of the automaton with adjacent inputs, we must ensure that if the first run takes a certain transition, the other run does as well. In particular, for real outputs, we must ensure that the outputs are equal. 

For each variable in $A$, we can consider a ``shadow'' automaton in a single variable that only has a single program variable. Such a shadow automaton would have the same underlying graph structure as $A$, but would only contain the transition guards and assignments that pertained to a single variable. 
For example, if we were considering such an automaton $A_x$ with respect to the variable $x$, a transition with guard ``$\lguard[x]$ and $\gguard[y]$'' would correspond to a transition with guard $\lguard[x]$ in $A_x$; a transition with guard ``$\gguard[y]$'' would correspond to a transition with guard $\texttt{true}$ in $A_x$.

Note that these automata are not, strictly speaking, DiPAs, since it is possible for a state to have multiple transitions with guard $\texttt{true}$ leaving it. 

Thus, each segment can be assigned a coupling strategy $S^N, S^L$, or $S^G$ as before based on these ``shadow'' automata, with similar constraints. 

\begin{const}\label{generalizedconstraintsystem}
    Consider a GDiPA $A$ with program variables $\mathcal{X}$. Let $\{s_i^{(x)}\}$ be the segments of $A$ for each variable $x\in \mathcal{X}$. 

    For each $x\in \mathcal{X}$ and segment $s_i^{(x)}$ for $x$, we can assign one of three coupling strategies $S_i^{(x)} \in \{S^L, S^G, S^N\}$. We would like to find an assignment of coupling strategies for each segment of each variable, subject to the following constraints: 

    \begin{enumerate}
        \item Constraints for valid couplings\begin{enumerate}
            \item For all $s_i^{(x)}$, if $\trans(s_i^{(x)})$ outputs $\texttt{insample}$, then $S_i^{(x)} = S^N$.
            \item For all $s_i^{(x)}, s_j^{(x)}$ such that $s_i^{(x)}$ is immediately followed by $s_j^{(x)}$, \begin{enumerate}
                \item If $\guard(s_j^{(x)})=\lguard$ and $S_i^{(x)} = S^G$, then $S_j^{(x)} = S^G$. 
                \item If $\guard(s_j^{(x)}) = \gguard$ and $S_i^{(x)} = S^L$, then $S_j^{(x)} = S^L$.
                \item If $\guard(s_j^{(x)}) = \lguard$ and $S_i^{(x)} = S^N$, then $S_j^{(x)}\neq S^L$.
                \item If $\guard(s_j^{(x)}) = \gguard$ and $S_i^{(x)} = S^N$, then $S_j^{(x)}\neq S^G$.
            \end{enumerate}
            \item For all segments $s_i^{(x)}$, there is no transition $\trans(a_k)$ in $s_i^{(x)}$ that is \textit{faulty}, i.e.:\begin{enumerate}
                \item If $s_i^{(x)}$ contains a $\lguard$ transition that outputs $\texttt{insample}$, then $S_i^{(x)} \neq S^G$.
                \item If $s_i^{(x)}$ contains a $\gguard$ transition that outputs $\texttt{insample}$, then $S_i^{(x)} \neq S^L$.
            \end{enumerate}
            \item If any transition in $s_i^{(x)}$ outputs $x$, then $S_i^{(x)} = S^N$. 
        \end{enumerate}
        \item Constraints for finite cost\begin{enumerate}
            \item For all $s_i^{(x)}$, no cycle in $s_i^{(x)}$ has a transition that outputs $\texttt{insample}$, $\texttt{insample}'$. 
            \item For all $s_i^{(x)}$, if $s_i^{(x)}$ has an $\texttt{L}$-cycle with respect to $x$, then $S_i^{(x)} = S^L$.
            \item For all $s_i^{(x)}$, if $s_i^{(x)}$ has a $\texttt{G}$-cycle with respect to $x$, then $S_i^{(x)} = S^G$. 
        \end{enumerate}
    \end{enumerate}

    This constraint system is \textbf{satisfiable} for a GDiPA $A$ if, for all variables $x\in \mathcal{X}$, there exists an assignment of all $S_i^{(x)}$ such that all constraints are satisfied. 
\end{const}

In particular, we can independently resolve constraints for each variable and combine them together.
\begin{thm}	
	For a GDiPA $\mathcal{A}$, for all variables $x$, if there exist a finite number of segments $s_i$, and for all segments $s_i$, the constraint system \ref{constraintsystem} is satisfied by an assignment $S_x$, then all $S_x$ assignments together induce a valid coupling proof that $\mathcal{A}$ is $\varepsilon$-DP. 
\end{thm}

\begin{proof}
	
	Fix some variable $x\in \mathcal{X}$. From before, we know that if \ref{generalizedconstraintsystem} is satisfied with respect to $x$, then the coupling 
	\[\mathcal{A}(X)(\mathcal{A}(X)\text{ takes transitions }T\text{ wrt }x\implies \mathcal{A}(X')\text{ takes transitions }T\text{ wrt }x)^{\#(\varepsilon_x, 0)}\mathcal{A}(X')\]
	is valid for some finite $\varepsilon_x$. 
		
	Because the noises on $\texttt{insample}$ are independent, and $((a \implies c) \land (b \implies d)) \implies ((a \land b) \implies (c \land d))$ and $((a \implies c) \lor (b \implies d)) \implies ((a \lor b) \implies (c \lor d))$,for every combined guard, we can construct the lifting 
	\[\mathcal{A}(X)(\mathcal{A}(X)\text{ takes transitions }T\implies \mathcal{A}(X')\text{ takes transitions }T)^{\#(\sum_{x\in\mathcal{X}}\varepsilon_x, 0)}\mathcal{A}(X')\]
	which gives us the lifting
	\[\mathcal{A}(X)(\mathcal{A}(X)=\sigma\implies \mathcal{A}(X')=\sigma)^{\#(\sum_{x\in\mathcal{X}}\varepsilon_x, 0)}\mathcal{A}(X')\]
\end{proof}

\begin{thm}[less optimistically]
    If, for each variable $x$, there exists a valid assignment of coupling strategies over all segments of a DiPA $A$ with respect to $x$, then $A$ is $d\varepsilon$-differentially private. 
\end{thm}

\begin{thm}[optimistically]
    A GDiPA $A$ is $d\varepsilon$-differentially private if and only if, for each variable $x$, there exists a valid assignment of coupling strategies over all segments of $A$ with respect to $x$. 
\end{thm}

\section{Conclusion}
We have shown how to use coupling techniques to prove privacy for a class of SVT-like programs first defined in \cite{chadhaLinearTimeDecidability2021} and discovered that couplings additionally characterize this class. We additionally showed that this can be done tractably, and that couplings can help provide lower bounds on privacy costs of these algorithms. 

Future work most naturally would focus on extensions of the program model. For the model, potential areas include removing the requirement for output to be deterministic of a path through the automaton, which would allow for algorithms such as Report Noisy Max to be captured by the model. Similarly, the alphabet of the automaton could be expanded to incorporate more than comparisons between two real numbers. 
Such extensions would naturally also require extensions of the class of couplings we define here, which are limited to ``shifts''. 

Additionally, we believe that couplings should completely characterize GDiPAs as well as DiPAs; proving this requires showing that a lack of well-formedness in any single variable generates a counterexample to privacy. 
In this vein, we would like to explore using couplings to \textit{disprove} privacy; the fact that shift couplings completely characterize DiPAs hints at the possibility of ``anti-couplings'' to generate counterexamples.

\section{Related Work}
The DiPA model and counterexamples to privacy are drawn from \cite{chadhaLinearTimeDecidability2021}. Approximate liftings were developed in \cite{bartheKopfOlmedo2012ProbabilisticRelationalReasoningforDifferentialPriv,BartheOlmedo2013} and applied to algorithms such as SVT in \cite{BartheEtAl2016}.
A full exploration of approximate liftings can be found in \cite{HsuThesis2017}. \cite{AlbarghouthiHsu2018} uses couplings; and in particular the ``shift'' couplings family we use, to create a heuristiccally successful program for proving the correctness of possible differentially private algorithms. 


{\color{red} need to reformat some citations at some point}
\bibliography{./dipalibrary}

\end{document} 