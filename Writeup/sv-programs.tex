\subsection{Decidability of Privacy}

Perhaps surprisingly, we now show that, for a subclass of programs under our program model, the privacy constraint system (definition \ref{privacyConstraintSystem}) is \textit{complete}; that is, if there exist no solutions to the privacy constraint system for a trajectory $L$, then $L$ is not private. 

Specifically, we analyze the class of programs such that outputs to the program uniquely identify paths; for any output $\sigma$ of a program $P$, there must exist exactly one path in $P$ that could have produced $\sigma$. 

We call this condition \textbf{output distinction}:

\begin{defn}[Output Distinction]\label{outputDistinctionDef}
    For a program $P$ generated by $G_P = (V_P, E_P)$, we say that $P$ satisfies \textbf{output distinction} if for all locations $\ell\in V_P$, if there exist two distinct edges $(\ell, \ell')$ labeled by $t'=(c', \sigma', \tau')$ and $(\ell, \ell^*)$ labeled by $t^* = (c^*, \sigma^*, \tau^*)$, then $\sigma' \neq \sigma^*$. Additionally, at least one of $\sigma'\in \Gamma$, $\sigma^*\in \Gamma$ is true (i.e. it cannot be that both transitions output a real number).
\end{defn}

We show that output distinction is, indeed, sufficient for the path-uniqueness condition described above.

\begin{prop}
    Let $P$ be a program generated by a proper graph $G_P$ that satisfies output distinction. Let $O\subseteq (\gamma\cup \RR)^*$ be the set of all possible outputs of paths in $P$. There exists an injection $f: O\to P$ from the set of all possible outputs to paths in $P$. 
\end{prop}
\begin{proof}
    Follows directly from the fact that $G_P$ satisfies determinism and output distinction. 
\end{proof}

Observe that, in particular, output distinction guarantees that if a path-program fails to be private, a program containing that path must also fail be to private. This is the key insight that allows us to produce counterexamples for any program whose trajectories do not satisfy the privacy constraint system. 

Thus, for output distinct programs, coupling proofs \textbf{completely} characterize differential privacy; the existence of \textit{any} coupling proof for privacy for a program that satisfies the privacy constraint system is equivalent to whether or not the program is private at all.

\begin{thm}\label{ProgramCounterexampleThm}
    If a program $P$ satisfies output distinction and, for some trajectory $L\subseteq P$, there does not exist a coupling strategy $C_L$ that satisfies the privacy constraint system, then there does not exist any finite $d>0$ such that $P$ is $d\varepsilon$-differentially private.
\end{thm}

\subsection{DiPA}

We have shown that we can decide whether or not a program is differentially private for the class of output-distinct programs under our program model. In particular, we argue that this procedure is conceptually simple (as we show later, it is also efficient) and demonstrate that it is \textit{complete} for this class of programs.

Notably, Chadha, Sistla, and Viswanathan \cite{chadhaLinearTimeDecidability2021} also have shown, through a completely different proof methodology, that there exists a complete and efficient decision procedure for determining if programs derived from an automata-theoretic model are differentially private. 

We demonstrate that these two program models are, in fact, equivalent. Additionally, we show that the privacy constraint system for trajectories can partially explain the somewhat arbitrary graph conditions checked for in the decision procedure of \cite{chadhaLinearTimeDecidability2021}.

We first introduce the program model of \cite{chadhaLinearTimeDecidability2021}, which is called DiPA:

\begin{defn}[\cite{chadhaLinearTimeDecidability2021}]
    A Differentially Private Automaton (DiPA) $A$ is an 8-tuple $(Q, \Sigma, C, \Gamma, q_{init}, X, P, \delta)$ where
    \begin{itemize}
        \item $Q$ is a finite set of locations partitioned into input locations $Q_{in}$ and non-input locations $Q_{non}$. 
        \item $\Sigma = \RR$ is the input alphabet
        \item $C = \{\texttt{true}, \lguard, \gguard\}$ is a set of guard conditions
        \item $\Gamma$ is a finite output alphabet
        \item $q_{init}\in Q$ is the initial location
        \item $X = \{\texttt{x}, \texttt{insample}, \texttt{insample}'\}$ is a set of variables
        \item $P: Q\to \QQ\times \QQ^{\geq 0}\times \QQ\times  \QQ^{\geq 0}$ is a parameter function that assigns sampling parameters for the Laplace distribution for each location
        \item $\delta:(Q\times C)\to (Q\times (\Gamma \cup \{\texttt{insample}, \texttt{insample}'\})\times \{\texttt{true}, \texttt{false}\})$ is a partial transition function. 
    \end{itemize}
    In addition, $\delta$ must satisfy the following conditions:
    \begin{itemize}
        \item \textbf{Determinism:} For any location $q\in Q$, if $\delta(q,\texttt{true})$ is defined, then $\delta(q,\lguard)$ and $\delta(q,\gguard)$ are not defined. 

        \item \textbf{Output Distinction:} For any location $q\in Q$, if $\delta(q, \gguard) = (q_1, o_1, b_1)$ and $\delta(q, \lguard) = (q_2, o_2, b_2)$, then $o_1\neq o_2$ and at least one of $o_1\in \Gamma$ and $o_2\in \Gamma$ is true.

        \item \textbf{Initialization:} The initial location $q_0$ has only one outgoing transition of the form $\delta(q_0, \texttt{true}) = (q, o, \texttt{true})$.

        \item \textbf{Non-input transition:} From any $q\in Q_{non}$, if $\delta(q, c)$ is defined, then $c=\texttt{true}$.
    \end{itemize}
\end{defn}

A DiPA operates as follows: 
\begin{itemize}
    \item At each location $q$ such that $P(q) = (a_q, d_q, a_q', d_q')$, a real-valued input $\texttt{in}$ is read in and two variables $\texttt{insample}\sim \Lap(\texttt{in}+a_q, \frac{1}{d_q\varepsilon})$ and $\texttt{insample}'\sim\Lap(\texttt{in}+a_q', \frac{1}{d_q'\varepsilon})$ are sampled. If $q\in Q_{non}$, then $\texttt{in}$ must be 0.
    \item $\texttt{insample}$ is compared to the stored variable $\texttt{x}$, and depending on the guards of the transitions out of the current location, the current location is changed and a value is output. This value can either be $\texttt{insample}, \texttt{insample}'$, or a symbol from $\Gamma$.
    \item Finally, the  value of $\texttt{x}$ is optionally updated with the value of $\texttt{insample}$.
\end{itemize}

Just like with programs, a path $\rho$ in a DiPA $A$ reads a real-valued input sequence $\texttt{in}\in \RR^n$.

We establish notation for discussing the probabilities of different paths in a DiPA, which allows us to define $d\varepsilon$-differential privacy. 

\begin{defn} 
    Let $\rho$ be a path in a DiPA $A$, let $\texttt{in}$ be a valid input sequence and let $o$ be an \textit{interval} $o\subseteq \RR$ of real numbers.
    Then $\texttt{Pr}[x, \rho, \texttt{in}, o]$ is the probability of $\rho$ being taken with input sequence $\texttt{in}$ and outputting $o$. If the first location in $\rho$ is $q_{init}$, then $\texttt{Pr}[x, \rho, \texttt{in}, o]$ may be shortened to $\texttt{Pr}[\rho, \texttt{in}, o]$, since the initial value of $\texttt{x}$ is irrelevant.
\end{defn}

For a full definition of DiPA semantics, we refer back to \cite{chadhaLinearTimeDecidability2021}. 

We argue that our program model completely encapsulates the set of programs modelable by DiPA. 
For example, observe that each condition on $\delta$ corresponds to a restriction on program-generating graphs; in particular, the non-input transition condition corresponds to public transitions. 
Indeed, the class of \textit{output distinct} programs under our program model and the class of programs modeled by DiPA are exactly equivalent. 

\begin{prop}
    If a program $P$ generated by $G_P$ satisfies output distinction, then $G_P$ represents a valid DiPA $A_P$, and, for any DiPA $A$, the automata graph of $A$ generates a program $P_A$ that satisfies output distinction. 
\end{prop}

We observe that the probability of a run $\rho$ of a generated DiPA $G_P$ producing an output $\sigma$ is equal to the probability of the corresponding path in $P$ producing the same output, so these models are indeed semantically equivalent as well.

\begin{prop}
    Let $P$ be a program generated by a DiPA $G_P$. For all runs $\rho$ of $G_P$, all possible output events $o$ of $\rho$, and input sequences $\texttt{in}$, \[
        \PP[\rho, \texttt{in}, o]=\PP[\Psi(\rho), \texttt{in}, o],
    \]
    where $\Psi$ is the forgetful homomorphism that drops states from runs. 
\end{prop}

Beyond the syntactic and semantic equivalence of these two program models, we also show equivalences between the decision procedure of \cite{chadhaLinearTimeDecidability2021} and our privacy constraint system. 

The decision procedure of \cite{chadhaLinearTimeDecidability2021} checks for the existence of four graph-theoretic structures in the graph of a DiPA $A$, called leaking cycles, leaking pairs, disclosing cycles, and privacy violating paths. 

As an example, we define leaking pairs, and refer back to \cite{chadhaLinearTimeDecidability2021} for full definitions of the other three graph structures.

\begin{defn}[\texttt{L}- and \texttt{G}-cycles; \texttt{AL}- and \texttt{AG}-paths]
    A cycle $\rho$ of a DiPA $A$ is called an \lcycle~(respectively, \gcycle) if there is an $i< |\rho|$ such that the guard of the $i$'th transition in $\rho$ is $\lguard$ (respectively, $\gguard$).
    We say that a path $\rho$ of a DiPA $A$ is an \texttt{AL}-path (respectively, \texttt{AG}-path) if all assignment transitions on $\rho$ have guard $\lguard$ (respectively, $\gguard$).
    Observe that a cycle can be both an \lcycle~and a \gcycle.
    Further, a path with no assignment transitions (including the empty path) is simultaneously both an \texttt{AL}-path and an \texttt{AG}-path.
\end{defn} 
\begin{defn}[Leaking Pairs~\cite{chadhaLinearTimeDecidability2021}]\label{defLeakingPairs}
    A pair of cycles $(C, C')$ in a DiPA A is called a leaking pair if one of the following two conditions is satisfied:
    \begin{enumerate}
        \item $C$ is an \lcycle, $C'$ is a \gcycle, and there is an AG-path
        from a state in $C$ to a state in $C'$.
        \item $C$ is a \gcycle, $C'$ is an \lcycle, and there is an AL-path
        from a state in $C$ to a state in $C'$.
    \end{enumerate}
\end{defn} 

Specifically, the existence of \textit{any} such ``problematic'' graph structure completely characterizes the privacy of a DiPA. 

\begin{thm}[\cite{chadhaLinearTimeDecidability2021}]\label{DiPACounterexamplesThm}
    For a DiPA $A$, there exists some $d>0$ such that for all $\varepsilon>0$, $A$ is $d\varepsilon$-differentially private if and only if the graph of $A$ does not contain a leaking cycle, leaking pair, disclosing cycle, or privacy violating path.
\end{thm}

Unfortunately, the graph structures used by \cite{chadhaLinearTimeDecidability2021} to decide the privacy of a DiPA can be rather obtuse; it can be hard to see why these four specific structures would characterize the privacy of a program. However, there is a direct relationship between these graph structures and the privacy constraint system of our model. 

\begin{thm}
    An output-distinct program $P$ contains a trajectory whose privacy constraint system is unsatisfiable (i.e.\ there exists some pair of contradictory constraints) if and only if the corresponding DiPA $A_P$ of $P$ contains a leaking cycle, leaking pair, disclosing cycle, or privacy violating path.
\end{thm}

Observe that this immediately provides a proof for theorem \ref{ProgramCounterexampleThm}. The reverse direction follows from corollary \ref{svProgramPrivacyCorollary} and theorem \ref{DiPACounterexamplesThm} along with the equivalence of the two program models.
The forward direction follows from a detailed case analysis (see lemma \ref{unsatisfiableImpliesNotWellformedLemma} in the appendix), for which we provide some simple illustrative examples:

Suppose that constraints (3) and (5) of the privacy constraint system of a trajectory $L$ contradict each other; i.e. attempting to change the shifts of a coupling strategy for $L$ to satisfy constraint (5) for some $\gamma_i$ would mean that constraint (3) is violated. This directly implies that $t_i$ must be a non-public transition that outputs $\texttt{insample}$ and that $t_i$ is contained within a cycle, which is exactly how a disclosing cycle can be defined in the generating graph of $G$. 

Similarly, suppose that constraint (1) is unsatisfiable for some $\gamma_i$ where $t_i$ is in a cycle. 
One way that this can happen is if trying to satisfy constraint (1) for $\gamma_i$ by setting $\gamma_{at(i)} = 1$ would violate constraint (1) for $\gamma_{at(i)}$. We can repeat this logic ``backwards'' through the trajectory until we reach an assignment transition $\gamma_{at(l)}$ such that setting $\gamma_{at(l)}=1$ \textit{does not} violate constraint (1) for itself. 
This logic implicitly ``constructs'' an $\texttt{AL}$-path from $t_{at(l)}$ to $t_i$, since constraint (1) only applies to transitions with guard $\lguard[\texttt{x}]$. 

In particular, it can be shown that setting $\gamma_{at(l)}=1$ must instead violate constraint (2) for some $\gamma_j$ where $t_{at(l)}$ is the assignment transition immediately preceding $t_j$, so $c_j = \gguard[\texttt{x}]$. 

Then setting $\gamma_{j}= 1$ must violate either constraint (3) or constraint (5) for $\gamma_{j}$. In the first case, it can be shown that there must be a privacy violating path from $t_j$ to $t_i$. In the second case, $t_{j}$ must be in a \gcycle (and observe that $t_i$ is in an \lcycle), so there is an \texttt{AL}-path from the \gcycle containing $t_j$ to the \lcycle containing $t_i$, creating a leaking pair. 

Thus, we argue that the DiPA graph conditions are best viewed as a summary of the different ways in which the privacy constraint system can be unsatisfiable for a trajectory. In this sense, we posit that coupling proofs provide a simpler characterization and rationale for the decision problem of privacy. 
